{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/pauly2/tk/crashs\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import pathlib\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import geomloss\n",
    "from scipy.special import softmax\n",
    "\n",
    "sys.path.append('/data/pauly2/tk/crashs')\n",
    "from vtkutil import *\n",
    "from lddmm import *\n",
    "from crashs import MeshData, Template, ASHSFolder, Workspace, ashs_output_to_cruise_input, run_cruise, cruise_postproc\n",
    "\n",
    "%cd /data/pauly2/tk/crashs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is cuda available? True\n",
      "Device count? 1\n",
      "Current device? 0\n",
      "Device name?  Quadro RTX 5000\n"
     ]
    }
   ],
   "source": [
    "# Load the template\n",
    "template = dict({ s: Template('/data/pauly2/ashs_xv/manifest/template_init_dir', s) for s in ['left','right'] })\n",
    "\n",
    "# Load the ASHS json\n",
    "with open('/data/pauly2/ashs_xv/manifest/crashs_input_fold_0.json') as fd:\n",
    "    ashs_input_desc = json.load(fd)\n",
    "\n",
    "# Prepare device\n",
    "# device = torch.device(args.device) if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(torch.cuda.current_device() if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Is cuda available?\", torch.cuda.is_available())\n",
    "print(\"Device count?\", torch.cuda.device_count())\n",
    "print(\"Current device?\", torch.cuda.current_device())\n",
    "print(\"Device name? \", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "# Keep track of ASHS importers and workspaces created\n",
    "data = {}\n",
    "\n",
    "# Run basic Nighres for each subject\n",
    "for d in ashs_input_desc:\n",
    "    id = d['id']\n",
    "    side = d['side']\n",
    "\n",
    "    # Create the output dir\n",
    "    out_dir = os.path.join('/data/pauly2/ashs_xv/work/fold_0/crashs_build', id)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    workspace = Workspace(out_dir, id)\n",
    "\n",
    "    # Store the data\n",
    "    data[id] = { 'side': side, 'workspace': workspace }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decimating mesh, target: 20000 faces\n",
      "Decimation complete, 19992 faces\n",
      "Decimating mesh, target: 20000 faces\n",
      "Decimation complete, 20000 faces\n",
      "Decimating mesh, target: 20000 faces\n",
      "Decimation complete, 20000 faces\n",
      "Decimating mesh, target: 20000 faces\n",
      "Decimation complete, 20000 faces\n",
      "Decimating mesh, target: 20000 faces\n",
      "Decimation complete, 20000 faces\n",
      "Decimating mesh, target: 20000 faces\n",
      "Decimation complete, 19968 faces\n",
      "Decimating mesh, target: 20000 faces\n",
      "Decimation complete, 20000 faces\n",
      "Decimating mesh, target: 20000 faces\n",
      "Decimation complete, 19976 faces\n",
      "Decimating mesh, target: 20000 faces\n",
      "Decimation complete, 19984 faces\n",
      "Decimating mesh, target: 20000 faces\n",
      "Decimation complete, 19992 faces\n",
      "Decimating mesh, target: 20000 faces\n",
      "Decimation complete, 20000 faces\n",
      "Decimating mesh, target: 20000 faces\n",
      "Decimation complete, 20000 faces\n",
      "Decimating mesh, target: 20000 faces\n",
      "Decimation complete, 20000 faces\n"
     ]
    }
   ],
   "source": [
    "# From the template directory, load the left/right flip file. \n",
    "flip_lr = np.loadtxt(os.path.join(template['left'].root, 'ashs_template_flip.mat'))\n",
    "\n",
    "# Set the sigma tensors\n",
    "# sigma_varifold = torch.tensor([template['left'].get_varifold_sigma()], dtype=torch.float32, device=device)\n",
    "sigma_varifold = torch.tensor([5], dtype=torch.float32, device=device)\n",
    "sigma_lddmm = torch.tensor([template['left'].get_lddmm_sigma()], dtype=torch.float32, device=device)\n",
    "\n",
    "# Load each of the meshes that will be used to build the template\n",
    "md = {}\n",
    "for id, sd in data.items():\n",
    "    \n",
    "    # Depending on the side, apply flip_lr as the transform\n",
    "    transform = flip_lr if sd['side'] == 'right' else None\n",
    "\n",
    "    # Load the mesh data (inflated avg surface in ASHS template space)\n",
    "    sd['pd_input'] = load_vtk(sd['workspace'].affine_moving)\n",
    "\n",
    "    # Downsample the mesh to a reasonable number of vertices\n",
    "    md[id] = MeshData(sd['pd_input'], device, transform=transform, target_faces=20000)\n",
    "    sd['pd_ds'] = vtk_make_pd(md[id].v, md[id].f)\n",
    "\n",
    "    # Apply additional Taubin smoothing to help build a smoother template\n",
    "    v,f = taubin_smooth(md[id].v, md[id].f, lam=0.5, mu=-0.45, steps=1000)\n",
    "    md[id] = MeshData(vtk_set_cell_array(vtk_make_pd(v, f), 'plab', md[id].lp), device)\n",
    "\n",
    "    pd = vtk_make_pd(md[id].v, md[id].f)\n",
    "    vtk_set_cell_array(pd, 'plab', md[id].lp)\n",
    "    save_vtk(pd, f'tmp/test_decimate_{id}.vtk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104937L 104937L 0.0\n",
      "104937L 106049L 167569.28125\n",
      "104937L 106312R 243772.5625\n",
      "104937L 113909R 195552.71875\n",
      "104937L 116748R 124347.96875\n",
      "104937L 117243R 181867.875\n",
      "104937L 117667R 122609.0625\n",
      "104937L 118374L 182103.5\n",
      "104937L 118430R 242721.0625\n",
      "104937L 120126L 121219.84375\n",
      "104937L 120267L 168783.46875\n",
      "104937L 120937L 195741.1875\n",
      "104937L 121250L 65552.875\n",
      "106049L 104937L 167569.28125\n",
      "106049L 106049L 0.0\n",
      "106049L 106312R 171448.625\n",
      "106049L 113909R 142091.8125\n",
      "106049L 116748R 154462.8125\n",
      "106049L 117243R 106478.28125\n",
      "106049L 117667R 126409.9375\n",
      "106049L 118374L 81883.84375\n",
      "106049L 118430R 127655.0625\n",
      "106049L 120126L 181912.90625\n",
      "106049L 120267L 151421.25\n",
      "106049L 120937L 181152.59375\n",
      "106049L 121250L 206505.6875\n",
      "106312R 104937L 243772.5625\n",
      "106312R 106049L 171448.625\n",
      "106312R 106312R 0.0\n",
      "106312R 113909R 135512.4375\n",
      "106312R 116748R 218999.09375\n",
      "106312R 117243R 175810.25\n",
      "106312R 117667R 217042.9375\n",
      "106312R 118374L 186314.5\n",
      "106312R 118430R 197615.21875\n",
      "106312R 120126L 247729.3125\n",
      "106312R 120267L 187983.75\n",
      "106312R 120937L 234934.375\n",
      "106312R 121250L 279673.625\n",
      "113909R 104937L 195552.75\n",
      "113909R 106049L 142091.8125\n",
      "113909R 106312R 135512.5\n",
      "113909R 113909R 0.0\n",
      "113909R 116748R 172556.625\n",
      "113909R 117243R 139358.0625\n",
      "113909R 117667R 96354.5\n",
      "113909R 118374L 154934.65625\n",
      "113909R 118430R 205513.625\n",
      "113909R 120126L 207718.734375\n",
      "113909R 120267L 126680.3125\n",
      "113909R 120937L 203893.28125\n",
      "113909R 121250L 208806.09375\n",
      "116748R 104937L 124347.96875\n",
      "116748R 106049L 154462.84375\n",
      "116748R 106312R 218999.125\n",
      "116748R 113909R 172556.65625\n",
      "116748R 116748R 0.0\n",
      "116748R 117243R 214502.0625\n",
      "116748R 117667R 123903.09375\n",
      "116748R 118374L 186720.25\n",
      "116748R 118430R 244281.75\n",
      "116748R 120126L 134956.0\n",
      "116748R 120267L 150274.5625\n",
      "116748R 120937L 261974.375\n",
      "116748R 121250L 157207.1875\n",
      "117243R 104937L 181867.90625\n",
      "117243R 106049L 106478.28125\n",
      "117243R 106312R 175810.25\n",
      "117243R 113909R 139358.0625\n",
      "117243R 116748R 214502.0625\n",
      "117243R 117243R 0.0\n",
      "117243R 117667R 130543.40625\n",
      "117243R 118374L 141454.75\n",
      "117243R 118430R 180485.0\n",
      "117243R 120126L 239238.09375\n",
      "117243R 120267L 177786.46875\n",
      "117243R 120937L 159934.5\n",
      "117243R 121250L 224200.3125\n",
      "117667R 104937L 122609.0625\n",
      "117667R 106049L 126409.90625\n",
      "117667R 106312R 217042.9375\n",
      "117667R 113909R 96354.5\n",
      "117667R 116748R 123903.09375\n",
      "117667R 117243R 130543.375\n",
      "117667R 117667R 0.0\n",
      "117667R 118374L 157762.90625\n",
      "117667R 118430R 181500.8125\n",
      "117667R 120126L 165048.203125\n",
      "117667R 120267L 129239.53125\n",
      "117667R 120937L 184333.875\n",
      "117667R 121250L 116440.65625\n",
      "118374L 104937L 182103.5\n",
      "118374L 106049L 81883.84375\n",
      "118374L 106312R 186314.5\n",
      "118374L 113909R 154934.65625\n",
      "118374L 116748R 186720.25\n",
      "118374L 117243R 141454.71875\n",
      "118374L 117667R 157762.90625\n",
      "118374L 118374L 0.0\n",
      "118374L 118430R 134608.25\n",
      "118374L 120126L 169061.03125\n",
      "118374L 120267L 166305.1875\n",
      "118374L 120937L 173675.1875\n",
      "118374L 121250L 224967.3125\n",
      "118430R 104937L 242721.0625\n",
      "118430R 106049L 127655.0625\n",
      "118430R 106312R 197615.21875\n",
      "118430R 113909R 205513.625\n",
      "118430R 116748R 244281.75\n",
      "118430R 117243R 180485.0\n",
      "118430R 117667R 181500.8125\n",
      "118430R 118374L 134608.25\n",
      "118430R 118430R 0.0\n",
      "118430R 120126L 192956.21875\n",
      "118430R 120267L 248628.625\n",
      "118430R 120937L 236053.5625\n",
      "118430R 121250L 277878.5625\n",
      "120126L 104937L 121219.84375\n",
      "120126L 106049L 181912.9375\n",
      "120126L 106312R 247729.3125\n",
      "120126L 113909R 207718.734375\n",
      "120126L 116748R 134955.96875\n",
      "120126L 117243R 239238.0625\n",
      "120126L 117667R 165048.1875\n",
      "120126L 118374L 169061.03125\n",
      "120126L 118430R 192956.21875\n",
      "120126L 120126L 0.0\n",
      "120126L 120267L 200213.53125\n",
      "120126L 120937L 229398.5\n",
      "120126L 121250L 139651.75\n",
      "120267L 104937L 168783.46875\n",
      "120267L 106049L 151421.25\n",
      "120267L 106312R 187983.78125\n",
      "120267L 113909R 126680.3125\n",
      "120267L 116748R 150274.5625\n",
      "120267L 117243R 177786.46875\n",
      "120267L 117667R 129239.53125\n",
      "120267L 118374L 166305.1875\n",
      "120267L 118430R 248628.625\n",
      "120267L 120126L 200213.53125\n",
      "120267L 120267L 0.0\n",
      "120267L 120937L 214074.09375\n",
      "120267L 121250L 199159.1875\n",
      "120937L 104937L 195741.1875\n",
      "120937L 106049L 181152.625\n",
      "120937L 106312R 234934.375\n",
      "120937L 113909R 203893.3125\n",
      "120937L 116748R 261974.375\n",
      "120937L 117243R 159934.4375\n",
      "120937L 117667R 184333.875\n",
      "120937L 118374L 173675.15625\n",
      "120937L 118430R 236053.5625\n",
      "120937L 120126L 229398.46875\n",
      "120937L 120267L 214074.09375\n",
      "120937L 120937L 0.0\n",
      "120937L 121250L 216940.0625\n",
      "121250L 104937L 65552.875\n",
      "121250L 106049L 206505.6875\n",
      "121250L 106312R 279673.625\n",
      "121250L 113909R 208806.109375\n",
      "121250L 116748R 157207.1875\n",
      "121250L 117243R 224200.3125\n",
      "121250L 117667R 116440.625\n",
      "121250L 118374L 224967.3125\n",
      "121250L 118430R 277878.5625\n",
      "121250L 120126L 139651.75\n",
      "121250L 120267L 199159.1875\n",
      "121250L 120937L 216940.0625\n",
      "121250L 121250L 0.0\n",
      "Best template candidate: 117667R, mean distance 134706.83533653847 vs 164805.3785133136\n"
     ]
    }
   ],
   "source": [
    "# Compute the varifold loss between all pairs of atlases in the template subset before\n",
    "# any registration - this is to determine the best candidate for the template\n",
    "ids = list(md.keys())\n",
    "dsq_sub = np.zeros((len(md), len(md)))\n",
    "for i1, (k1,v1) in enumerate(md.items()):\n",
    "    for i2, (k2,v2) in enumerate(md.items()):\n",
    "        pair_loss = lossVarifoldSurfWithLabels(v1.ft, v2.vt, v2.ft, v1.lpt, v2.lpt, \n",
    "                                                GaussLinKernelWithLabels(sigma_varifold, v1.lp.shape[1]))\n",
    "        dsq_sub[i1,i2] = pair_loss(v1.vt).item()\n",
    "        print(k1, k2, dsq_sub[i1,i2])\n",
    "        \n",
    "# Find the index of the template candidate\n",
    "i_src = np.argmin(dsq_sub.sum(axis=1))\n",
    "id_src = ids[i_src]\n",
    "print(f'Best template candidate: {id_src}, mean distance {dsq_sub.mean(axis=1)[i_src]} vs {dsq_sub.mean()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_rotation_from_vector(x):\n",
    "    \"\"\"\n",
    "    Generate a 3D rotation vector from three parameters.\n",
    "\n",
    "    Args:\n",
    "        x: \n",
    "            A torch tensor of shape (3). It contains the parameters of the rotation.\n",
    "            [Write more detail about what the parameters mean geometrically]\n",
    "    Output:\n",
    "        A shape (3,3) tensor holding a rotation matrix corresponding to x\n",
    "    \"\"\"\n",
    "    # I will use the the axis/angle representation. The norm of the vector x gives the\n",
    "    # angle in radians, and the normalized vector is the axis around which the rotation\n",
    "    # is performed. At x=[0,0,0], there is a degeneracy that requires special handling\n",
    "    # but this should not prevent the code from being used in optimization\n",
    "    \n",
    "    # Compute theta, no issues here\n",
    "    theta = torch.norm(x)\n",
    "\n",
    "    # Use the trick from `torch.nn.functional.normalize`, which adds a small epsilon to\n",
    "    # the denominator to avoid division by zero\n",
    "    v = torch.nn.functional.normalize(x, dim=0)\n",
    "\n",
    "    # Apply the Rodrigues formula\n",
    "    A = torch.zeros(3, 3, dtype=x.dtype, device=x.device)\n",
    "    A[0,1], A[0,2], A[1,2] = -v[2], v[1], -v[0]\n",
    "    K = A - A.T\n",
    "    R = torch.eye(3, dtype=x.dtype, device=x.device) + torch.sin(theta) * K + (1-torch.cos(theta)) * (K @ K)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair 104937L, 106049L loss : 119642.062500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_199102/2798177639.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# Run the optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mopt_affine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# Print loss and record the best run/best parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/be537/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m                             )\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/be537/lib/python3.9/site-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/be537/lib/python3.9/site-packages/torch/optim/lbfgs.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;31m# evaluate initial f(x) and df/dx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0morig_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mcurrent_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/be537/lib/python3.9/site-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_199102/2798177639.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss_ab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1_to_v2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_ba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv2_to_v1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/be537/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
      "\u001b[0;32m~/.conda/envs/be537/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compute the varifold loss between all pairs of atlases with similarity transform,\n",
    "# running a quick registration between all pairs. This might get too much for large\n",
    "# training sets though\n",
    "ids = list(md.keys())\n",
    "dsq_sub = np.zeros((len(md), len(md)))\n",
    "\n",
    "# The default affine parameters\n",
    "theta_all = { }\n",
    "kernel = GaussLinKernelWithLabels(sigma_varifold, md[ids[0]].lp.shape[1])\n",
    "for i1, (k1,v1) in enumerate(md.items()):\n",
    "    for i2, (k2,v2) in enumerate(md.items()):\n",
    "        if k1 != k2: \n",
    "            # Define the symmetric loss for this pair\n",
    "            loss_ab = lossVarifoldSurfWithLabels(v1.ft, v2.vt, v2.ft, v1.lpt, v2.lpt, kernel)\n",
    "            loss_ba = lossVarifoldSurfWithLabels(v2.ft, v1.vt, v1.ft, v2.lpt, v1.lpt, kernel)\n",
    "            pair_theta = torch.tensor([0.01, 0.01, 0.01, 1.0, 0.0, 0.0, 0.0], \n",
    "                                    dtype=torch.float32, device=device, requires_grad=True)\n",
    "            \n",
    "            # Create optimizer\n",
    "            opt_affine = torch.optim.LBFGS([pair_theta], max_eval=10, max_iter=10, line_search_fn='strong_wolfe')\n",
    "\n",
    "            # Define closure\n",
    "            def closure():\n",
    "                opt_affine.zero_grad()\n",
    "\n",
    "                R = my_rotation_from_vector(pair_theta[0:3]) * pair_theta[3]\n",
    "                b = pair_theta[4:]\n",
    "                R_inv = torch.inverse(R)\n",
    "                b_inv = - R_inv @ b\n",
    "\n",
    "                v1_to_v2 = (R @ v1.vt.t()).t() + b\n",
    "                v2_to_v1 = (R_inv @ v2.vt.t()).t() + b_inv\n",
    "\n",
    "                L = 0.5 * (loss_ab(v1_to_v2) + loss_ba(v2_to_v1))\n",
    "                L.backward()\n",
    "                return L\n",
    "            \n",
    "            # Run the optimization\n",
    "            for i in range(10):\n",
    "                opt_affine.step(closure)\n",
    "\n",
    "            # Print loss and record the best run/best parameters\n",
    "            dsq_sub[i1,i2] = closure().item()\n",
    "            theta_all[(k1,k2)] = pair_theta.detach()\n",
    "            print(f'Pair {k1}, {k2} loss : {dsq_sub[i1,i2]:8.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best template candidate: 113909R, mean distance 82006.578125 vs 96785.2781989645\n"
     ]
    }
   ],
   "source": [
    "# Find the index of the template candidate\n",
    "i_best = np.argmin(dsq_sub.sum(axis=1))\n",
    "k_best = ids[i_best]\n",
    "print(f'Best template candidate: {k_best}, mean distance {dsq_sub.mean(axis=1)[i_best]} vs {dsq_sub.mean()}')\n",
    "\n",
    "# Now we need to go through and apply the best transformation to each case\n",
    "for i, (k,v) in enumerate(md.items()):\n",
    "    affine_mat = np.eye(4)\n",
    "    if k != k_best:\n",
    "        # Compute the transform to move k to k_best\n",
    "        theta_pair = theta_all[(k,k_best)]\n",
    "        R = my_rotation_from_vector(theta_pair[0:3]) * theta_pair[3]\n",
    "        b = theta_pair[4:]\n",
    "\n",
    "        # Save the transformation\n",
    "        affine_mat[0:3,0:3] = R.detach().cpu().numpy()\n",
    "        affine_mat[0:3,  3] = b.detach().cpu().numpy()\n",
    "\n",
    "        # Save the registered mesh\n",
    "        v_reg = (R @ v.vt.t()).t() + b\n",
    "        pd_reg = vtk_make_pd(v_reg.detach().cpu().numpy(), v.f)\n",
    "        pd_reg = vtk_set_cell_array(pd_reg, 'plab', v.lp)\n",
    "        save_vtk(pd_reg, f'tmp/test_register_{k}.vtk')\n",
    "    else:\n",
    "        pd_reg = vtk_make_pd(v.vt.detach().cpu().numpy(), v.f)\n",
    "        pd_reg = vtk_set_cell_array(pd_reg, 'plab', v.lp)\n",
    "        save_vtk(pd_reg, f'tmp/test_register_{k}.vtk')\n",
    "\n",
    "    np.savetxt(f'tmp/affine_to_template_{k}.mat', affine_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start here once you did affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's read these meshes all over again\n",
    "md_aff = {}\n",
    "for id, sd in data.items():\n",
    "    md_aff[id] = MeshData(load_vtk(f'tmp/test_register_{id}.vtk'), device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best template candidate: 113909R, mean distance 57551.558293269234 vs 66266.58621486687\n"
     ]
    }
   ],
   "source": [
    "# Compute the varifold loss between all pairs of atlases in the template subset before\n",
    "# any registration - this is to determine the best candidate for the template\n",
    "dsq_sub_aff = np.zeros((len(md_aff), len(md_aff)))\n",
    "for i1, (k1,v1) in enumerate(md_aff.items()):\n",
    "    for i2, (k2,v2) in enumerate(md_aff.items()):\n",
    "        pair_loss = lossVarifoldSurfWithLabels(v1.ft, v2.vt, v2.ft, v1.lpt, v2.lpt, \n",
    "                                                GaussLinKernelWithLabels(sigma_varifold, v1.lp.shape[1]))\n",
    "        dsq_sub_aff[i1,i2] = pair_loss(v1.vt).item()\n",
    "        \n",
    "# Find the index of the template candidate\n",
    "i_src = np.argmin(dsq_sub_aff.sum(axis=1))\n",
    "id_src = list(md_aff.keys())[i_src]\n",
    "print(f'Best template candidate: {id_src}, mean distance {dsq_sub_aff.mean(axis=1)[i_src]} vs {dsq_sub_aff.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_282450/4133472675.py:21: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing optimization...\n",
      "loop 0 it  0 : loss 58590.33\n",
      "loss 58538.117\n",
      "loss 58070.35\n",
      "loss 55783.45\n",
      "loss 36880.926\n",
      "loss 21507.525\n",
      "loss 15940.157\n",
      "loss 12152.864\n",
      "loss 9967.647\n",
      "loss 8353.243\n",
      "loss 7264.7305\n",
      "loss 6356.4136\n",
      "loss 5804.233\n",
      "loss 5108.625\n",
      "loss 4657.018\n",
      "loss 4310.9624\n",
      "loop 0 it  1 : loss 4310.9624\n",
      "loss 4037.0576\n",
      "loss 3760.9807\n",
      "loss 3412.2766\n",
      "loss 3247.2654\n",
      "loss 3000.9998\n",
      "loss 2890.3289\n",
      "loss 2770.5088\n",
      "loss 2613.636\n",
      "loss 2529.1516\n",
      "loss 2419.1067\n",
      "loss 2344.7275\n",
      "loss 2247.0496\n",
      "loss 2124.166\n",
      "loss 2026.0796\n",
      "loss 1932.8729\n",
      "loop 0 it  2 : loss 1932.8729\n",
      "loss 1838.4634\n",
      "loss 1759.1803\n",
      "loss 1699.0504\n",
      "loss 1631.6964\n",
      "loss 1575.5435\n",
      "loss 1515.2178\n",
      "loss 1469.5781\n",
      "loss 1415.8208\n",
      "loss 1379.9711\n",
      "loss 1343.8052\n",
      "loss 1310.4236\n",
      "loss 1288.2694\n",
      "loss 1252.809\n",
      "loss 1213.577\n",
      "loss 1184.6647\n",
      "loop 0 it  3 : loss 1184.6647\n",
      "loss 1166.1188\n",
      "loss 1133.3737\n",
      "loss 1105.3508\n",
      "loss 1077.1577\n",
      "loss 1046.4344\n",
      "loss 1026.9844\n",
      "loss 1004.40796\n",
      "loss 978.8319\n",
      "loss 955.822\n",
      "loss 940.3514\n",
      "loss 926.3813\n",
      "loss 913.2293\n",
      "loss 900.2513\n",
      "loss 888.4801\n",
      "loss 878.13794\n",
      "loop 0 it  4 : loss 878.13794\n",
      "loss 867.75824\n",
      "loss 858.5034\n",
      "loss 844.055\n",
      "loss 829.05383\n",
      "loss 814.955\n",
      "loss 796.0546\n",
      "loss 783.4311\n",
      "loss 772.1694\n",
      "loss 762.53705\n",
      "loss 753.07275\n",
      "loss 742.25146\n",
      "loss 734.00055\n",
      "loss 727.3693\n",
      "loss 719.7584\n",
      "loss 707.21625\n",
      "loop 0 it  5 : loss 707.21625\n",
      "loss 696.3862\n",
      "loss 687.116\n",
      "loss 679.9057\n",
      "loss 672.688\n",
      "loss 664.5003\n",
      "loss 655.5585\n",
      "loss 645.82794\n",
      "loss 636.6847\n",
      "loss 630.38635\n",
      "loss 625.2555\n",
      "loss 619.2109\n",
      "loss 610.9084\n",
      "loss 603.9571\n",
      "loss 597.8788\n",
      "loss 592.6835\n",
      "loop 0 it  6 : loss 592.6835\n",
      "loss 586.94836\n",
      "loss 580.2902\n",
      "loss 574.4516\n",
      "loss 568.8799\n",
      "loss 563.8265\n",
      "loss 559.4265\n",
      "loss 555.4483\n",
      "loss 551.3235\n",
      "loss 546.1945\n",
      "loss 541.0244\n",
      "loss 536.5496\n",
      "loss 531.8922\n",
      "loss 527.2844\n",
      "loss 522.7704\n",
      "loss 518.9654\n",
      "loop 0 it  7 : loss 518.9654\n",
      "loss 515.0547\n",
      "loss 510.93796\n",
      "loss 506.77985\n",
      "loss 503.54242\n",
      "loss 499.76486\n",
      "loss 496.03098\n",
      "loss 493.0505\n",
      "loss 489.9547\n",
      "loss 486.41043\n",
      "loss 483.4556\n",
      "loss 481.0256\n",
      "loss 478.3052\n",
      "loss 474.9545\n",
      "loss 471.38846\n",
      "loss 468.50745\n",
      "loop 0 it  8 : loss 468.50745\n",
      "loss 465.6826\n",
      "loss 462.45047\n",
      "loss 459.87408\n",
      "loss 457.99374\n",
      "loss 455.67776\n",
      "loss 452.0048\n",
      "loss 448.926\n",
      "loss 446.49118\n",
      "loss 444.19525\n",
      "loss 441.43863\n",
      "loss 438.77863\n",
      "loss 436.89392\n",
      "loss 434.484\n",
      "loss 431.98834\n",
      "loss 430.07336\n",
      "loop 0 it  9 : loss 430.07336\n",
      "loss 427.96716\n",
      "loss 425.678\n",
      "loss 422.79605\n",
      "loss 420.69928\n",
      "loss 418.40112\n",
      "loss 416.32788\n",
      "loss 414.0688\n",
      "loss 412.02277\n",
      "loss 410.1251\n",
      "loss 408.31946\n",
      "loss 406.3652\n",
      "loss 404.42664\n",
      "loss 402.60165\n",
      "loss 400.96988\n",
      "loss 399.38535\n",
      "Optimization (L-BFGS) time:  505.4  seconds\n",
      "performing optimization...\n",
      "loop 1 it  0 : loss 48370.387\n",
      "loss 48327.58\n",
      "loss 47943.996\n",
      "loss 46068.473\n",
      "loss 31234.043\n",
      "loss 21701.812\n",
      "loss 15836.654\n",
      "loss 12576.779\n",
      "loss 10249.094\n",
      "loss 8770.169\n",
      "loss 7192.9287\n",
      "loss 6404.4204\n",
      "loss 5626.9487\n",
      "loss 5276.395\n",
      "loss 4545.252\n",
      "loss 4282.3193\n",
      "loop 1 it  1 : loss 4282.3193\n",
      "loss 3931.0635\n",
      "loss 3726.8635\n",
      "loss 3396.8926\n",
      "loss 3237.326\n",
      "loss 3089.5234\n",
      "loss 2880.0623\n",
      "loss 2707.1938\n",
      "loss 2567.0613\n",
      "loss 2422.4692\n",
      "loss 2306.5955\n",
      "loss 2201.043\n",
      "loss 2146.745\n",
      "loss 2069.9817\n",
      "loss 1969.8889\n",
      "loss 1899.8864\n",
      "loop 1 it  2 : loss 1899.8864\n",
      "loss 1830.1017\n",
      "loss 1752.0575\n",
      "loss 1710.1998\n",
      "loss 1663.3134\n",
      "loss 1596.074\n",
      "loss 1535.3221\n",
      "loss 1498.4797\n",
      "loss 1445.0375\n",
      "loss 1416.4716\n",
      "loss 1380.0651\n",
      "loss 1351.0477\n",
      "loss 1328.3295\n",
      "loss 1278.5774\n",
      "loss 1255.0941\n",
      "loss 1216.8821\n",
      "loop 1 it  3 : loss 1216.8821\n",
      "loss 1195.312\n",
      "loss 1168.6721\n",
      "loss 1143.3939\n",
      "loss 1110.2529\n",
      "loss 1089.5928\n",
      "loss 1064.6648\n",
      "loss 1040.6632\n",
      "loss 1017.0722\n",
      "loss 1000.4412\n",
      "loss 984.89465\n",
      "loss 963.8365\n",
      "loss 944.2527\n",
      "loss 929.5507\n",
      "loss 915.9057\n",
      "loss 897.97955\n",
      "loop 1 it  4 : loss 897.97955\n",
      "loss 878.677\n",
      "loss 864.09717\n",
      "loss 854.25415\n",
      "loss 839.1655\n",
      "loss 834.41095\n",
      "loss 813.5656\n",
      "loss 806.9425\n",
      "loss 797.31793\n",
      "loss 784.7184\n",
      "loss 772.3679\n",
      "loss 762.28754\n",
      "loss 753.4184\n",
      "loss 743.02924\n",
      "loss 731.46704\n",
      "loss 722.2601\n",
      "loop 1 it  5 : loss 722.2601\n",
      "loss 714.1597\n",
      "loss 706.3404\n",
      "loss 696.7095\n",
      "loss 688.27826\n",
      "loss 680.7438\n",
      "loss 672.3554\n",
      "loss 664.5016\n",
      "loss 656.87067\n",
      "loss 650.4871\n",
      "loss 642.8301\n",
      "loss 636.8722\n",
      "loss 630.95746\n",
      "loss 624.7008\n",
      "loss 619.59595\n",
      "loss 612.054\n",
      "loop 1 it  6 : loss 612.054\n",
      "loss 605.80316\n",
      "loss 600.72614\n",
      "loss 594.8488\n",
      "loss 588.1987\n",
      "loss 582.9754\n",
      "loss 577.4945\n",
      "loss 572.51514\n",
      "loss 567.64435\n",
      "loss 561.31506\n",
      "loss 556.9702\n",
      "loss 553.1356\n",
      "loss 547.25195\n",
      "loss 543.141\n",
      "loss 538.14716\n",
      "loss 533.0878\n",
      "loop 1 it  7 : loss 533.0878\n",
      "loss 528.46735\n",
      "loss 525.4957\n",
      "loss 520.43823\n",
      "loss 517.7976\n",
      "loss 513.61053\n",
      "loss 510.55835\n",
      "loss 507.92596\n",
      "loss 504.68536\n",
      "loss 500.06378\n",
      "loss 497.0284\n",
      "loss 493.58047\n",
      "loss 490.28195\n",
      "loss 487.32404\n",
      "loss 484.36563\n",
      "loss 482.0743\n",
      "loop 1 it  8 : loss 482.0743\n",
      "loss 480.24908\n",
      "loss 476.20578\n",
      "loss 474.0323\n",
      "loss 471.5468\n",
      "loss 468.25964\n",
      "loss 466.21024\n",
      "loss 462.8053\n",
      "loss 460.07346\n",
      "loss 458.15054\n",
      "loss 454.99652\n",
      "loss 452.815\n",
      "loss 450.12766\n",
      "loss 447.18497\n",
      "loss 444.8035\n",
      "loss 442.23355\n",
      "loop 1 it  9 : loss 442.23355\n",
      "loss 439.05087\n",
      "loss 436.5593\n",
      "loss 434.24017\n",
      "loss 431.3736\n",
      "loss 428.93356\n",
      "loss 426.99973\n",
      "loss 423.5603\n",
      "loss 421.6597\n",
      "loss 419.25626\n",
      "loss 416.7273\n",
      "loss 415.0784\n",
      "loss 413.26642\n",
      "loss 410.15115\n",
      "loss 408.59064\n",
      "loss 406.95273\n",
      "Optimization (L-BFGS) time:  503.05  seconds\n",
      "performing optimization...\n",
      "loop 2 it  0 : loss 44842.676\n",
      "loss 44801.7\n",
      "loss 44617.54\n",
      "loss 42645.516\n",
      "loss 29144.602\n",
      "loss 20618.594\n",
      "loss 15310.968\n",
      "loss 12002.952\n",
      "loss 10114.643\n",
      "loss 8433.773\n",
      "loss 7354.879\n",
      "loss 6467.6323\n",
      "loss 5879.9756\n",
      "loss 5359.6143\n",
      "loss 4942.677\n",
      "loss 4415.5312\n",
      "loop 2 it  1 : loss 4415.5312\n",
      "loss 4208.9116\n",
      "loss 3701.6423\n",
      "loss 3509.9893\n",
      "loss 3253.8264\n",
      "loss 3010.347\n",
      "loss 2772.5127\n",
      "loss 2586.5735\n",
      "loss 2453.141\n",
      "loss 2535.2283\n",
      "loss 2358.7087\n",
      "loss 2229.4824\n",
      "loss 2135.6797\n",
      "loss 2029.8524\n",
      "loss 1920.7567\n",
      "loss 1841.5673\n",
      "loop 2 it  2 : loss 1841.5673\n",
      "loss 1774.7341\n",
      "loss 1720.6266\n",
      "loss 1660.7753\n",
      "loss 1598.0322\n",
      "loss 1551.511\n",
      "loss 1491.576\n",
      "loss 1432.0974\n",
      "loss 1385.386\n",
      "loss 1348.8348\n",
      "loss 1311.3518\n",
      "loss 1276.3064\n",
      "loss 1239.6139\n",
      "loss 1205.3254\n",
      "loss 1178.801\n",
      "loss 1153.5917\n",
      "loop 2 it  3 : loss 1153.5917\n",
      "loss 1119.0554\n",
      "loss 1088.867\n",
      "loss 1055.8759\n",
      "loss 1027.6475\n",
      "loss 1003.3957\n",
      "loss 980.13904\n",
      "loss 958.55646\n",
      "loss 943.3552\n",
      "loss 929.5829\n",
      "loss 911.1238\n",
      "loss 895.7502\n",
      "loss 885.31726\n",
      "loss 871.5141\n",
      "loss 858.7659\n",
      "loss 843.37775\n",
      "loop 2 it  4 : loss 843.37775\n",
      "loss 829.104\n",
      "loss 817.74817\n",
      "loss 808.3371\n",
      "loss 799.03894\n",
      "loss 788.535\n",
      "loss 774.72327\n",
      "loss 763.78906\n",
      "loss 755.0342\n",
      "loss 744.3159\n",
      "loss 733.365\n",
      "loss 723.61847\n",
      "loss 714.23224\n",
      "loss 705.9898\n",
      "loss 698.4592\n",
      "loss 689.68616\n",
      "loop 2 it  5 : loss 689.68616\n",
      "loss 680.5784\n",
      "loss 673.2765\n",
      "loss 666.1912\n",
      "loss 658.37463\n",
      "loss 649.749\n",
      "loss 642.9728\n",
      "loss 635.9376\n",
      "loss 629.1153\n",
      "loss 622.2564\n",
      "loss 616.4622\n",
      "loss 611.0961\n",
      "loss 606.24835\n",
      "loss 600.61615\n",
      "loss 593.7919\n",
      "loss 587.77386\n",
      "loop 2 it  6 : loss 587.77386\n",
      "loss 581.8381\n",
      "loss 575.64014\n",
      "loss 570.4498\n",
      "loss 563.7886\n",
      "loss 558.4707\n",
      "loss 552.92456\n",
      "loss 548.15936\n",
      "loss 543.9061\n",
      "loss 538.95557\n",
      "loss 534.9243\n",
      "loss 530.8245\n",
      "loss 525.53595\n",
      "loss 521.5242\n",
      "loss 517.8408\n",
      "loss 513.1618\n",
      "loop 2 it  7 : loss 513.1618\n",
      "loss 509.40485\n",
      "loss 504.20062\n",
      "loss 499.65167\n",
      "loss 495.22128\n",
      "loss 492.0502\n",
      "loss 488.90244\n",
      "loss 485.71268\n",
      "loss 481.8189\n",
      "loss 478.45255\n",
      "loss 475.5572\n",
      "loss 473.11224\n",
      "loss 470.54654\n",
      "loss 467.7989\n",
      "loss 465.13113\n",
      "loss 462.47797\n",
      "loop 2 it  8 : loss 462.47797\n",
      "loss 459.59433\n",
      "loss 456.34503\n",
      "loss 453.2676\n",
      "loss 451.04318\n",
      "loss 448.12802\n",
      "loss 445.9059\n",
      "loss 443.65836\n",
      "loss 440.58246\n",
      "loss 438.63904\n",
      "loss 436.59354\n",
      "loss 433.21527\n",
      "loss 431.46054\n",
      "loss 429.60217\n",
      "loss 426.85306\n",
      "loss 425.19373\n",
      "loop 2 it  9 : loss 425.19373\n",
      "loss 422.17996\n",
      "loss 419.70078\n",
      "loss 417.91516\n",
      "loss 415.96954\n",
      "loss 413.2935\n",
      "loss 410.72598\n",
      "loss 408.84006\n",
      "loss 406.97437\n",
      "loss 405.1316\n",
      "loss 402.6205\n",
      "loss 400.37216\n",
      "loss 397.7325\n",
      "loss 395.9985\n",
      "loss 394.35376\n",
      "loss 392.66183\n",
      "Optimization (L-BFGS) time:  504.52  seconds\n",
      "performing optimization...\n",
      "loop 3 it  0 : loss 44210.832\n",
      "loss 44170.08\n",
      "loss 43805.203\n",
      "loss 40346.27\n",
      "loss 25470.654\n",
      "loss 16509.795\n",
      "loss 13941.262\n",
      "loss 11557.312\n",
      "loss 8925.417\n",
      "loss 8606.24\n",
      "loss 6996.199\n",
      "loss 6476.0664\n",
      "loss 5811.012\n",
      "loss 5036.076\n",
      "loss 4632.9766\n",
      "loss 4119.2686\n",
      "loop 3 it  1 : loss 4119.2686\n",
      "loss 3790.0889\n",
      "loss 3467.7976\n",
      "loss 3154.0447\n",
      "loss 2936.0193\n",
      "loss 2801.5164\n",
      "loss 2665.5994\n",
      "loss 2518.0864\n",
      "loss 2382.0422\n",
      "loss 2249.359\n",
      "loss 2131.2766\n",
      "loss 2018.9622\n",
      "loss 1927.5181\n",
      "loss 1840.4159\n",
      "loss 1776.7627\n",
      "loss 1715.0298\n",
      "loop 3 it  2 : loss 1715.0298\n",
      "loss 1651.4235\n",
      "loss 1613.5165\n",
      "loss 1571.2184\n",
      "loss 1551.9858\n",
      "loss 1500.6047\n",
      "loss 1448.3707\n",
      "loss 1405.5825\n",
      "loss 1374.8505\n",
      "loss 1342.5975\n",
      "loss 1311.8391\n",
      "loss 1269.595\n",
      "loss 1233.9901\n",
      "loss 1213.3916\n",
      "loss 1169.092\n",
      "loss 1143.8075\n",
      "loop 3 it  3 : loss 1143.8075\n",
      "loss 1105.224\n",
      "loss 1086.1234\n",
      "loss 1064.7502\n",
      "loss 1037.0465\n",
      "loss 1010.81226\n",
      "loss 992.5527\n",
      "loss 972.70233\n",
      "loss 951.69476\n",
      "loss 932.36224\n",
      "loss 914.7833\n",
      "loss 900.7439\n",
      "loss 880.71674\n",
      "loss 865.21216\n",
      "loss 852.9529\n",
      "loss 840.62506\n",
      "loop 3 it  4 : loss 840.62506\n",
      "loss 827.48773\n",
      "loss 815.58234\n",
      "loss 807.04443\n",
      "loss 798.08246\n",
      "loss 786.70734\n",
      "loss 771.84875\n",
      "loss 764.4021\n",
      "loss 752.5257\n",
      "loss 745.1978\n",
      "loss 737.6151\n",
      "loss 724.98645\n",
      "loss 721.08685\n",
      "loss 706.9669\n",
      "loss 702.4368\n",
      "loss 694.79816\n",
      "loop 3 it  5 : loss 694.79816\n",
      "loss 686.14087\n",
      "loss 677.997\n",
      "loss 672.0713\n",
      "loss 667.39923\n",
      "loss 660.47894\n",
      "loss 649.999\n",
      "loss 643.5152\n",
      "loss 637.87305\n",
      "loss 629.27856\n",
      "loss 622.9184\n",
      "loss 615.86914\n",
      "loss 607.29095\n",
      "loss 601.5904\n",
      "loss 595.3732\n",
      "loss 591.0792\n",
      "loop 3 it  6 : loss 591.0792\n",
      "loss 586.59406\n",
      "loss 578.7885\n",
      "loss 572.38654\n",
      "loss 567.3925\n",
      "loss 562.4603\n",
      "loss 556.7235\n",
      "loss 552.35724\n",
      "loss 546.26935\n",
      "loss 543.8195\n",
      "loss 539.7658\n",
      "loss 533.4513\n",
      "loss 528.3845\n",
      "loss 524.92737\n",
      "loss 520.50226\n",
      "loss 516.9999\n",
      "loop 3 it  7 : loss 516.9999\n",
      "loss 513.02673\n",
      "loss 508.92157\n",
      "loss 505.97003\n",
      "loss 501.32648\n",
      "loss 497.2818\n",
      "loss 494.93085\n",
      "loss 491.65533\n",
      "loss 487.4966\n",
      "loss 483.65616\n",
      "loss 480.69855\n",
      "loss 477.0603\n",
      "loss 473.84485\n",
      "loss 470.74875\n",
      "loss 467.63898\n",
      "loss 465.57703\n",
      "loop 3 it  8 : loss 465.57703\n",
      "loss 462.78864\n",
      "loss 460.1539\n",
      "loss 456.86\n",
      "loss 455.33655\n",
      "loss 453.1922\n",
      "loss 450.72067\n",
      "loss 448.25632\n",
      "loss 446.25452\n",
      "loss 444.4067\n",
      "loss 441.7969\n",
      "loss 439.4308\n",
      "loss 436.56873\n",
      "loss 434.9628\n",
      "loss 432.89728\n",
      "loss 431.02698\n",
      "loop 3 it  9 : loss 431.02698\n",
      "loss 429.00824\n",
      "loss 427.1768\n",
      "loss 425.61432\n",
      "loss 423.12442\n",
      "loss 421.08694\n",
      "loss 419.21838\n",
      "loss 417.30768\n",
      "loss 415.33206\n",
      "loss 412.9753\n",
      "loss 411.012\n",
      "loss 409.02975\n",
      "loss 407.36066\n",
      "loss 405.59055\n",
      "loss 403.6132\n",
      "loss 401.8663\n",
      "Optimization (L-BFGS) time:  504.83  seconds\n",
      "performing optimization...\n",
      "loop 4 it  0 : loss 44667.125\n",
      "loss 44626.32\n",
      "loss 44442.895\n",
      "loss 42482.617\n",
      "loss 29601.12\n",
      "loss 21499.166\n",
      "loss 16211.179\n",
      "loss 12333.387\n",
      "loss 10549.02\n",
      "loss 8936.678\n",
      "loss 7769.575\n",
      "loss 6972.0225\n",
      "loss 6133.282\n",
      "loss 5555.363\n",
      "loss 5067.3306\n",
      "loss 4736.381\n",
      "loop 4 it  1 : loss 4736.381\n",
      "loss 4124.0166\n",
      "loss 4007.9731\n",
      "loss 3630.8528\n",
      "loss 3424.4775\n",
      "loss 3186.053\n",
      "loss 2878.8818\n",
      "loss 2956.7458\n",
      "loss 2705.4758\n",
      "loss 2598.0947\n",
      "loss 2479.311\n",
      "loss 2425.7131\n",
      "loss 2294.115\n",
      "loss 2157.7134\n",
      "loss 2044.868\n",
      "loss 1959.0706\n",
      "loop 4 it  2 : loss 1959.0706\n",
      "loss 1883.7561\n",
      "loss 1817.3341\n",
      "loss 1763.8193\n",
      "loss 1716.9652\n",
      "loss 1663.2334\n",
      "loss 1595.1298\n",
      "loss 1543.6027\n",
      "loss 1492.2496\n",
      "loss 1469.7505\n",
      "loss 1421.0485\n",
      "loss 1389.5944\n",
      "loss 1350.9542\n",
      "loss 1329.14\n",
      "loss 1304.4543\n",
      "loss 1261.3677\n",
      "loop 4 it  3 : loss 1261.3677\n",
      "loss 1230.9296\n",
      "loss 1198.5149\n",
      "loss 1163.8179\n",
      "loss 1136.2456\n",
      "loss 1090.7969\n",
      "loss 1059.9258\n",
      "loss 1037.8372\n",
      "loss 1017.6891\n",
      "loss 994.6235\n",
      "loss 967.2719\n",
      "loss 945.0532\n",
      "loss 930.47217\n",
      "loss 913.82056\n",
      "loss 897.2052\n",
      "loss 879.3438\n",
      "loop 4 it  4 : loss 879.3438\n",
      "loss 863.6927\n",
      "loss 851.2862\n",
      "loss 834.15356\n",
      "loss 821.52356\n",
      "loss 812.3175\n",
      "loss 800.22534\n",
      "loss 787.9044\n",
      "loss 777.03235\n",
      "loss 767.2359\n",
      "loss 758.592\n",
      "loss 746.24164\n",
      "loss 735.2154\n",
      "loss 727.5278\n",
      "loss 719.4423\n",
      "loss 710.67664\n",
      "loop 4 it  5 : loss 710.67664\n",
      "loss 701.5832\n",
      "loss 692.30414\n",
      "loss 683.8061\n",
      "loss 676.4567\n",
      "loss 668.6463\n",
      "loss 660.45264\n",
      "loss 652.64355\n",
      "loss 645.5428\n",
      "loss 638.9588\n",
      "loss 631.93317\n",
      "loss 623.1451\n",
      "loss 615.4762\n",
      "loss 609.8547\n",
      "loss 601.4753\n",
      "loss 595.65656\n",
      "loop 4 it  6 : loss 595.65656\n",
      "loss 590.02765\n",
      "loss 583.6636\n",
      "loss 579.66077\n",
      "loss 573.7922\n",
      "loss 568.538\n",
      "loss 563.63\n",
      "loss 559.255\n",
      "loss 553.56085\n",
      "loss 548.326\n",
      "loss 543.8964\n",
      "loss 539.4481\n",
      "loss 535.2377\n",
      "loss 530.0251\n",
      "loss 525.32526\n",
      "loss 521.8118\n",
      "loop 4 it  7 : loss 521.8118\n",
      "loss 517.6035\n",
      "loss 513.15875\n",
      "loss 509.0307\n",
      "loss 504.93143\n",
      "loss 501.4195\n",
      "loss 496.69638\n",
      "loss 493.2338\n",
      "loss 490.32806\n",
      "loss 487.9384\n",
      "loss 484.76126\n",
      "loss 480.72394\n",
      "loss 477.95456\n",
      "loss 475.64032\n",
      "loss 473.34222\n",
      "loss 470.3267\n",
      "loop 4 it  8 : loss 470.3267\n",
      "loss 466.80627\n",
      "loss 464.0181\n",
      "loss 461.21353\n",
      "loss 458.39944\n",
      "loss 455.56833\n",
      "loss 453.0488\n",
      "loss 451.15274\n",
      "loss 448.43674\n",
      "loss 446.62848\n",
      "loss 444.7291\n",
      "loss 442.84055\n",
      "loss 441.38327\n",
      "loss 438.15744\n",
      "loss 435.66568\n",
      "loss 432.8756\n",
      "loop 4 it  9 : loss 432.8756\n",
      "loss 431.34158\n",
      "loss 429.23627\n",
      "loss 426.82077\n",
      "loss 424.60696\n",
      "loss 422.83218\n",
      "loss 421.04907\n",
      "loss 418.44864\n",
      "loss 416.70193\n",
      "loss 414.38696\n",
      "loss 412.8064\n",
      "loss 410.85513\n",
      "loss 408.34357\n",
      "loss 405.80222\n",
      "loss 404.25208\n",
      "loss 402.4491\n",
      "Optimization (L-BFGS) time:  510.48  seconds\n"
     ]
    }
   ],
   "source": [
    "# Select this candidate and go with it\n",
    "md_src = md_aff[id_src]\n",
    "\n",
    "# Create losses for each of the target meshes\n",
    "loss = {}\n",
    "for i, (id,v) in enumerate(md_aff.items()):\n",
    "\n",
    "    # Data loss with label similarity\n",
    "    dataloss = lossVarifoldSurfWithLabels(\n",
    "        md_src.ft, v.vt, v.ft, md_src.lpt, v.lpt, \n",
    "        GaussLinKernelWithLabels(sigma_varifold, md_src.lp.shape[1]))\n",
    "    \n",
    "    # Complete LDDMM loss\n",
    "    loss[id] = LDDMMloss(GaussKernel(sigma=sigma_lddmm), dataloss, gamma=0.1)\n",
    "    \n",
    "# Create a storage for the template coordinates and momenta at each iteration\n",
    "td = list()\n",
    "\n",
    "# Initialize the first template iteration\n",
    "td.append({\n",
    "    'q': torch.tensor(md_src.vt, dtype=torch.float32, device=device, requires_grad=True).contiguous(),\n",
    "    'p': torch.zeros((len(md_aff),) + md_src.vt.shape, dtype=torch.float32, device=device, requires_grad=True).contiguous()\n",
    "})\n",
    "\n",
    "# Outer loop: template update iterations\n",
    "for m in range(5):\n",
    "\n",
    "    # Generate a combined objective function\n",
    "    optimizer = torch.optim.LBFGS([td[m]['p']], max_eval=16, max_iter=16, line_search_fn='strong_wolfe')\n",
    "    print(\"performing optimization...\")\n",
    "    start = time.time()\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        L = 0\n",
    "        for i, (id,v) in enumerate(md_aff.items()):\n",
    "            L = L + loss[id](td[m]['p'][i,:], td[m]['q'])\n",
    "        L = L / len(md_aff.items())\n",
    "        print(\"loss\", L.detach().cpu().numpy())\n",
    "        L.backward()\n",
    "        return L\n",
    "\n",
    "    for i in range(10):\n",
    "        print(\"loop\", m, \"it \", i, \": \", end=\"\")\n",
    "        optimizer.step(closure)\n",
    "\n",
    "    print(\"Optimization (L-BFGS) time: \", round(time.time() - start, 2), \" seconds\")\n",
    "\n",
    "    # Compute the new starting point for optimization\n",
    "    (p_mean, q_mean)=Shooting(td[m]['p'].mean(axis=0), td[m]['q'], GaussKernel(sigma=sigma_lddmm))[-1]\n",
    "    td.append({\n",
    "        'q': q_mean.detach().clone().detach().requires_grad_(True),\n",
    "        'p': torch.zeros_like(td[m]['p']).requires_grad_(True)\n",
    "    })\n",
    "\n",
    "# Save the template with labels\n",
    "v_opt = td[-1]['q'].detach().cpu().numpy()\n",
    "pd_template = vtk_make_pd(v_opt, md_src.f)\n",
    "\n",
    "# mlp_template = mesh_label_prob_maps(md_src['pd'])\n",
    "# lab_template = np.argmax(mlp_template, axis=1)\n",
    "# vtk_set_cell_array(pd_template, 'plab', mlp_template)\n",
    "# vtk_set_cell_array(pd_template, 'label', lab_template)\n",
    "\n",
    "# Save the left side template\n",
    "save_vtk(pd_template, f'tmp/template_shoot_built.vtk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p_mean, q_mean)=Shooting(td[-1]['p'].mean(axis=0), td[-1]['q'], GaussKernel(sigma=sigma_lddmm))[-1]\n",
    "pd_template = vtk_make_pd(q_mean.detach().cpu().numpy(), md_src.f)\n",
    "\n",
    "# Add the original array\n",
    "pd_template = vtk_set_cell_array(pd_template, 'plab', md_src.lp)\n",
    "\n",
    "# mlp_template = mesh_label_prob_maps(md_src['pd'])\n",
    "# lab_template = np.argmax(mlp_template, axis=1)\n",
    "# vtk_set_cell_array(pd_template, 'plab', mlp_template)\n",
    "# vtk_set_cell_array(pd_template, 'label', lab_template)\n",
    "\n",
    "# Save the left side template\n",
    "save_vtk(pd_template, f'tmp/template_shoot_built.vtk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting to targets with OMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's read these meshes all over again\n",
    "md_aff = {}\n",
    "for id, sd in data.items():\n",
    "    md_aff[id] = MeshData(load_vtk(f'tmp/test_register_{id}.vtk'), device)\n",
    "\n",
    "# Load the template previously saved (the left is equivalent to the right, except fo the flip)\n",
    "md_template = MeshData(load_vtk(f'results_symm/template_shoot_built.vtk'), device)\n",
    "\n",
    "# Create losses for each of the target meshes relative to the template\n",
    "for i, (k,v) in enumerate(md_aff.items()):\n",
    "\n",
    "    # Data loss with label similarity\n",
    "    v['dataloss'] = lossVarifoldSurfWithLabels(\n",
    "        md_template['ft'], v['vt'], v['ft'], md_template['lpt'], v['lpt'], \n",
    "        GaussLinKernelWithLabels(sigma=sigma))\n",
    "    \n",
    "    # Complete LDDMM loss\n",
    "    v['loss'] = LDDMMloss(GaussKernel(sigma=sigma), v['dataloss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'104937L': <crashs.MeshData at 0x7f4d016f4490>,\n",
       " '106049L': <crashs.MeshData at 0x7f4d00dc8d30>,\n",
       " '106312R': <crashs.MeshData at 0x7f4cf002e070>,\n",
       " '113909R': <crashs.MeshData at 0x7f4cf002eb50>,\n",
       " '116748R': <crashs.MeshData at 0x7f4cf002e5b0>,\n",
       " '117243R': <crashs.MeshData at 0x7f4cf002ed90>,\n",
       " '117667R': <crashs.MeshData at 0x7f4cf002e0a0>,\n",
       " '118374L': <crashs.MeshData at 0x7f4cf002e910>,\n",
       " '118430R': <crashs.MeshData at 0x7f4cf002e6d0>,\n",
       " '120126L': <crashs.MeshData at 0x7f4cf03d8c40>,\n",
       " '120267L': <crashs.MeshData at 0x7f4cf03d8a00>,\n",
       " '120937L': <crashs.MeshData at 0x7f4cf02bc9d0>,\n",
       " '121250L': <crashs.MeshData at 0x7f4cf03f3490>}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_aff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try a different way to build the template, non-iteratively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymeshlab\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_src = md_aff[id_src]\n",
    "pd_result = vtk_make_pd(md_src.v, md_src.f)\n",
    "pd_result = vtk_set_cell_array(pd_result, 'plab', md_src.lp)\n",
    "save_vtk(pd_result, 'tmp/smooth_input.vtk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  46.23693976,  -10.32145243,   22.4971508 ],\n",
       "       [ -10.32145243,  263.13849297, -119.82218186],\n",
       "       [  22.4971508 , -119.82218186,   77.77082017]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to generate an ellipsoid to use as a template instead of one subject\n",
    "v_all = np.concatenate([ x.v for id,x in md_aff.items() ], 0)\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(v_all)\n",
    "pca.get_covariance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = pymeshlab.MeshSet()\n",
    "ms.create_sphere(subdiv = 4)\n",
    "m0 = ms.mesh(0)\n",
    "v_sph, f_sph = m0.vertex_matrix(), m0.face_matrix()\n",
    "pd_sph = vtk_make_pd(v_sph, f_sph)\n",
    "pd_sph = vtk_set_cell_array(pd_sph, 'plab', np.zeros((f_sph.shape[0],1)))\n",
    "md_sph = MeshData(pd_sph, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 000, Loss: 10108611.0\n",
      "Iter 001, Loss: 213723.046875\n",
      "Iter 002, Loss: 213498.46875\n",
      "Iter 003, Loss: 213409.53125\n",
      "Iter 004, Loss: 213280.65625\n",
      "Iter 005, Loss: 213204.390625\n",
      "Iter 006, Loss: 213041.046875\n",
      "Iter 007, Loss: 212903.515625\n",
      "Iter 008, Loss: 212737.234375\n",
      "Iter 009, Loss: 212451.328125\n",
      "Iter 010, Loss: 211823.859375\n",
      "Iter 011, Loss: 211607.953125\n",
      "Iter 012, Loss: 211356.640625\n",
      "Iter 013, Loss: 210616.21875\n",
      "Iter 014, Loss: 210040.828125\n",
      "Iter 015, Loss: 208005.625\n",
      "Iter 016, Loss: 201438.078125\n",
      "Iter 017, Loss: 199097.15625\n",
      "Iter 018, Loss: 176922.046875\n",
      "Iter 019, Loss: 93612.8203125\n",
      "Iter 020, Loss: 92065.5234375\n",
      "Iter 021, Loss: 92065.5234375\n",
      "Iter 022, Loss: 92065.5234375\n",
      "Iter 023, Loss: 92065.5234375\n",
      "Iter 024, Loss: 92065.5234375\n",
      "Iter 025, Loss: 92065.5234375\n",
      "Iter 026, Loss: 92065.5234375\n",
      "Iter 027, Loss: 92065.5234375\n",
      "Iter 028, Loss: 92065.5234375\n",
      "Iter 029, Loss: 92065.5234375\n"
     ]
    }
   ],
   "source": [
    "# Find an affine transformation of the sphere that best aligns with the data \n",
    "# using the varifold measure\n",
    "\n",
    "# Create losses for each of the target meshes\n",
    "kernel = GaussLinKernel(sigma_varifold)\n",
    "loss = { id: lossVarifoldSurf(md_sph.ft, v.vt, v.ft, kernel) for (id,v) in md_aff.items() }\n",
    "\n",
    "# Create a parameter tensor for the sphere\n",
    "b = torch.tensor(pca.mean_, dtype=torch.float32, device=device, requires_grad=True).contiguous()\n",
    "A = torch.tensor(pca.get_covariance(), dtype=torch.float32, device=device, requires_grad=True).contiguous()\n",
    "\n",
    "# Generate a combined objective function\n",
    "optimizer = torch.optim.LBFGS([A,b], max_eval=16, max_iter=16, line_search_fn='strong_wolfe')\n",
    "start = time.time()\n",
    "\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    # Apply transformation to the sphere\n",
    "    x = md_sph.vt\n",
    "    y = (A @ x.T).T + b\n",
    "    L = 0\n",
    "    for i, (id,v) in enumerate(md_aff.items()):\n",
    "        L = L + loss[id](y)\n",
    "    L = L / len(md_aff.items())\n",
    "    L.backward()\n",
    "    return L\n",
    "\n",
    "for i in range(30):\n",
    "    print(f'Iter {i:03d}, Loss: {closure()}')\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the new rotated sphere\n",
    "v_sph_opt = (A @ md_sph.vt.T).T + b\n",
    "\n",
    "# Peform remeshing of the sphere\n",
    "ms = pymeshlab.MeshSet()\n",
    "ms.add_mesh(pymeshlab.Mesh(vertex_matrix=v_sph_opt.detach().cpu().numpy(), face_matrix=md_sph.f))\n",
    "ms.meshing_isotropic_explicit_remeshing()\n",
    "v_ell, f_ell = ms.mesh(0).vertex_matrix(), ms.mesh(0).face_matrix()\n",
    "\n",
    "pd_ell = vtk_make_pd(v_ell, f_ell)\n",
    "pd_ell = vtk_set_cell_array(pd_ell, 'plab', np.zeros((f_ell.shape[0],1)))\n",
    "md_ell = MeshData(pd_ell, device)\n",
    "\n",
    "pd_sphere_opt = vtk_make_pd(v_ell, f_ell)\n",
    "save_vtk(pd_sphere_opt, 'tmp/ellipsoid_best_fit.vtk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to initialize the labeling of the sphere. We can try directly to use OMT to \n",
    "# match the sphere to each of the meshes and maybe that's going to be good enough for getting\n",
    "# the initial label distributions. If not, have to deform\n",
    "def to_measure(points, triangles):\n",
    "    \"\"\"Turns a triangle into a weighted point cloud.\"\"\"\n",
    "\n",
    "    # Our mesh is given as a collection of ABC triangles:\n",
    "    A, B, C = points[triangles[:, 0]], points[triangles[:, 1]], points[triangles[:, 2]]\n",
    "\n",
    "    # Locations and weights of our Dirac atoms:\n",
    "    X = (A + B + C) / 3  # centers of the faces\n",
    "    S = torch.sqrt(torch.sum(torch.cross(B - A, C - A) ** 2, dim=1)) / 2  # areas of the faces\n",
    "\n",
    "    # We return a (normalized) vector of weights + a \"list\" of points\n",
    "    return S / torch.sum(S), X\n",
    "\n",
    "# Compute optimal transport matching\n",
    "def match_omt(vs, fs, vt, ft):\n",
    "    (a_src, x_src) = to_measure(vs, fs)\n",
    "    (a_trg, x_trg) = to_measure(vt, ft)\n",
    "    x_src.requires_grad_(True)\n",
    "    x_trg.requires_grad_(True)\n",
    "\n",
    "    # Generate correspondence between models using OMT\n",
    "    t_start = time.time()\n",
    "    w_loss = geomloss.SamplesLoss(\"sinkhorn\", p=2, blur=0.05, scaling=0.8, backend='multiscale', verbose=True)\n",
    "    w_loss_value = w_loss(a_src, x_src, a_trg, x_trg)\n",
    "    [w_loss_grad] = torch.autograd.grad(w_loss_value, x_src)\n",
    "    w_match = x_src - w_loss_grad / a_src[:, None]\n",
    "    t_end = time.time()\n",
    "\n",
    "    print(f'OMT matching distance: {w_loss_value.item()}, time elapsed: {t_end-t_start}')\n",
    "    return w_loss_value, w_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234x387 clusters, computed at scale = 3.367\n",
      "Successive scales :  73.469, 73.469, 58.775, 47.020, 37.616, 30.093, 24.074, 19.259, 15.408, 12.326, 9.861, 7.889, 6.311, 5.049, 4.039, 3.231, 2.585, 2.068, 1.654, 1.324, 1.059, 0.847, 0.678, 0.542, 0.434, 0.347, 0.278, 0.222, 0.178, 0.142, 0.114, 0.091, 0.073, 0.058, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.039) and 15 (=3.231).\n",
      "Keep 37619/90558 = 41.5% of the coarse cost matrix.\n",
      "Keep 25434/54756 = 46.4% of the coarse cost matrix.\n",
      "Keep 53261/149769 = 35.6% of the coarse cost matrix.\n",
      "OMT matching distance: 11.80711555480957, time elapsed: 3.303954839706421\n",
      "269x446 clusters, computed at scale = 3.169\n",
      "Successive scales :  69.161, 69.161, 55.329, 44.263, 35.410, 28.328, 22.663, 18.130, 14.504, 11.603, 9.283, 7.426, 5.941, 4.753, 3.802, 3.042, 2.433, 1.947, 1.557, 1.246, 0.997, 0.797, 0.638, 0.510, 0.408, 0.327, 0.261, 0.209, 0.167, 0.134, 0.107, 0.086, 0.068, 0.055, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.802) and 15 (=3.042).\n",
      "Keep 47369/119974 = 39.5% of the coarse cost matrix.\n",
      "Keep 30747/72361 = 42.5% of the coarse cost matrix.\n",
      "Keep 69610/198916 = 35.0% of the coarse cost matrix.\n",
      "OMT matching distance: 9.201794624328613, time elapsed: 3.6359260082244873\n",
      "234x392 clusters, computed at scale = 3.367\n",
      "Successive scales :  73.477, 73.477, 58.782, 47.025, 37.620, 30.096, 24.077, 19.262, 15.409, 12.327, 9.862, 7.890, 6.312, 5.049, 4.039, 3.232, 2.585, 2.068, 1.655, 1.324, 1.059, 0.847, 0.678, 0.542, 0.434, 0.347, 0.278, 0.222, 0.178, 0.142, 0.114, 0.091, 0.073, 0.058, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.039) and 15 (=3.232).\n",
      "Keep 38255/91728 = 41.7% of the coarse cost matrix.\n",
      "Keep 25432/54756 = 46.4% of the coarse cost matrix.\n",
      "Keep 55004/153664 = 35.8% of the coarse cost matrix.\n",
      "OMT matching distance: 13.82139778137207, time elapsed: 3.1872947216033936\n",
      "235x340 clusters, computed at scale = 3.350\n",
      "Successive scales :  73.101, 73.101, 58.481, 46.785, 37.428, 29.942, 23.954, 19.163, 15.330, 12.264, 9.811, 7.849, 6.279, 5.023, 4.019, 3.215, 2.572, 2.058, 1.646, 1.317, 1.053, 0.843, 0.674, 0.539, 0.432, 0.345, 0.276, 0.221, 0.177, 0.141, 0.113, 0.090, 0.072, 0.058, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.019) and 15 (=3.215).\n",
      "Keep 32933/79900 = 41.2% of the coarse cost matrix.\n",
      "Keep 25247/55225 = 45.7% of the coarse cost matrix.\n",
      "Keep 41794/115600 = 36.2% of the coarse cost matrix.\n",
      "OMT matching distance: 14.805846214294434, time elapsed: 3.0088307857513428\n",
      "268x411 clusters, computed at scale = 3.177\n",
      "Successive scales :  69.339, 69.339, 55.471, 44.377, 35.502, 28.401, 22.721, 18.177, 14.541, 11.633, 9.307, 7.445, 5.956, 4.765, 3.812, 3.050, 2.440, 1.952, 1.561, 1.249, 0.999, 0.799, 0.640, 0.512, 0.409, 0.327, 0.262, 0.210, 0.168, 0.134, 0.107, 0.086, 0.069, 0.055, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.812) and 15 (=3.050).\n",
      "Keep 44081/110148 = 40.0% of the coarse cost matrix.\n",
      "Keep 30706/71824 = 42.8% of the coarse cost matrix.\n",
      "Keep 61185/168921 = 36.2% of the coarse cost matrix.\n",
      "OMT matching distance: 16.830209732055664, time elapsed: 3.415099859237671\n",
      "229x368 clusters, computed at scale = 3.484\n",
      "Successive scales :  76.029, 76.029, 60.824, 48.659, 38.927, 31.142, 24.913, 19.931, 15.945, 12.756, 10.205, 8.164, 6.531, 5.225, 4.180, 3.344, 2.675, 2.140, 1.712, 1.370, 1.096, 0.877, 0.701, 0.561, 0.449, 0.359, 0.287, 0.230, 0.184, 0.147, 0.118, 0.094, 0.075, 0.060, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.180) and 15 (=3.344).\n",
      "Keep 36330/84272 = 43.1% of the coarse cost matrix.\n",
      "Keep 25305/52441 = 48.3% of the coarse cost matrix.\n",
      "Keep 49204/135424 = 36.3% of the coarse cost matrix.\n",
      "OMT matching distance: 14.692052841186523, time elapsed: 3.1529369354248047\n",
      "228x325 clusters, computed at scale = 3.474\n",
      "Successive scales :  75.816, 75.816, 60.653, 48.522, 38.818, 31.054, 24.843, 19.875, 15.900, 12.720, 10.176, 8.141, 6.513, 5.210, 4.168, 3.334, 2.668, 2.134, 1.707, 1.366, 1.093, 0.874, 0.699, 0.559, 0.448, 0.358, 0.286, 0.229, 0.183, 0.147, 0.117, 0.094, 0.075, 0.060, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.168) and 15 (=3.334).\n",
      "Keep 32188/74100 = 43.4% of the coarse cost matrix.\n",
      "Keep 24936/51984 = 48.0% of the coarse cost matrix.\n",
      "Keep 40087/105625 = 38.0% of the coarse cost matrix.\n",
      "OMT matching distance: 11.581701278686523, time elapsed: 2.8693461418151855\n",
      "229x348 clusters, computed at scale = 3.480\n",
      "Successive scales :  75.952, 75.952, 60.762, 48.610, 38.888, 31.110, 24.888, 19.910, 15.928, 12.743, 10.194, 8.155, 6.524, 5.219, 4.176, 3.340, 2.672, 2.138, 1.710, 1.368, 1.095, 0.876, 0.701, 0.560, 0.448, 0.359, 0.287, 0.230, 0.184, 0.147, 0.118, 0.094, 0.075, 0.060, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.176) and 15 (=3.340).\n",
      "Keep 35321/79692 = 44.3% of the coarse cost matrix.\n",
      "Keep 25309/52441 = 48.3% of the coarse cost matrix.\n",
      "Keep 47426/121104 = 39.2% of the coarse cost matrix.\n",
      "OMT matching distance: 12.699905395507812, time elapsed: 7.224475860595703\n",
      "244x395 clusters, computed at scale = 3.316\n",
      "Successive scales :  72.360, 72.360, 57.888, 46.310, 37.048, 29.638, 23.711, 18.969, 15.175, 12.140, 9.712, 7.770, 6.216, 4.973, 3.978, 3.182, 2.546, 2.037, 1.629, 1.304, 1.043, 0.834, 0.667, 0.534, 0.427, 0.342, 0.273, 0.219, 0.175, 0.140, 0.112, 0.090, 0.072, 0.057, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.978) and 15 (=3.182).\n",
      "Keep 40682/96380 = 42.2% of the coarse cost matrix.\n",
      "Keep 26962/59536 = 45.3% of the coarse cost matrix.\n",
      "Keep 59175/156025 = 37.9% of the coarse cost matrix.\n",
      "OMT matching distance: 8.927657127380371, time elapsed: 3.2155492305755615\n",
      "234x339 clusters, computed at scale = 3.392\n",
      "Successive scales :  74.020, 74.020, 59.216, 47.373, 37.898, 30.318, 24.255, 19.404, 15.523, 12.418, 9.935, 7.948, 6.358, 5.087, 4.069, 3.255, 2.604, 2.083, 1.667, 1.333, 1.067, 0.853, 0.683, 0.546, 0.437, 0.350, 0.280, 0.224, 0.179, 0.143, 0.115, 0.092, 0.073, 0.059, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.069) and 15 (=3.255).\n",
      "Keep 33877/79326 = 42.7% of the coarse cost matrix.\n",
      "Keep 26062/54756 = 47.6% of the coarse cost matrix.\n",
      "Keep 42415/114921 = 36.9% of the coarse cost matrix.\n",
      "OMT matching distance: 13.589749336242676, time elapsed: 2.902883291244507\n",
      "250x403 clusters, computed at scale = 3.283\n",
      "Successive scales :  71.641, 71.641, 57.313, 45.850, 36.680, 29.344, 23.475, 18.780, 15.024, 12.019, 9.616, 7.692, 6.154, 4.923, 3.939, 3.151, 2.521, 2.017, 1.613, 1.291, 1.032, 0.826, 0.661, 0.529, 0.423, 0.338, 0.271, 0.217, 0.173, 0.139, 0.111, 0.089, 0.071, 0.057, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.939) and 15 (=3.151).\n",
      "Keep 40936/100750 = 40.6% of the coarse cost matrix.\n",
      "Keep 28066/62500 = 44.9% of the coarse cost matrix.\n",
      "Keep 57505/162409 = 35.4% of the coarse cost matrix.\n",
      "OMT matching distance: 17.345169067382812, time elapsed: 3.268620729446411\n",
      "226x376 clusters, computed at scale = 3.447\n",
      "Successive scales :  75.216, 75.216, 60.173, 48.138, 38.511, 30.809, 24.647, 19.717, 15.774, 12.619, 10.095, 8.076, 6.461, 5.169, 4.135, 3.308, 2.646, 2.117, 1.694, 1.355, 1.084, 0.867, 0.694, 0.555, 0.444, 0.355, 0.284, 0.227, 0.182, 0.145, 0.116, 0.093, 0.074, 0.060, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.135) and 15 (=3.308).\n",
      "Keep 35640/84976 = 41.9% of the coarse cost matrix.\n",
      "Keep 24404/51076 = 47.8% of the coarse cost matrix.\n",
      "Keep 49512/141376 = 35.0% of the coarse cost matrix.\n",
      "OMT matching distance: 15.416260719299316, time elapsed: 2.987980842590332\n",
      "236x375 clusters, computed at scale = 3.341\n",
      "Successive scales :  72.904, 72.904, 58.323, 46.658, 37.327, 29.861, 23.889, 19.111, 15.289, 12.231, 9.785, 7.828, 6.262, 5.010, 4.008, 3.206, 2.565, 2.052, 1.642, 1.313, 1.051, 0.841, 0.672, 0.538, 0.430, 0.344, 0.275, 0.220, 0.176, 0.141, 0.113, 0.090, 0.072, 0.058, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.008) and 15 (=3.206).\n",
      "Keep 36177/88500 = 40.9% of the coarse cost matrix.\n",
      "Keep 25398/55696 = 45.6% of the coarse cost matrix.\n",
      "Keep 49571/140625 = 35.3% of the coarse cost matrix.\n",
      "OMT matching distance: 10.82838249206543, time elapsed: 3.184957981109619\n"
     ]
    }
   ],
   "source": [
    "plab_sample = []\n",
    "for (id, md_i) in md_aff.items():\n",
    "    f_omt, w_omt = match_omt(md_ell.vt, md_ell.ft, md_i.vt, md_i.ft)\n",
    "    lp_omt = vtk_sample_cell_array_at_vertices(md_i.pd, md_i.lp, w_omt.detach().cpu().numpy())\n",
    "    plab_sample.append(lp_omt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "plab_sample_avg = np.stack(plab_sample).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_sphere_opt_2 = vtk_set_cell_array(pd_sphere_opt, 'plab', softmax(plab_sample_avg * 10, axis=1))\n",
    "save_vtk(pd_sphere_opt_2, 'tmp/ellipsoid_best_fit_plab.vtk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the sphere as a starting point for template fitting\n",
    "md_src2 = MeshData(pd_sphere_opt_2, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map an array to new vertex locations\n",
    "def vtk_sample_point_array_at_vertices(pd_src, array, x_samples):\n",
    "    # Use the locator to sample from the halfway mesh\n",
    "    loc = vtk.vtkCellLocator()\n",
    "    loc.SetDataSet(pd_src)\n",
    "    loc.BuildLocator()\n",
    "    result = np.zeros((x_samples.shape[0], array.shape[1]))    \n",
    "    cellId = vtk.reference(0)\n",
    "    c = [0.0, 0.0, 0.0]\n",
    "    subId = vtk.reference(0)\n",
    "    d = vtk.reference(0.0)\n",
    "    pcoord = [0.0, 0.0, 0.0]\n",
    "    wgt = [0.0, 0.0, 0.0]\n",
    "    xj = [0.0, 0.0, 0.0]\n",
    "    for j in range(x_samples.shape[0]):\n",
    "        loc.FindClosestPoint(x_samples[j,:], c, cellId, subId, d)\n",
    "        cell = pd_src.GetCell(cellId)\n",
    "        cell.EvaluatePosition(x_samples[j,:], c, subId, pcoord, d, wgt)\n",
    "        result[j] = np.sum(np.stack([ array[cell.GetPointId(i),:] * w for i, w in enumerate(wgt) ]), 0)\n",
    "    return result\n",
    "\n",
    "\n",
    "# Given a set of sampling locations on a triangle mesh surface, generate arrays of\n",
    "# vertex indices and weights that allow data from the source mesh to be sampled at\n",
    "# the sampling locations. This can be used to interpolate point data, coordinates,\n",
    "# etc from the source mesh or spatial transformations thereof \n",
    "def vtk_get_interpolation_arrays_for_sample(pd_src, x_samples):\n",
    "    \n",
    "    # Use the locator to sample from the halfway mesh\n",
    "    loc = vtk.vtkCellLocator()\n",
    "    loc.SetDataSet(pd_src)\n",
    "    loc.BuildLocator()\n",
    "\n",
    "    # Return data: array of vertex indices and weights\n",
    "    v_res = np.zeros((x_samples.shape[0], 3), dtype=np.int32)\n",
    "    w_res = np.zeros((x_samples.shape[0], 3), dtype=np.double)\n",
    "\n",
    "    cellId = vtk.reference(0)\n",
    "    c = [0.0, 0.0, 0.0]\n",
    "    subId = vtk.reference(0)\n",
    "    d = vtk.reference(0.0)\n",
    "    pcoord = [0.0, 0.0, 0.0]\n",
    "    wgt = [0.0, 0.0, 0.0]\n",
    "    xj = [0.0, 0.0, 0.0]\n",
    "    for j in range(x_samples.shape[0]):\n",
    "        loc.FindClosestPoint(x_samples[j,:], c, cellId, subId, d)\n",
    "        cell = pd_src.GetCell(cellId)\n",
    "        cell.EvaluatePosition(x_samples[j,:], c, subId, pcoord, d, wgt)\n",
    "        for i, w in enumerate(wgt):\n",
    "            v_res[j,i], w_res[j,i] = cell.GetPointId(i), w\n",
    "\n",
    "    return v_res, w_res\n",
    "\n",
    "\n",
    "\n",
    "# Define a function that can fit a model to a population\n",
    "def fit_model_to_population(md_root, md_targets, n_iter = 10, \n",
    "                            sigma_lddmm=5, sigma_root=20, sigma_varifold=5, gamma_lddmm=0.1):\n",
    "\n",
    "    # LDDMM kernels\n",
    "    device = md_root.vt.device\n",
    "    K_root = GaussKernel(sigma=torch.tensor(sigma_root, dtype=torch.float32, device=device))\n",
    "    K_temp = GaussKernel(sigma=torch.tensor(sigma_lddmm, dtype=torch.float32, device=device))\n",
    "    K_vari = GaussLinKernelWithLabels(torch.tensor(sigma_varifold, dtype=torch.float32, device=device), md_root.lp.shape[1])\n",
    "\n",
    "    # Create losses for each of the target meshes\n",
    "    d_loss = { id: lossVarifoldSurfWithLabels(md_root.ft, v.vt, v.ft, md_root.lpt, v.lpt, K_vari) for id,v in md_targets.items() }\n",
    "            \n",
    "    # Create the root->template points/momentum, as well as the template->subject momenta\n",
    "    q_root = torch.tensor(md_root.vt, dtype=torch.float32, device=device, requires_grad=True).contiguous()\n",
    "    p_root = torch.zeros(md_root.vt.shape, dtype=torch.float32, device=device, requires_grad=True).contiguous()\n",
    "    p_temp = torch.zeros((len(md_targets),) + md_root.vt.shape, dtype=torch.float32, device=device, requires_grad=True).contiguous()\n",
    "\n",
    "    # Create the optimizer\n",
    "    start = time.time()\n",
    "    optimizer = torch.optim.LBFGS([p_root, p_temp], max_eval=16, max_iter=16, line_search_fn='strong_wolfe')\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Shoot root->template\n",
    "        _, q_temp = Shooting(p_root, q_root, K_root)[-1]\n",
    "\n",
    "        # Make the momenta applied to the template average out to zero\n",
    "        p_temp_z = p_temp - torch.mean(p_temp, 0, keepdim=True)\n",
    "\n",
    "        # Compute the loss\n",
    "        L = 0\n",
    "        for i, (id,v) in enumerate(md_targets.items()):\n",
    "            _, q_i = Shooting(p_temp_z[i,:], q_temp, K_temp)[-1]\n",
    "            L = L + gamma_lddmm * Hamiltonian(K_temp)(p_temp_z[i,:], q_temp) + d_loss[id](q_i)\n",
    "        L = L / len(md_targets.items())\n",
    "        L.backward()\n",
    "        return L\n",
    "\n",
    "    # Perform optimization\n",
    "    for i in range(n_iter):\n",
    "        print(f'Iteration {i:03d}  Loss {closure()}')\n",
    "        optimizer.step(closure)\n",
    "\n",
    "    print(f'Optimization (L-BFGS) time: {round(time.time() - start, 2)} seconds')\n",
    "\n",
    "    # Return the root model and the momenta\n",
    "    p_temp_z = p_temp - torch.mean(p_temp, 0, keepdim=True)\n",
    "    return p_root, p_temp_z \n",
    "\n",
    "\n",
    "# Compute label probability sampling using shooting and OMT\n",
    "# def map_array_to_fittedect_shooting_omt(q_root, p_root, p_temp, md_targets, array):\n",
    "#     _, q_temp = Shooting(p_root, q_root, K)[-1]\n",
    "#     plab_sample = []\n",
    "#     p_temp_z = p_temp - torch.mean(p_temp, 0, keepdim=True)\n",
    "#     for (id, md_i) in md_aff.items():\n",
    "#         _, q_i = Shooting(p_temp_z[i,:], q_temp, K)[-1]\n",
    "#         f_omt, w_omt = match_omt(q_i, md_src2.ft, md_i.vt, md_i.ft)\n",
    "#         lp_omt = vtk_sample_cell_array_at_vertices(md_i.pd, md_i.lp, w_omt.detach().cpu().numpy())\n",
    "#         plab_sample.append(lp_omt)\n",
    "\n",
    "\n",
    "def shoot_root_to_template(md_root, p_root, sigma_root=20):\n",
    "    device = md_root.vt.device\n",
    "    K_root = GaussKernel(sigma=torch.tensor(sigma_root, dtype=torch.float32, device=device))\n",
    "    _, q_temp = Shooting(p_root, md_root.vt.clone().requires_grad_(True).contiguous(), K_root)[-1]\n",
    "    pd = vtk_make_pd(q_temp.detach().cpu().numpy(), md_root.f)\n",
    "    pd = vtk_set_cell_array(pd, 'plab', md_root.lp)\n",
    "    return MeshData(pd, device=q_temp.device)\n",
    "\n",
    "\n",
    "# Update the template by remeshing and updating probability labels\n",
    "def update_model_by_remeshing(md_root, md_targets, p_root, p_temp_z, \n",
    "                              sigma_lddmm=5, sigma_root=20):\n",
    "\n",
    "    # LDDMM kernels\n",
    "    device = md_root.vt.device\n",
    "    K_root = GaussKernel(sigma=torch.tensor(sigma_root, dtype=torch.float32, device=device))\n",
    "    K_temp = GaussKernel(sigma=torch.tensor(sigma_lddmm, dtype=torch.float32, device=device))\n",
    "\n",
    "    # Shoot from root to obtain the template\n",
    "    q_root = md_root.vt.clone().requires_grad_(True).contiguous()\n",
    "    _, q_temp = Shooting(p_root, q_root, K_root)[-1]\n",
    "    pd_template = vtk_make_pd(q_temp.detach().cpu().numpy(), md_root.f)\n",
    "\n",
    "    # Sample and average the plab array from the subjects using OMT\n",
    "    plab_sample = []\n",
    "    for i, (id, md_i) in enumerate(md_targets.items()):\n",
    "        _, q_i = Shooting(p_temp_z[i,:], q_temp, K_temp)[-1]\n",
    "        _, w_omt = match_omt(q_i, md_root.ft, md_i.vt, md_i.ft)\n",
    "        lp_omt = vtk_sample_cell_array_at_vertices(md_i.pd, md_i.lp, w_omt.detach().cpu().numpy())\n",
    "        plab_sample.append(lp_omt)\n",
    "    plab_sample_avg = np.stack(plab_sample).mean(0)\n",
    "\n",
    "    # Apply remeshing to the template\n",
    "    ms = pymeshlab.MeshSet()\n",
    "    ms.add_mesh(pymeshlab.Mesh(vertex_matrix=q_temp.detach().cpu().numpy(), face_matrix=md_root.f))\n",
    "    ms.meshing_isotropic_explicit_remeshing()\n",
    "    v_remesh, f_remesh = ms.mesh(0).vertex_matrix(), ms.mesh(0).face_matrix()\n",
    "    pd_remesh = vtk_make_pd(v_remesh, f_remesh)\n",
    "\n",
    "    # Apply the remeshing to the plab array\n",
    "    _, w_omt = match_omt(torch.tensor(v_remesh, dtype=torch.float32, device=device), \n",
    "                         torch.tensor(f_remesh, dtype=torch.long, device=device),\n",
    "                         q_temp, md_root.ft)\n",
    "    lp_remesh = vtk_sample_cell_array_at_vertices(pd_template, plab_sample_avg, w_omt.detach().cpu().numpy())\n",
    "    pd_remesh = vtk_set_cell_array(pd_remesh, 'plab', softmax(lp_remesh * 10, 1))\n",
    "\n",
    "    # Return the new template as MeshData\n",
    "    return MeshData(pd_remesh, device=md_root.vt.device)\n",
    "\n",
    "\n",
    "# Map template into subject space and return mesh\n",
    "def map_template_to_subject(md_temp, md_target, p_temp, sigma_lddmm=5):\n",
    "\n",
    "    # LDDMM kernels\n",
    "    device = md_temp.vt.device\n",
    "    K_temp = GaussKernel(sigma=torch.tensor(sigma_lddmm, dtype=torch.float32, device=device))\n",
    "\n",
    "    # Shoot from template to subject and save as polydata/meshdata\n",
    "    q_temp = md_temp.vt.clone().requires_grad_(True).contiguous()\n",
    "    _, q_fitted = Shooting(p_temp, q_temp, K_temp)[-1]\n",
    "    pd_fitted = vtk_make_pd(q_fitted.detach().cpu().numpy(), md_temp.f)\n",
    "    pd_fitted = vtk_set_cell_array(pd_fitted, 'plab', md_temp.lp)\n",
    "\n",
    "    # Match the subject via OMT, i.e. every template vertex is mapped to somewhere on the\n",
    "    # subject mesh, this fits more closely than LDDMM but might break topology\n",
    "    # _, w_omt = match_omt(md_target.vt, md_target.ft, q_fitted, md_temp.ft)\n",
    "    _, w_omt = match_omt(q_fitted, md_temp.ft, md_target.vt, md_target.ft)\n",
    "    pd_omt = vtk_clone_pd(pd_fitted)\n",
    "    pd_omt = vtk_set_cell_array(pd_omt, 'match', w_omt.detach().cpu().numpy())\n",
    "    vtk_cell_array_to_point_array(pd_omt, 'match')\n",
    "    v_omt = vtk_get_point_array(pd_omt, 'match')\n",
    "\n",
    "    # Create a clean model to return\n",
    "    pd_omt = vtk_make_pd(v_omt, md_temp.f)\n",
    "    pd_omt = vtk_set_cell_array(pd_omt, 'plab', md_temp.lp)\n",
    "    pd_omt = vtk_set_cell_array(pd_omt, 'match', w_omt.detach().cpu().numpy())\n",
    "\n",
    "    # Get the interpolation arrays from the matching and place them into the fitted template\n",
    "    v_int, w_int = vtk_get_interpolation_arrays_for_sample(md_target.pd, v_omt)\n",
    "    pd_fitted = vtk_set_point_array(pd_fitted, 'omt_v_int', v_int)\n",
    "    pd_fitted = vtk_set_point_array(pd_fitted, 'omt_w_int', w_int)\n",
    "\n",
    "    return pd_fitted, pd_omt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_template_multistage(md_root, md_targets, schedule, \n",
    "                              sigma_lddmm=5, sigma_root=20, sigma_varifold=5,\n",
    "                              gamma_lddmm=0.1):\n",
    "\n",
    "    # Iterate over the schedule\n",
    "    for i, iter in enumerate(schedule):\n",
    "\n",
    "        # Print iteration\n",
    "        print(f'*** TEMPLATE BUILD STAGE {i} ***')\n",
    "\n",
    "        # Fit the model to the population\n",
    "        p_root, p_temp_z = fit_model_to_population(md_root, md_targets, iter,\n",
    "                                                   sigma_lddmm=sigma_lddmm, sigma_root=sigma_root, \n",
    "                                                   sigma_varifold=sigma_varifold, gamma_lddmm=gamma_lddmm)\n",
    "\n",
    "        # Compute the template by forward shooting\n",
    "        md_temp = shoot_root_to_template(md_root, p_root, sigma_root=sigma_root)\n",
    "        save_vtk(md_temp.pd, f'tmp/template_iter{i:02d}.vtk')\n",
    "\n",
    "        # Remesh the template\n",
    "        md_remesh = update_model_by_remeshing(md_root, md_targets, p_root, p_temp_z, sigma_lddmm=sigma_lddmm, sigma_root=sigma_root)\n",
    "        save_vtk(md_remesh.pd, f'tmp/template_iter{i:02d}_remesh.vtk')\n",
    "\n",
    "        # Make the template the new root\n",
    "        md_root = md_remesh\n",
    "\n",
    "    # Return the model from the last iteration\n",
    "    return md_temp, p_temp_z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template['left'].get_lddmm_gamma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TEMPLATE BUILD STAGE 0 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_476292/2053768558.py:70: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 000  Loss 73180.25\n",
      "Iteration 001  Loss 48189.68359375\n",
      "Iteration 002  Loss 32612.52734375\n",
      "Iteration 003  Loss 24865.779296875\n",
      "Iteration 004  Loss 20050.994140625\n",
      "Iteration 005  Loss 16614.220703125\n",
      "Iteration 006  Loss 13710.7568359375\n",
      "Iteration 007  Loss 11285.1953125\n",
      "Iteration 008  Loss 10152.326171875\n",
      "Iteration 009  Loss 9215.896484375\n",
      "Optimization (L-BFGS) time: 511.72 seconds\n",
      "356x409 clusters, computed at scale = 3.313\n",
      "Successive scales :  72.302, 72.302, 57.842, 46.274, 37.019, 29.615, 23.692, 18.954, 15.163, 12.130, 9.704, 7.763, 6.211, 4.969, 3.975, 3.180, 2.544, 2.035, 1.628, 1.302, 1.042, 0.834, 0.667, 0.533, 0.427, 0.341, 0.273, 0.219, 0.175, 0.140, 0.112, 0.090, 0.072, 0.057, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.975) and 15 (=3.180).\n",
      "Keep 51769/145604 = 35.6% of the coarse cost matrix.\n",
      "Keep 46330/126736 = 36.6% of the coarse cost matrix.\n",
      "Keep 57027/167281 = 34.1% of the coarse cost matrix.\n",
      "OMT matching distance: 2.1946306228637695, time elapsed: 3.743993043899536\n",
      "405x458 clusters, computed at scale = 3.146\n",
      "Successive scales :  68.658, 68.658, 54.926, 43.941, 35.153, 28.122, 22.498, 17.998, 14.399, 11.519, 9.215, 7.372, 5.898, 4.718, 3.774, 3.020, 2.416, 1.933, 1.546, 1.237, 0.989, 0.792, 0.633, 0.507, 0.405, 0.324, 0.259, 0.208, 0.166, 0.133, 0.106, 0.085, 0.068, 0.054, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.774) and 15 (=3.020).\n",
      "Keep 64759/185490 = 34.9% of the coarse cost matrix.\n",
      "Keep 56899/164025 = 34.7% of the coarse cost matrix.\n",
      "Keep 72628/209764 = 34.6% of the coarse cost matrix.\n",
      "OMT matching distance: 1.75980806350708, time elapsed: 4.235213279724121\n",
      "367x389 clusters, computed at scale = 3.394\n",
      "Successive scales :  74.062, 74.062, 59.250, 47.400, 37.920, 30.336, 24.269, 19.415, 15.532, 12.426, 9.940, 7.952, 6.362, 5.090, 4.072, 3.257, 2.606, 2.085, 1.668, 1.334, 1.067, 0.854, 0.683, 0.546, 0.437, 0.350, 0.280, 0.224, 0.179, 0.143, 0.115, 0.092, 0.073, 0.059, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.072) and 15 (=3.257).\n",
      "Keep 53235/142763 = 37.3% of the coarse cost matrix.\n",
      "Keep 51243/134689 = 38.0% of the coarse cost matrix.\n",
      "Keep 54849/151321 = 36.2% of the coarse cost matrix.\n",
      "OMT matching distance: 2.1588587760925293, time elapsed: 3.778752088546753\n",
      "328x337 clusters, computed at scale = 3.363\n",
      "Successive scales :  73.398, 73.398, 58.718, 46.975, 37.580, 30.064, 24.051, 19.241, 15.393, 12.314, 9.851, 7.881, 6.305, 5.044, 4.035, 3.228, 2.582, 2.066, 1.653, 1.322, 1.058, 0.846, 0.677, 0.542, 0.433, 0.347, 0.277, 0.222, 0.177, 0.142, 0.114, 0.091, 0.073, 0.058, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.035) and 15 (=3.228).\n",
      "Keep 40516/110536 = 36.7% of the coarse cost matrix.\n",
      "Keep 39910/107584 = 37.1% of the coarse cost matrix.\n",
      "Keep 41053/113569 = 36.1% of the coarse cost matrix.\n",
      "OMT matching distance: 0.284898579120636, time elapsed: 3.321169376373291\n",
      "422x471 clusters, computed at scale = 2.986\n",
      "Successive scales :  65.159, 65.159, 52.127, 41.701, 33.361, 26.689, 21.351, 17.081, 13.665, 10.932, 8.745, 6.996, 5.597, 4.478, 3.582, 2.866, 2.293, 1.834, 1.467, 1.174, 0.939, 0.751, 0.601, 0.481, 0.385, 0.308, 0.246, 0.197, 0.158, 0.126, 0.101, 0.081, 0.065, 0.052, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.582) and 15 (=2.866).\n",
      "Keep 67235/198762 = 33.8% of the coarse cost matrix.\n",
      "Keep 60540/178084 = 34.0% of the coarse cost matrix.\n",
      "Keep 73863/221841 = 33.3% of the coarse cost matrix.\n",
      "OMT matching distance: 0.9430001974105835, time elapsed: 4.3215861320495605\n",
      "308x368 clusters, computed at scale = 3.489\n",
      "Successive scales :  76.132, 76.132, 60.905, 48.724, 38.979, 31.184, 24.947, 19.957, 15.966, 12.773, 10.218, 8.175, 6.540, 5.232, 4.185, 3.348, 2.679, 2.143, 1.714, 1.371, 1.097, 0.878, 0.702, 0.562, 0.449, 0.360, 0.288, 0.230, 0.184, 0.147, 0.118, 0.094, 0.075, 0.060, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.185) and 15 (=3.348).\n",
      "Keep 43601/113344 = 38.5% of the coarse cost matrix.\n",
      "Keep 38112/94864 = 40.2% of the coarse cost matrix.\n",
      "Keep 49272/135424 = 36.4% of the coarse cost matrix.\n",
      "OMT matching distance: 2.2554049491882324, time elapsed: 3.323336601257324\n",
      "298x319 clusters, computed at scale = 3.484\n",
      "Successive scales :  76.023, 76.023, 60.818, 48.655, 38.924, 31.139, 24.911, 19.929, 15.943, 12.754, 10.204, 8.163, 6.530, 5.224, 4.179, 3.344, 2.675, 2.140, 1.712, 1.370, 1.096, 0.876, 0.701, 0.561, 0.449, 0.359, 0.287, 0.230, 0.184, 0.147, 0.118, 0.094, 0.075, 0.060, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.179) and 15 (=3.344).\n",
      "Keep 36997/95062 = 38.9% of the coarse cost matrix.\n",
      "Keep 35198/88804 = 39.6% of the coarse cost matrix.\n",
      "Keep 38493/101761 = 37.8% of the coarse cost matrix.\n",
      "OMT matching distance: 1.5783395767211914, time elapsed: 3.127448081970215\n",
      "341x361 clusters, computed at scale = 3.383\n",
      "Successive scales :  73.819, 73.819, 59.055, 47.244, 37.795, 30.236, 24.189, 19.351, 15.481, 12.385, 9.908, 7.926, 6.341, 5.073, 4.058, 3.247, 2.597, 2.078, 1.662, 1.330, 1.064, 0.851, 0.681, 0.545, 0.436, 0.349, 0.279, 0.223, 0.178, 0.143, 0.114, 0.091, 0.073, 0.058, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.058) and 15 (=3.247).\n",
      "Keep 47525/123101 = 38.6% of the coarse cost matrix.\n",
      "Keep 45499/116281 = 39.1% of the coarse cost matrix.\n",
      "Keep 49625/130321 = 38.1% of the coarse cost matrix.\n",
      "OMT matching distance: 0.6254472732543945, time elapsed: 3.507154703140259\n",
      "342x395 clusters, computed at scale = 3.316\n",
      "Successive scales :  72.360, 72.360, 57.888, 46.310, 37.048, 29.638, 23.711, 18.969, 15.175, 12.140, 9.712, 7.770, 6.216, 4.973, 3.978, 3.182, 2.546, 2.037, 1.629, 1.304, 1.043, 0.834, 0.667, 0.534, 0.427, 0.342, 0.273, 0.219, 0.175, 0.140, 0.112, 0.090, 0.072, 0.057, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.978) and 15 (=3.182).\n",
      "Keep 52092/135090 = 38.6% of the coarse cost matrix.\n",
      "Keep 45668/116964 = 39.0% of the coarse cost matrix.\n",
      "Keep 59175/156025 = 37.9% of the coarse cost matrix.\n",
      "OMT matching distance: 0.629435658454895, time elapsed: 3.7832541465759277\n",
      "311x335 clusters, computed at scale = 3.395\n",
      "Successive scales :  74.082, 74.082, 59.266, 47.413, 37.930, 30.344, 24.275, 19.420, 15.536, 12.429, 9.943, 7.955, 6.364, 5.091, 4.073, 3.258, 2.607, 2.085, 1.668, 1.335, 1.068, 0.854, 0.683, 0.547, 0.437, 0.350, 0.280, 0.224, 0.179, 0.143, 0.115, 0.092, 0.073, 0.059, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.073) and 15 (=3.258).\n",
      "Keep 39167/104185 = 37.6% of the coarse cost matrix.\n",
      "Keep 36879/96721 = 38.1% of the coarse cost matrix.\n",
      "Keep 41439/112225 = 36.9% of the coarse cost matrix.\n",
      "OMT matching distance: 1.1088881492614746, time elapsed: 3.2756259441375732\n",
      "366x408 clusters, computed at scale = 3.289\n",
      "Successive scales :  71.766, 71.766, 57.413, 45.930, 36.744, 29.395, 23.516, 18.813, 15.050, 12.040, 9.632, 7.706, 6.165, 4.932, 3.945, 3.156, 2.525, 2.020, 1.616, 1.293, 1.034, 0.827, 0.662, 0.530, 0.424, 0.339, 0.271, 0.217, 0.174, 0.139, 0.111, 0.089, 0.071, 0.057, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.945) and 15 (=3.156).\n",
      "Keep 54097/149328 = 36.2% of the coarse cost matrix.\n",
      "Keep 49434/133956 = 36.9% of the coarse cost matrix.\n",
      "Keep 58978/166464 = 35.4% of the coarse cost matrix.\n",
      "OMT matching distance: 0.6391966342926025, time elapsed: 3.9263699054718018\n",
      "339x384 clusters, computed at scale = 3.415\n",
      "Successive scales :  74.522, 74.522, 59.617, 47.694, 38.155, 30.524, 24.419, 19.535, 15.628, 12.503, 10.002, 8.002, 6.401, 5.121, 4.097, 3.277, 2.622, 2.098, 1.678, 1.342, 1.074, 0.859, 0.687, 0.550, 0.440, 0.352, 0.282, 0.225, 0.180, 0.144, 0.115, 0.092, 0.074, 0.059, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.097) and 15 (=3.277).\n",
      "Keep 46777/130176 = 35.9% of the coarse cost matrix.\n",
      "Keep 42645/114921 = 37.1% of the coarse cost matrix.\n",
      "Keep 50966/147456 = 34.6% of the coarse cost matrix.\n",
      "OMT matching distance: 1.175171971321106, time elapsed: 3.5874710083007812\n",
      "344x374 clusters, computed at scale = 3.341\n",
      "Successive scales :  72.908, 72.908, 58.326, 46.661, 37.329, 29.863, 23.890, 19.112, 15.290, 12.232, 9.786, 7.828, 6.263, 5.010, 4.008, 3.207, 2.565, 2.052, 1.642, 1.313, 1.051, 0.841, 0.672, 0.538, 0.430, 0.344, 0.275, 0.220, 0.176, 0.141, 0.113, 0.090, 0.072, 0.058, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.008) and 15 (=3.207).\n",
      "Keep 46244/128656 = 35.9% of the coarse cost matrix.\n",
      "Keep 43284/118336 = 36.6% of the coarse cost matrix.\n",
      "Keep 49302/139876 = 35.2% of the coarse cost matrix.\n",
      "OMT matching distance: 0.5192858576774597, time elapsed: 3.758814573287964\n",
      "373x374 clusters, computed at scale = 2.871\n",
      "Successive scales :  62.646, 62.646, 50.117, 40.093, 32.075, 25.660, 20.528, 16.422, 13.138, 10.510, 8.408, 6.727, 5.381, 4.305, 3.444, 2.755, 2.204, 1.763, 1.411, 1.129, 0.903, 0.722, 0.578, 0.462, 0.370, 0.296, 0.237, 0.189, 0.151, 0.121, 0.097, 0.078, 0.062, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.444) and 15 (=2.755).\n",
      "Keep 47837/139502 = 34.3% of the coarse cost matrix.\n",
      "Keep 47833/139129 = 34.4% of the coarse cost matrix.\n",
      "Keep 47856/139876 = 34.2% of the coarse cost matrix.\n",
      "OMT matching distance: 0.01980762369930744, time elapsed: 3.482186794281006\n",
      "*** TEMPLATE BUILD STAGE 1 ***\n",
      "Iteration 000  Loss 54708.515625\n",
      "Iteration 001  Loss 39302.20703125\n",
      "Iteration 002  Loss 28447.169921875\n",
      "Iteration 003  Loss 21464.443359375\n",
      "Iteration 004  Loss 16580.95703125\n",
      "Iteration 005  Loss 13691.2314453125\n",
      "Iteration 006  Loss 11089.1953125\n",
      "Iteration 007  Loss 9426.75\n",
      "Iteration 008  Loss 8582.412109375\n",
      "Iteration 009  Loss 7926.3662109375\n",
      "Optimization (L-BFGS) time: 512.77 seconds\n",
      "356x403 clusters, computed at scale = 3.320\n",
      "Successive scales :  72.443, 72.443, 57.955, 46.364, 37.091, 29.673, 23.738, 18.991, 15.193, 12.154, 9.723, 7.779, 6.223, 4.978, 3.983, 3.186, 2.549, 2.039, 1.631, 1.305, 1.044, 0.835, 0.668, 0.535, 0.428, 0.342, 0.274, 0.219, 0.175, 0.140, 0.112, 0.090, 0.072, 0.057, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.983) and 15 (=3.186).\n",
      "Keep 51088/143468 = 35.6% of the coarse cost matrix.\n",
      "Keep 46262/126736 = 36.5% of the coarse cost matrix.\n",
      "Keep 55743/162409 = 34.3% of the coarse cost matrix.\n",
      "OMT matching distance: 2.2918434143066406, time elapsed: 3.729529619216919\n",
      "389x457 clusters, computed at scale = 3.141\n",
      "Successive scales :  68.538, 68.538, 54.830, 43.864, 35.091, 28.073, 22.458, 17.967, 14.373, 11.499, 9.199, 7.359, 5.887, 4.710, 3.768, 3.014, 2.411, 1.929, 1.543, 1.235, 0.988, 0.790, 0.632, 0.506, 0.405, 0.324, 0.259, 0.207, 0.166, 0.133, 0.106, 0.085, 0.068, 0.054, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.768) and 15 (=3.014).\n",
      "Keep 62895/177773 = 35.4% of the coarse cost matrix.\n",
      "Keep 53825/151321 = 35.6% of the coarse cost matrix.\n",
      "Keep 72339/208849 = 34.6% of the coarse cost matrix.\n",
      "OMT matching distance: 2.2744247913360596, time elapsed: 4.124557733535767\n",
      "355x391 clusters, computed at scale = 3.384\n",
      "Successive scales :  73.857, 73.857, 59.086, 47.269, 37.815, 30.252, 24.202, 19.361, 15.489, 12.391, 9.913, 7.930, 6.344, 5.075, 4.060, 3.248, 2.599, 2.079, 1.663, 1.330, 1.064, 0.852, 0.681, 0.545, 0.436, 0.349, 0.279, 0.223, 0.179, 0.143, 0.114, 0.091, 0.073, 0.059, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.060) and 15 (=3.248).\n",
      "Keep 51633/138805 = 37.2% of the coarse cost matrix.\n",
      "Keep 48169/126025 = 38.2% of the coarse cost matrix.\n",
      "Keep 55117/152881 = 36.1% of the coarse cost matrix.\n",
      "OMT matching distance: 2.1098766326904297, time elapsed: 3.8576009273529053\n",
      "323x337 clusters, computed at scale = 3.370\n",
      "Successive scales :  73.533, 73.533, 58.827, 47.061, 37.649, 30.119, 24.095, 19.276, 15.421, 12.337, 9.869, 7.896, 6.316, 5.053, 4.043, 3.234, 2.587, 2.070, 1.656, 1.325, 1.060, 0.848, 0.678, 0.543, 0.434, 0.347, 0.278, 0.222, 0.178, 0.142, 0.114, 0.091, 0.073, 0.058, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.043) and 15 (=3.234).\n",
      "Keep 40012/108851 = 36.8% of the coarse cost matrix.\n",
      "Keep 38941/104329 = 37.3% of the coarse cost matrix.\n",
      "Keep 41155/113569 = 36.2% of the coarse cost matrix.\n",
      "OMT matching distance: 0.23738962411880493, time elapsed: 3.4994494915008545\n",
      "429x467 clusters, computed at scale = 3.008\n",
      "Successive scales :  65.641, 65.641, 52.512, 42.010, 33.608, 26.886, 21.509, 17.207, 13.766, 11.013, 8.810, 7.048, 5.638, 4.511, 3.609, 2.887, 2.310, 1.848, 1.478, 1.182, 0.946, 0.757, 0.605, 0.484, 0.387, 0.310, 0.248, 0.198, 0.159, 0.127, 0.102, 0.081, 0.065, 0.052, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.609) and 15 (=2.887).\n",
      "Keep 68230/200343 = 34.1% of the coarse cost matrix.\n",
      "Keep 63173/184041 = 34.3% of the coarse cost matrix.\n",
      "Keep 73167/218089 = 33.5% of the coarse cost matrix.\n",
      "OMT matching distance: 0.8445049524307251, time elapsed: 4.4026939868927\n",
      "312x368 clusters, computed at scale = 3.491\n",
      "Successive scales :  76.174, 76.174, 60.939, 48.751, 39.001, 31.201, 24.961, 19.968, 15.975, 12.780, 10.224, 8.179, 6.543, 5.235, 4.188, 3.350, 2.680, 2.144, 1.715, 1.372, 1.098, 0.878, 0.703, 0.562, 0.450, 0.360, 0.288, 0.230, 0.184, 0.147, 0.118, 0.094, 0.075, 0.060, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.188) and 15 (=3.350).\n",
      "Keep 43849/114816 = 38.2% of the coarse cost matrix.\n",
      "Keep 38552/97344 = 39.6% of the coarse cost matrix.\n",
      "Keep 49440/135424 = 36.5% of the coarse cost matrix.\n",
      "OMT matching distance: 1.8380987644195557, time elapsed: 3.4242022037506104\n",
      "303x317 clusters, computed at scale = 3.488\n",
      "Successive scales :  76.117, 76.117, 60.894, 48.715, 38.972, 31.178, 24.942, 19.954, 15.963, 12.770, 10.216, 8.173, 6.538, 5.231, 4.185, 3.348, 2.678, 2.143, 1.714, 1.371, 1.097, 0.878, 0.702, 0.562, 0.449, 0.359, 0.288, 0.230, 0.184, 0.147, 0.118, 0.094, 0.075, 0.060, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.185) and 15 (=3.348).\n",
      "Keep 37415/96051 = 39.0% of the coarse cost matrix.\n",
      "Keep 36367/91809 = 39.6% of the coarse cost matrix.\n",
      "Keep 38111/100489 = 37.9% of the coarse cost matrix.\n",
      "OMT matching distance: 1.5981051921844482, time elapsed: 3.229661464691162\n",
      "343x361 clusters, computed at scale = 3.383\n",
      "Successive scales :  73.819, 73.819, 59.055, 47.244, 37.795, 30.236, 24.189, 19.351, 15.481, 12.385, 9.908, 7.926, 6.341, 5.073, 4.058, 3.247, 2.597, 2.078, 1.662, 1.330, 1.064, 0.851, 0.681, 0.545, 0.436, 0.349, 0.279, 0.223, 0.178, 0.143, 0.114, 0.091, 0.073, 0.058, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.058) and 15 (=3.247).\n",
      "Keep 47718/123823 = 38.5% of the coarse cost matrix.\n",
      "Keep 45787/117649 = 38.9% of the coarse cost matrix.\n",
      "Keep 49625/130321 = 38.1% of the coarse cost matrix.\n",
      "OMT matching distance: 0.7385166883468628, time elapsed: 3.455770254135132\n",
      "350x395 clusters, computed at scale = 3.316\n",
      "Successive scales :  72.369, 72.369, 57.896, 46.316, 37.053, 29.643, 23.714, 18.971, 15.177, 12.142, 9.713, 7.771, 6.216, 4.973, 3.979, 3.183, 2.546, 2.037, 1.630, 1.304, 1.043, 0.834, 0.667, 0.534, 0.427, 0.342, 0.273, 0.219, 0.175, 0.140, 0.112, 0.090, 0.072, 0.057, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.979) and 15 (=3.183).\n",
      "Keep 53147/138250 = 38.4% of the coarse cost matrix.\n",
      "Keep 47600/122500 = 38.9% of the coarse cost matrix.\n",
      "Keep 59163/156025 = 37.9% of the coarse cost matrix.\n",
      "OMT matching distance: 0.4905232787132263, time elapsed: 3.7039525508880615\n",
      "305x334 clusters, computed at scale = 3.397\n",
      "Successive scales :  74.135, 74.135, 59.308, 47.446, 37.957, 30.366, 24.292, 19.434, 15.547, 12.438, 9.950, 7.960, 6.368, 5.094, 4.076, 3.260, 2.608, 2.087, 1.669, 1.335, 1.068, 0.855, 0.684, 0.547, 0.438, 0.350, 0.280, 0.224, 0.179, 0.143, 0.115, 0.092, 0.073, 0.059, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.076) and 15 (=3.260).\n",
      "Keep 38510/101870 = 37.8% of the coarse cost matrix.\n",
      "Keep 35899/93025 = 38.6% of the coarse cost matrix.\n",
      "Keep 41130/111556 = 36.9% of the coarse cost matrix.\n",
      "OMT matching distance: 1.1766438484191895, time elapsed: 3.1612439155578613\n",
      "372x407 clusters, computed at scale = 3.288\n",
      "Successive scales :  71.759, 71.759, 57.407, 45.926, 36.741, 29.392, 23.514, 18.811, 15.049, 12.039, 9.631, 7.705, 6.164, 4.931, 3.945, 3.156, 2.525, 2.020, 1.616, 1.293, 1.034, 0.827, 0.662, 0.529, 0.424, 0.339, 0.271, 0.217, 0.174, 0.139, 0.111, 0.089, 0.071, 0.057, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.945) and 15 (=3.156).\n",
      "Keep 54774/151404 = 36.2% of the coarse cost matrix.\n",
      "Keep 50994/138384 = 36.8% of the coarse cost matrix.\n",
      "Keep 58679/165649 = 35.4% of the coarse cost matrix.\n",
      "OMT matching distance: 0.511993408203125, time elapsed: 3.8122012615203857\n",
      "332x383 clusters, computed at scale = 3.424\n",
      "Successive scales :  74.727, 74.727, 59.781, 47.825, 38.260, 30.608, 24.486, 19.589, 15.671, 12.537, 10.030, 8.024, 6.419, 5.135, 4.108, 3.287, 2.629, 2.103, 1.683, 1.346, 1.077, 0.862, 0.689, 0.551, 0.441, 0.353, 0.282, 0.226, 0.181, 0.145, 0.116, 0.093, 0.074, 0.059, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.108) and 15 (=3.287).\n",
      "Keep 45499/127156 = 35.8% of the coarse cost matrix.\n",
      "Keep 40216/110224 = 36.5% of the coarse cost matrix.\n",
      "Keep 51257/146689 = 34.9% of the coarse cost matrix.\n",
      "OMT matching distance: 1.467808485031128, time elapsed: 3.5208351612091064\n",
      "347x377 clusters, computed at scale = 3.336\n",
      "Successive scales :  72.791, 72.791, 58.233, 46.586, 37.269, 29.815, 23.852, 19.082, 15.265, 12.212, 9.770, 7.816, 6.253, 5.002, 4.002, 3.201, 2.561, 2.049, 1.639, 1.311, 1.049, 0.839, 0.671, 0.537, 0.430, 0.344, 0.275, 0.220, 0.176, 0.141, 0.113, 0.090, 0.072, 0.058, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.002) and 15 (=3.201).\n",
      "Keep 47348/130819 = 36.2% of the coarse cost matrix.\n",
      "Keep 44667/120409 = 37.1% of the coarse cost matrix.\n",
      "Keep 50043/142129 = 35.2% of the coarse cost matrix.\n",
      "OMT matching distance: 0.8003249168395996, time elapsed: 3.8811490535736084\n",
      "360x360 clusters, computed at scale = 2.950\n",
      "Successive scales :  64.372, 64.372, 51.498, 41.198, 32.959, 26.367, 21.094, 16.875, 13.500, 10.800, 8.640, 6.912, 5.530, 4.424, 3.539, 2.831, 2.265, 1.812, 1.450, 1.160, 0.928, 0.742, 0.594, 0.475, 0.380, 0.304, 0.243, 0.195, 0.156, 0.125, 0.100, 0.080, 0.064, 0.051, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.539) and 15 (=2.831).\n",
      "Keep 45445/129600 = 35.1% of the coarse cost matrix.\n",
      "Keep 45484/129600 = 35.1% of the coarse cost matrix.\n",
      "Keep 45372/129600 = 35.0% of the coarse cost matrix.\n",
      "OMT matching distance: 0.012269124388694763, time elapsed: 3.6285345554351807\n",
      "*** TEMPLATE BUILD STAGE 2 ***\n",
      "Iteration 000  Loss 51082.1796875\n",
      "Iteration 001  Loss 35499.59375\n",
      "Iteration 002  Loss 24800.97265625\n",
      "Iteration 003  Loss 19217.783203125\n",
      "Iteration 004  Loss 15542.744140625\n",
      "Iteration 005  Loss 12876.6376953125\n",
      "Iteration 006  Loss 10837.59765625\n",
      "Iteration 007  Loss 9231.9365234375\n",
      "Iteration 008  Loss 8500.7333984375\n",
      "Iteration 009  Loss 7719.36376953125\n",
      "Optimization (L-BFGS) time: 500.06 seconds\n",
      "360x412 clusters, computed at scale = 3.307\n",
      "Successive scales :  72.168, 72.168, 57.734, 46.188, 36.950, 29.560, 23.648, 18.918, 15.135, 12.108, 9.686, 7.749, 6.199, 4.959, 3.967, 3.174, 2.539, 2.031, 1.625, 1.300, 1.040, 0.832, 0.666, 0.533, 0.426, 0.341, 0.273, 0.218, 0.174, 0.140, 0.112, 0.089, 0.071, 0.057, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.967) and 15 (=3.174).\n",
      "Keep 52612/148320 = 35.5% of the coarse cost matrix.\n",
      "Keep 47304/129600 = 36.5% of the coarse cost matrix.\n",
      "Keep 57842/169744 = 34.1% of the coarse cost matrix.\n",
      "OMT matching distance: 2.256169319152832, time elapsed: 3.886906147003174\n",
      "390x456 clusters, computed at scale = 3.141\n",
      "Successive scales :  68.550, 68.550, 54.840, 43.872, 35.098, 28.078, 22.463, 17.970, 14.376, 11.501, 9.201, 7.361, 5.888, 4.711, 3.769, 3.015, 2.412, 1.930, 1.544, 1.235, 0.988, 0.790, 0.632, 0.506, 0.405, 0.324, 0.259, 0.207, 0.166, 0.133, 0.106, 0.085, 0.068, 0.054, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.769) and 15 (=3.015).\n",
      "Keep 62857/177840 = 35.3% of the coarse cost matrix.\n",
      "Keep 54212/152100 = 35.6% of the coarse cost matrix.\n",
      "Keep 71914/207936 = 34.6% of the coarse cost matrix.\n",
      "OMT matching distance: 2.313028335571289, time elapsed: 4.437098026275635\n",
      "348x394 clusters, computed at scale = 3.377\n",
      "Successive scales :  73.698, 73.698, 58.959, 47.167, 37.734, 30.187, 24.149, 19.320, 15.456, 12.365, 9.892, 7.913, 6.331, 5.065, 4.052, 3.241, 2.593, 2.074, 1.660, 1.328, 1.062, 0.850, 0.680, 0.544, 0.435, 0.348, 0.278, 0.223, 0.178, 0.143, 0.114, 0.091, 0.073, 0.058, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.052) and 15 (=3.241).\n",
      "Keep 50958/137112 = 37.2% of the coarse cost matrix.\n",
      "Keep 46320/121104 = 38.2% of the coarse cost matrix.\n",
      "Keep 55730/155236 = 35.9% of the coarse cost matrix.\n",
      "OMT matching distance: 2.080552101135254, time elapsed: 3.7890377044677734\n",
      "312x337 clusters, computed at scale = 3.365\n",
      "Successive scales :  73.430, 73.430, 58.744, 46.995, 37.596, 30.077, 24.062, 19.249, 15.399, 12.319, 9.856, 7.884, 6.308, 5.046, 4.037, 3.229, 2.584, 2.067, 1.653, 1.323, 1.058, 0.847, 0.677, 0.542, 0.433, 0.347, 0.277, 0.222, 0.178, 0.142, 0.114, 0.091, 0.073, 0.058, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.037) and 15 (=3.229).\n",
      "Keep 38545/105144 = 36.7% of the coarse cost matrix.\n",
      "Keep 36192/97344 = 37.2% of the coarse cost matrix.\n",
      "Keep 41051/113569 = 36.1% of the coarse cost matrix.\n",
      "OMT matching distance: 0.2758874297142029, time elapsed: 3.218036413192749\n",
      "422x461 clusters, computed at scale = 3.013\n",
      "Successive scales :  65.741, 65.741, 52.593, 42.074, 33.659, 26.928, 21.542, 17.234, 13.787, 11.030, 8.824, 7.059, 5.647, 4.518, 3.614, 2.891, 2.313, 1.850, 1.480, 1.184, 0.947, 0.758, 0.606, 0.485, 0.388, 0.310, 0.248, 0.199, 0.159, 0.127, 0.102, 0.081, 0.065, 0.052, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.614) and 15 (=2.891).\n",
      "Keep 66722/194542 = 34.3% of the coarse cost matrix.\n",
      "Keep 62068/178084 = 34.9% of the coarse cost matrix.\n",
      "Keep 71301/212521 = 33.6% of the coarse cost matrix.\n",
      "OMT matching distance: 0.8929653167724609, time elapsed: 4.282342195510864\n",
      "310x368 clusters, computed at scale = 3.490\n",
      "Successive scales :  76.162, 76.162, 60.930, 48.744, 38.995, 31.196, 24.957, 19.965, 15.972, 12.778, 10.222, 8.178, 6.542, 5.234, 4.187, 3.350, 2.680, 2.144, 1.715, 1.372, 1.098, 0.878, 0.702, 0.562, 0.450, 0.360, 0.288, 0.230, 0.184, 0.147, 0.118, 0.094, 0.075, 0.060, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.187) and 15 (=3.350).\n",
      "Keep 43326/114080 = 38.0% of the coarse cost matrix.\n",
      "Keep 37726/96100 = 39.3% of the coarse cost matrix.\n",
      "Keep 49432/135424 = 36.5% of the coarse cost matrix.\n",
      "OMT matching distance: 1.755637288093567, time elapsed: 3.3796494007110596\n",
      "298x321 clusters, computed at scale = 3.483\n",
      "Successive scales :  76.000, 76.000, 60.800, 48.640, 38.912, 31.130, 24.904, 19.923, 15.938, 12.751, 10.201, 8.160, 6.528, 5.223, 4.178, 3.343, 2.674, 2.139, 1.711, 1.369, 1.095, 0.876, 0.701, 0.561, 0.449, 0.359, 0.287, 0.230, 0.184, 0.147, 0.118, 0.094, 0.075, 0.060, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.178) and 15 (=3.343).\n",
      "Keep 37248/95658 = 38.9% of the coarse cost matrix.\n",
      "Keep 35192/88804 = 39.6% of the coarse cost matrix.\n",
      "Keep 39065/103041 = 37.9% of the coarse cost matrix.\n",
      "OMT matching distance: 1.5611718893051147, time elapsed: 3.099738597869873\n",
      "342x361 clusters, computed at scale = 3.383\n",
      "Successive scales :  73.819, 73.819, 59.055, 47.244, 37.795, 30.236, 24.189, 19.351, 15.481, 12.385, 9.908, 7.926, 6.341, 5.073, 4.058, 3.247, 2.597, 2.078, 1.662, 1.330, 1.064, 0.851, 0.681, 0.545, 0.436, 0.349, 0.279, 0.223, 0.178, 0.143, 0.114, 0.091, 0.073, 0.058, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.058) and 15 (=3.247).\n",
      "Keep 47953/123462 = 38.8% of the coarse cost matrix.\n",
      "Keep 46176/116964 = 39.5% of the coarse cost matrix.\n",
      "Keep 49625/130321 = 38.1% of the coarse cost matrix.\n",
      "OMT matching distance: 0.6648587584495544, time elapsed: 3.5484280586242676\n",
      "353x395 clusters, computed at scale = 3.316\n",
      "Successive scales :  72.360, 72.360, 57.888, 46.310, 37.048, 29.638, 23.711, 18.969, 15.175, 12.140, 9.712, 7.770, 6.216, 4.973, 3.978, 3.182, 2.546, 2.037, 1.629, 1.304, 1.043, 0.834, 0.667, 0.534, 0.427, 0.342, 0.273, 0.219, 0.175, 0.140, 0.112, 0.090, 0.072, 0.057, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.978) and 15 (=3.182).\n",
      "Keep 53741/139435 = 38.5% of the coarse cost matrix.\n",
      "Keep 48527/124609 = 38.9% of the coarse cost matrix.\n",
      "Keep 59175/156025 = 37.9% of the coarse cost matrix.\n",
      "OMT matching distance: 0.5404236316680908, time elapsed: 3.7734758853912354\n",
      "303x334 clusters, computed at scale = 3.401\n",
      "Successive scales :  74.222, 74.222, 59.378, 47.502, 38.002, 30.401, 24.321, 19.457, 15.566, 12.452, 9.962, 7.970, 6.376, 5.101, 4.080, 3.264, 2.611, 2.089, 1.671, 1.337, 1.070, 0.856, 0.685, 0.548, 0.438, 0.351, 0.280, 0.224, 0.179, 0.144, 0.115, 0.092, 0.074, 0.059, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.080) and 15 (=3.264).\n",
      "Keep 38327/101202 = 37.9% of the coarse cost matrix.\n",
      "Keep 35543/91809 = 38.7% of the coarse cost matrix.\n",
      "Keep 41126/111556 = 36.9% of the coarse cost matrix.\n",
      "OMT matching distance: 1.1235442161560059, time elapsed: 3.1381592750549316\n",
      "380x403 clusters, computed at scale = 3.284\n",
      "Successive scales :  71.657, 71.657, 57.326, 45.861, 36.688, 29.351, 23.481, 18.784, 15.028, 12.022, 9.618, 7.694, 6.155, 4.924, 3.939, 3.152, 2.521, 2.017, 1.614, 1.291, 1.033, 0.826, 0.661, 0.529, 0.423, 0.338, 0.271, 0.217, 0.173, 0.139, 0.111, 0.089, 0.071, 0.057, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.939) and 15 (=3.152).\n",
      "Keep 55631/153140 = 36.3% of the coarse cost matrix.\n",
      "Keep 53726/144400 = 37.2% of the coarse cost matrix.\n",
      "Keep 57511/162409 = 35.4% of the coarse cost matrix.\n",
      "OMT matching distance: 0.5240598917007446, time elapsed: 4.030681610107422\n",
      "338x385 clusters, computed at scale = 3.419\n",
      "Successive scales :  74.618, 74.618, 59.695, 47.756, 38.205, 30.564, 24.451, 19.561, 15.649, 12.519, 10.015, 8.012, 6.410, 5.128, 4.102, 3.282, 2.625, 2.100, 1.680, 1.344, 1.075, 0.860, 0.688, 0.551, 0.440, 0.352, 0.282, 0.226, 0.180, 0.144, 0.115, 0.092, 0.074, 0.059, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.102) and 15 (=3.282).\n",
      "Keep 46260/130130 = 35.5% of the coarse cost matrix.\n",
      "Keep 41522/114244 = 36.3% of the coarse cost matrix.\n",
      "Keep 51457/148225 = 34.7% of the coarse cost matrix.\n",
      "OMT matching distance: 0.9469083547592163, time elapsed: 3.564122200012207\n",
      "341x375 clusters, computed at scale = 3.337\n",
      "Successive scales :  72.826, 72.826, 58.261, 46.609, 37.287, 29.830, 23.864, 19.091, 15.273, 12.218, 9.775, 7.820, 6.256, 5.005, 4.004, 3.203, 2.562, 2.050, 1.640, 1.312, 1.050, 0.840, 0.672, 0.537, 0.430, 0.344, 0.275, 0.220, 0.176, 0.141, 0.113, 0.090, 0.072, 0.058, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.004) and 15 (=3.203).\n",
      "Keep 46320/127875 = 36.2% of the coarse cost matrix.\n",
      "Keep 43117/116281 = 37.1% of the coarse cost matrix.\n",
      "Keep 49605/140625 = 35.3% of the coarse cost matrix.\n",
      "OMT matching distance: 0.815060019493103, time elapsed: 3.628431797027588\n",
      "353x354 clusters, computed at scale = 2.980\n",
      "Successive scales :  65.036, 65.036, 52.028, 41.623, 33.298, 26.639, 21.311, 17.049, 13.639, 10.911, 8.729, 6.983, 5.587, 4.469, 3.575, 2.860, 2.288, 1.831, 1.464, 1.172, 0.937, 0.750, 0.600, 0.480, 0.384, 0.307, 0.246, 0.197, 0.157, 0.126, 0.101, 0.081, 0.064, 0.052, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.575) and 15 (=2.860).\n",
      "Keep 44835/124962 = 35.9% of the coarse cost matrix.\n",
      "Keep 44713/124609 = 35.9% of the coarse cost matrix.\n",
      "Keep 44956/125316 = 35.9% of the coarse cost matrix.\n",
      "OMT matching distance: 0.009982645511627197, time elapsed: 3.3688347339630127\n",
      "*** TEMPLATE BUILD STAGE 3 ***\n",
      "Iteration 000  Loss 49732.34765625\n",
      "Iteration 001  Loss 35614.66015625\n",
      "Iteration 002  Loss 24741.107421875\n",
      "Iteration 003  Loss 18804.177734375\n",
      "Iteration 004  Loss 15325.0869140625\n",
      "Iteration 005  Loss 12721.71875\n",
      "Iteration 006  Loss 10526.259765625\n",
      "Iteration 007  Loss 8804.302734375\n",
      "Iteration 008  Loss 8126.388671875\n",
      "Iteration 009  Loss 7341.5517578125\n",
      "Iteration 010  Loss 6823.708984375\n",
      "Iteration 011  Loss 6354.2939453125\n",
      "Iteration 012  Loss 5913.78759765625\n",
      "Iteration 013  Loss 5536.0537109375\n",
      "Iteration 014  Loss 5172.81201171875\n",
      "Iteration 015  Loss 4964.580078125\n",
      "Iteration 016  Loss 4740.75341796875\n",
      "Iteration 017  Loss 4541.65771484375\n",
      "Iteration 018  Loss 4335.59423828125\n",
      "Iteration 019  Loss 4146.41650390625\n",
      "Iteration 020  Loss 3948.266357421875\n",
      "Iteration 021  Loss 3745.425048828125\n",
      "Iteration 022  Loss 3648.07275390625\n",
      "Iteration 023  Loss 3510.276611328125\n",
      "Iteration 024  Loss 3412.426513671875\n",
      "Iteration 025  Loss 3320.556396484375\n",
      "Iteration 026  Loss 3223.6337890625\n",
      "Iteration 027  Loss 3112.21533203125\n",
      "Iteration 028  Loss 3012.50244140625\n",
      "Iteration 029  Loss 2948.46875\n",
      "Iteration 030  Loss 2878.88720703125\n",
      "Iteration 031  Loss 2819.151611328125\n",
      "Iteration 032  Loss 2762.361572265625\n",
      "Iteration 033  Loss 2694.649169921875\n",
      "Iteration 034  Loss 2624.66064453125\n",
      "Iteration 035  Loss 2545.089111328125\n",
      "Iteration 036  Loss 2498.813232421875\n",
      "Iteration 037  Loss 2437.6982421875\n",
      "Iteration 038  Loss 2389.0078125\n",
      "Iteration 039  Loss 2346.565185546875\n",
      "Iteration 040  Loss 2308.749267578125\n",
      "Iteration 041  Loss 2266.922607421875\n",
      "Iteration 042  Loss 2220.090087890625\n",
      "Iteration 043  Loss 2187.26513671875\n",
      "Iteration 044  Loss 2157.600341796875\n",
      "Iteration 045  Loss 2128.72900390625\n",
      "Iteration 046  Loss 2107.409423828125\n",
      "Iteration 047  Loss 2072.859375\n",
      "Iteration 048  Loss 2043.941162109375\n",
      "Iteration 049  Loss 2007.9434814453125\n",
      "Optimization (L-BFGS) time: 2466.96 seconds\n",
      "400x412 clusters, computed at scale = 3.303\n",
      "Successive scales :  72.074, 72.074, 57.659, 46.127, 36.902, 29.521, 23.617, 18.894, 15.115, 12.092, 9.674, 7.739, 6.191, 4.953, 3.962, 3.170, 2.536, 2.029, 1.623, 1.298, 1.039, 0.831, 0.665, 0.532, 0.425, 0.340, 0.272, 0.218, 0.174, 0.139, 0.112, 0.089, 0.071, 0.057, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.962) and 15 (=3.170).\n",
      "Keep 56998/164800 = 34.6% of the coarse cost matrix.\n",
      "Keep 56258/160000 = 35.2% of the coarse cost matrix.\n",
      "Keep 57742/169744 = 34.0% of the coarse cost matrix.\n",
      "OMT matching distance: 0.2958791255950928, time elapsed: 4.086221218109131\n",
      "416x456 clusters, computed at scale = 3.151\n",
      "Successive scales :  68.772, 68.772, 55.017, 44.014, 35.211, 28.169, 22.535, 18.028, 14.422, 11.538, 9.230, 7.384, 5.907, 4.726, 3.781, 3.025, 2.420, 1.936, 1.549, 1.239, 0.991, 0.793, 0.634, 0.507, 0.406, 0.325, 0.260, 0.208, 0.166, 0.133, 0.106, 0.085, 0.068, 0.054, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.781) and 15 (=3.025).\n",
      "Keep 66355/189696 = 35.0% of the coarse cost matrix.\n",
      "Keep 60888/173056 = 35.2% of the coarse cost matrix.\n",
      "Keep 72360/207936 = 34.8% of the coarse cost matrix.\n",
      "OMT matching distance: 0.24707621335983276, time elapsed: 4.3756797313690186\n",
      "373x393 clusters, computed at scale = 3.376\n",
      "Successive scales :  73.669, 73.669, 58.935, 47.148, 37.718, 30.175, 24.140, 19.312, 15.449, 12.360, 9.888, 7.910, 6.328, 5.062, 4.050, 3.240, 2.592, 2.074, 1.659, 1.327, 1.062, 0.849, 0.679, 0.544, 0.435, 0.348, 0.278, 0.223, 0.178, 0.142, 0.114, 0.091, 0.073, 0.058, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.050) and 15 (=3.240).\n",
      "Keep 53564/146589 = 36.5% of the coarse cost matrix.\n",
      "Keep 51609/139129 = 37.1% of the coarse cost matrix.\n",
      "Keep 55417/154449 = 35.9% of the coarse cost matrix.\n",
      "OMT matching distance: 0.1903756856918335, time elapsed: 3.7568228244781494\n",
      "331x339 clusters, computed at scale = 3.354\n",
      "Successive scales :  73.187, 73.187, 58.549, 46.839, 37.471, 29.977, 23.982, 19.185, 15.348, 12.279, 9.823, 7.858, 6.287, 5.029, 4.023, 3.219, 2.575, 2.060, 1.648, 1.318, 1.055, 0.844, 0.675, 0.540, 0.432, 0.346, 0.276, 0.221, 0.177, 0.142, 0.113, 0.091, 0.072, 0.058, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.023) and 15 (=3.219).\n",
      "Keep 40903/112209 = 36.5% of the coarse cost matrix.\n",
      "Keep 40181/109561 = 36.7% of the coarse cost matrix.\n",
      "Keep 41623/114921 = 36.2% of the coarse cost matrix.\n",
      "OMT matching distance: 0.09352000057697296, time elapsed: 3.3288791179656982\n",
      "434x472 clusters, computed at scale = 2.991\n",
      "Successive scales :  65.275, 65.275, 52.220, 41.776, 33.421, 26.737, 21.389, 17.111, 13.689, 10.951, 8.761, 7.009, 5.607, 4.486, 3.589, 2.871, 2.297, 1.837, 1.470, 1.176, 0.941, 0.753, 0.602, 0.482, 0.385, 0.308, 0.247, 0.197, 0.158, 0.126, 0.101, 0.081, 0.065, 0.052, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.589) and 15 (=2.871).\n",
      "Keep 69077/204848 = 33.7% of the coarse cost matrix.\n",
      "Keep 63592/188356 = 33.8% of the coarse cost matrix.\n",
      "Keep 74512/222784 = 33.4% of the coarse cost matrix.\n",
      "OMT matching distance: 0.5570186376571655, time elapsed: 4.611894369125366\n",
      "338x367 clusters, computed at scale = 3.491\n",
      "Successive scales :  76.183, 76.183, 60.946, 48.757, 39.006, 31.205, 24.964, 19.971, 15.977, 12.781, 10.225, 8.180, 6.544, 5.235, 4.188, 3.351, 2.680, 2.144, 1.715, 1.372, 1.098, 0.878, 0.703, 0.562, 0.450, 0.360, 0.288, 0.230, 0.184, 0.147, 0.118, 0.094, 0.075, 0.060, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.188) and 15 (=3.351).\n",
      "Keep 45937/124046 = 37.0% of the coarse cost matrix.\n",
      "Keep 42926/114244 = 37.6% of the coarse cost matrix.\n",
      "Keep 49193/134689 = 36.5% of the coarse cost matrix.\n",
      "OMT matching distance: 0.30680835247039795, time elapsed: 3.437551736831665\n",
      "308x325 clusters, computed at scale = 3.474\n",
      "Successive scales :  75.816, 75.816, 60.653, 48.522, 38.818, 31.054, 24.843, 19.875, 15.900, 12.720, 10.176, 8.141, 6.513, 5.210, 4.168, 3.334, 2.668, 2.134, 1.707, 1.366, 1.093, 0.874, 0.699, 0.559, 0.448, 0.358, 0.286, 0.229, 0.183, 0.147, 0.117, 0.094, 0.075, 0.060, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.168) and 15 (=3.334).\n",
      "Keep 38593/100100 = 38.6% of the coarse cost matrix.\n",
      "Keep 37004/94864 = 39.0% of the coarse cost matrix.\n",
      "Keep 40087/105625 = 38.0% of the coarse cost matrix.\n",
      "OMT matching distance: 0.6004239916801453, time elapsed: 3.1815481185913086\n",
      "348x361 clusters, computed at scale = 3.383\n",
      "Successive scales :  73.819, 73.819, 59.055, 47.244, 37.795, 30.236, 24.189, 19.351, 15.481, 12.385, 9.908, 7.926, 6.341, 5.073, 4.058, 3.247, 2.597, 2.078, 1.662, 1.330, 1.064, 0.851, 0.681, 0.545, 0.436, 0.349, 0.279, 0.223, 0.178, 0.143, 0.114, 0.091, 0.073, 0.058, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.058) and 15 (=3.247).\n",
      "Keep 48127/125628 = 38.3% of the coarse cost matrix.\n",
      "Keep 46640/121104 = 38.5% of the coarse cost matrix.\n",
      "Keep 49625/130321 = 38.1% of the coarse cost matrix.\n",
      "OMT matching distance: 0.3512294292449951, time elapsed: 3.5212924480438232\n",
      "354x395 clusters, computed at scale = 3.316\n",
      "Successive scales :  72.360, 72.360, 57.888, 46.310, 37.048, 29.638, 23.711, 18.969, 15.175, 12.140, 9.712, 7.770, 6.216, 4.973, 3.978, 3.182, 2.546, 2.037, 1.629, 1.304, 1.043, 0.834, 0.667, 0.534, 0.427, 0.342, 0.273, 0.219, 0.175, 0.140, 0.112, 0.090, 0.072, 0.057, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.978) and 15 (=3.182).\n",
      "Keep 53528/139830 = 38.3% of the coarse cost matrix.\n",
      "Keep 48460/125316 = 38.7% of the coarse cost matrix.\n",
      "Keep 59175/156025 = 37.9% of the coarse cost matrix.\n",
      "OMT matching distance: 0.20669174194335938, time elapsed: 3.8135228157043457\n",
      "304x339 clusters, computed at scale = 3.392\n",
      "Successive scales :  74.020, 74.020, 59.216, 47.373, 37.898, 30.318, 24.255, 19.404, 15.523, 12.418, 9.935, 7.948, 6.358, 5.087, 4.069, 3.255, 2.604, 2.083, 1.667, 1.333, 1.067, 0.853, 0.683, 0.546, 0.437, 0.350, 0.280, 0.224, 0.179, 0.143, 0.115, 0.092, 0.073, 0.059, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.069) and 15 (=3.255).\n",
      "Keep 39255/103056 = 38.1% of the coarse cost matrix.\n",
      "Keep 36378/92416 = 39.4% of the coarse cost matrix.\n",
      "Keep 42415/114921 = 36.9% of the coarse cost matrix.\n",
      "OMT matching distance: 1.021406888961792, time elapsed: 3.313197612762451\n",
      "388x405 clusters, computed at scale = 3.287\n",
      "Successive scales :  71.738, 71.738, 57.390, 45.912, 36.730, 29.384, 23.507, 18.806, 15.044, 12.036, 9.628, 7.703, 6.162, 4.930, 3.944, 3.155, 2.524, 2.019, 1.615, 1.292, 1.034, 0.827, 0.662, 0.529, 0.423, 0.339, 0.271, 0.217, 0.173, 0.139, 0.111, 0.089, 0.071, 0.057, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.944) and 15 (=3.155).\n",
      "Keep 55966/157140 = 35.6% of the coarse cost matrix.\n",
      "Keep 53992/150544 = 35.9% of the coarse cost matrix.\n",
      "Keep 58049/164025 = 35.4% of the coarse cost matrix.\n",
      "OMT matching distance: 0.28968703746795654, time elapsed: 3.8875467777252197\n",
      "359x383 clusters, computed at scale = 3.430\n",
      "Successive scales :  74.853, 74.853, 59.883, 47.906, 38.325, 30.660, 24.528, 19.622, 15.698, 12.558, 10.047, 8.037, 6.430, 5.144, 4.115, 3.292, 2.634, 2.107, 1.686, 1.348, 1.079, 0.863, 0.690, 0.552, 0.442, 0.353, 0.283, 0.226, 0.181, 0.145, 0.116, 0.093, 0.074, 0.059, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.115) and 15 (=3.292).\n",
      "Keep 48733/137497 = 35.4% of the coarse cost matrix.\n",
      "Keep 46331/128881 = 35.9% of the coarse cost matrix.\n",
      "Keep 51065/146689 = 34.8% of the coarse cost matrix.\n",
      "OMT matching distance: 0.353969931602478, time elapsed: 3.723888635635376\n",
      "365x372 clusters, computed at scale = 3.331\n",
      "Successive scales :  72.682, 72.682, 58.146, 46.517, 37.213, 29.771, 23.817, 19.053, 15.243, 12.194, 9.755, 7.804, 6.243, 4.995, 3.996, 3.197, 2.557, 2.046, 1.637, 1.309, 1.047, 0.838, 0.670, 0.536, 0.429, 0.343, 0.275, 0.220, 0.176, 0.141, 0.112, 0.090, 0.072, 0.058, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.996) and 15 (=3.197).\n",
      "Keep 48314/135780 = 35.6% of the coarse cost matrix.\n",
      "Keep 47779/133225 = 35.9% of the coarse cost matrix.\n",
      "Keep 48750/138384 = 35.2% of the coarse cost matrix.\n",
      "OMT matching distance: 0.17271603643894196, time elapsed: 3.6061911582946777\n",
      "363x366 clusters, computed at scale = 2.971\n",
      "Successive scales :  64.841, 64.841, 51.873, 41.498, 33.199, 26.559, 21.247, 16.998, 13.598, 10.879, 8.703, 6.962, 5.570, 4.456, 3.565, 2.852, 2.281, 1.825, 1.460, 1.168, 0.934, 0.748, 0.598, 0.478, 0.383, 0.306, 0.245, 0.196, 0.157, 0.125, 0.100, 0.080, 0.064, 0.051, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.565) and 15 (=2.852).\n",
      "Keep 47086/132858 = 35.4% of the coarse cost matrix.\n",
      "Keep 46797/131769 = 35.5% of the coarse cost matrix.\n",
      "Keep 47370/133956 = 35.4% of the coarse cost matrix.\n",
      "OMT matching distance: 0.011854970827698708, time elapsed: 3.5658645629882812\n"
     ]
    }
   ],
   "source": [
    "# Run the whole template building pipeline\n",
    "# template['left'].get_varifold_sigma()\n",
    "md_temp, p_temp = build_template_multistage(md_src2, md_aff, schedule=[10, 10, 10, 50], \n",
    "                                            sigma_root = 2.4 * template['left'].get_lddmm_sigma(), \n",
    "                                            sigma_lddmm = template['left'].get_lddmm_sigma(), \n",
    "                                            sigma_varifold = 5,\n",
    "                                            gamma_lddmm=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the template and the momenta\n",
    "pd_temp_save = vtk_clone_pd(md_temp.pd)\n",
    "for i, (id, md_i) in enumerate(md_aff.items()):\n",
    "    vtk_set_point_array(pd_temp_save, f'momenta_{id}', p_temp[i,:,:].detach().cpu().numpy())\n",
    "save_vtk(pd_temp_save, 'tmp/template_final_with_momenta.vtk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400x412 clusters, computed at scale = 3.303\n",
      "Successive scales :  72.074, 72.074, 57.659, 46.127, 36.902, 29.521, 23.617, 18.894, 15.115, 12.092, 9.674, 7.739, 6.191, 4.953, 3.962, 3.170, 2.536, 2.029, 1.623, 1.298, 1.039, 0.831, 0.665, 0.532, 0.425, 0.340, 0.272, 0.218, 0.174, 0.139, 0.112, 0.089, 0.071, 0.057, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.962) and 15 (=3.170).\n",
      "Keep 56998/164800 = 34.6% of the coarse cost matrix.\n",
      "Keep 56258/160000 = 35.2% of the coarse cost matrix.\n",
      "Keep 57742/169744 = 34.0% of the coarse cost matrix.\n",
      "OMT matching distance: 0.29587888717651367, time elapsed: 4.4686267375946045\n",
      "389x393 clusters, computed at scale = 3.378\n",
      "Successive scales :  73.725, 73.725, 58.980, 47.184, 37.747, 30.198, 24.158, 19.327, 15.461, 12.369, 9.895, 7.916, 6.333, 5.066, 4.053, 3.242, 2.594, 2.075, 1.660, 1.328, 1.062, 0.850, 0.680, 0.544, 0.435, 0.348, 0.279, 0.223, 0.178, 0.143, 0.114, 0.091, 0.073, 0.058, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.053) and 15 (=3.242).\n",
      "Keep 54135/152877 = 35.4% of the coarse cost matrix.\n",
      "Keep 53511/151321 = 35.4% of the coarse cost matrix.\n",
      "Keep 54757/154449 = 35.5% of the coarse cost matrix.\n",
      "OMT matching distance: 0.019928812980651855, time elapsed: 4.20853328704834\n",
      "416x456 clusters, computed at scale = 3.151\n",
      "Successive scales :  68.772, 68.772, 55.017, 44.014, 35.211, 28.169, 22.535, 18.028, 14.422, 11.538, 9.230, 7.384, 5.907, 4.726, 3.781, 3.025, 2.420, 1.936, 1.549, 1.239, 0.991, 0.793, 0.634, 0.507, 0.406, 0.325, 0.260, 0.208, 0.166, 0.133, 0.106, 0.085, 0.068, 0.054, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.781) and 15 (=3.025).\n",
      "Keep 66355/189696 = 35.0% of the coarse cost matrix.\n",
      "Keep 60888/173056 = 35.2% of the coarse cost matrix.\n",
      "Keep 72360/207936 = 34.8% of the coarse cost matrix.\n",
      "OMT matching distance: 0.24707619845867157, time elapsed: 4.382683515548706\n",
      "464x477 clusters, computed at scale = 3.084\n",
      "Successive scales :  67.295, 67.295, 53.836, 43.069, 34.455, 27.564, 22.051, 17.641, 14.113, 11.290, 9.032, 7.226, 5.781, 4.624, 3.700, 2.960, 2.368, 1.894, 1.515, 1.212, 0.970, 0.776, 0.621, 0.497, 0.397, 0.318, 0.254, 0.203, 0.163, 0.130, 0.104, 0.083, 0.067, 0.053, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.700) and 15 (=2.960).\n",
      "Keep 75500/221328 = 34.1% of the coarse cost matrix.\n",
      "Keep 73340/215296 = 34.1% of the coarse cost matrix.\n",
      "Keep 77729/227529 = 34.2% of the coarse cost matrix.\n",
      "OMT matching distance: 0.020019924268126488, time elapsed: 5.041019439697266\n",
      "373x393 clusters, computed at scale = 3.376\n",
      "Successive scales :  73.669, 73.669, 58.935, 47.148, 37.718, 30.175, 24.140, 19.312, 15.449, 12.360, 9.888, 7.910, 6.328, 5.062, 4.050, 3.240, 2.592, 2.074, 1.659, 1.327, 1.062, 0.849, 0.679, 0.544, 0.435, 0.348, 0.278, 0.223, 0.178, 0.142, 0.114, 0.091, 0.073, 0.058, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.050) and 15 (=3.240).\n",
      "Keep 53564/146589 = 36.5% of the coarse cost matrix.\n",
      "Keep 51609/139129 = 37.1% of the coarse cost matrix.\n",
      "Keep 55417/154449 = 35.9% of the coarse cost matrix.\n",
      "OMT matching distance: 0.19037573039531708, time elapsed: 3.943756103515625\n",
      "180x189 clusters, computed at scale = 5.115\n",
      "Successive scales :  111.615, 111.615, 89.292, 71.434, 57.147, 45.718, 36.574, 29.259, 23.407, 18.726, 14.981, 11.985, 9.588, 7.670, 6.136, 4.909, 3.927, 3.142, 2.513, 2.011, 1.609, 1.287, 1.029, 0.824, 0.659, 0.527, 0.422, 0.337, 0.270, 0.216, 0.173, 0.138, 0.111, 0.088, 0.071, 0.057, 0.050\n",
      "Jump from coarse to fine between indices 14 (=6.136) and 15 (=4.909).\n",
      "Keep 18907/34020 = 55.6% of the coarse cost matrix.\n",
      "Keep 17352/32400 = 53.6% of the coarse cost matrix.\n",
      "Keep 19155/35721 = 53.6% of the coarse cost matrix.\n",
      "OMT matching distance: 1518.9732666015625, time elapsed: 2.7285139560699463\n",
      "331x339 clusters, computed at scale = 3.354\n",
      "Successive scales :  73.187, 73.187, 58.549, 46.839, 37.471, 29.977, 23.982, 19.185, 15.348, 12.279, 9.823, 7.858, 6.287, 5.029, 4.023, 3.219, 2.575, 2.060, 1.648, 1.318, 1.055, 0.844, 0.675, 0.540, 0.432, 0.346, 0.276, 0.221, 0.177, 0.142, 0.113, 0.091, 0.072, 0.058, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.023) and 15 (=3.219).\n",
      "Keep 40903/112209 = 36.5% of the coarse cost matrix.\n",
      "Keep 40181/109561 = 36.7% of the coarse cost matrix.\n",
      "Keep 41623/114921 = 36.2% of the coarse cost matrix.\n",
      "OMT matching distance: 0.09352000057697296, time elapsed: 3.457387924194336\n",
      "153x170 clusters, computed at scale = 4.912\n",
      "Successive scales :  107.191, 107.191, 85.753, 68.602, 54.882, 43.906, 35.124, 28.100, 22.480, 17.984, 14.387, 11.510, 9.208, 7.366, 5.893, 4.714, 3.771, 3.017, 2.414, 1.931, 1.545, 1.236, 0.989, 0.791, 0.633, 0.506, 0.405, 0.324, 0.259, 0.207, 0.166, 0.133, 0.106, 0.085, 0.068, 0.054, 0.050\n",
      "Jump from coarse to fine between indices 14 (=5.893) and 15 (=4.714).\n",
      "Keep 13821/26010 = 53.1% of the coarse cost matrix.\n",
      "Keep 12003/23409 = 51.3% of the coarse cost matrix.\n",
      "Keep 15076/28900 = 52.2% of the coarse cost matrix.\n",
      "OMT matching distance: 1640.3416748046875, time elapsed: 2.250120162963867\n",
      "434x472 clusters, computed at scale = 2.991\n",
      "Successive scales :  65.275, 65.275, 52.220, 41.776, 33.421, 26.737, 21.389, 17.111, 13.689, 10.951, 8.761, 7.009, 5.607, 4.486, 3.589, 2.871, 2.297, 1.837, 1.470, 1.176, 0.941, 0.753, 0.602, 0.482, 0.385, 0.308, 0.247, 0.197, 0.158, 0.126, 0.101, 0.081, 0.065, 0.052, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.589) and 15 (=2.871).\n",
      "Keep 69077/204848 = 33.7% of the coarse cost matrix.\n",
      "Keep 63592/188356 = 33.8% of the coarse cost matrix.\n",
      "Keep 74512/222784 = 33.4% of the coarse cost matrix.\n",
      "OMT matching distance: 0.5570186376571655, time elapsed: 4.499578237533569\n",
      "162x173 clusters, computed at scale = 4.861\n",
      "Successive scales :  106.077, 106.077, 84.861, 67.889, 54.311, 43.449, 34.759, 27.807, 22.246, 17.797, 14.237, 11.390, 9.112, 7.290, 5.832, 4.665, 3.732, 2.986, 2.389, 1.911, 1.529, 1.223, 0.978, 0.783, 0.626, 0.501, 0.401, 0.321, 0.256, 0.205, 0.164, 0.131, 0.105, 0.084, 0.067, 0.054, 0.050\n",
      "Jump from coarse to fine between indices 14 (=5.832) and 15 (=4.665).\n",
      "Keep 17195/28026 = 61.4% of the coarse cost matrix.\n",
      "Keep 16176/26244 = 61.6% of the coarse cost matrix.\n",
      "Keep 17696/29929 = 59.1% of the coarse cost matrix.\n",
      "OMT matching distance: 1636.189453125, time elapsed: 2.232590675354004\n",
      "338x367 clusters, computed at scale = 3.491\n",
      "Successive scales :  76.183, 76.183, 60.946, 48.757, 39.006, 31.205, 24.964, 19.971, 15.977, 12.781, 10.225, 8.180, 6.544, 5.235, 4.188, 3.351, 2.680, 2.144, 1.715, 1.372, 1.098, 0.878, 0.703, 0.562, 0.450, 0.360, 0.288, 0.230, 0.184, 0.147, 0.118, 0.094, 0.075, 0.060, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.188) and 15 (=3.351).\n",
      "Keep 45937/124046 = 37.0% of the coarse cost matrix.\n",
      "Keep 42926/114244 = 37.6% of the coarse cost matrix.\n",
      "Keep 49193/134689 = 36.5% of the coarse cost matrix.\n",
      "OMT matching distance: 0.30680835247039795, time elapsed: 3.2918436527252197\n",
      "175x167 clusters, computed at scale = 5.323\n",
      "Successive scales :  116.161, 116.161, 92.928, 74.343, 59.474, 47.579, 38.063, 30.451, 24.361, 19.489, 15.591, 12.473, 9.978, 7.982, 6.386, 5.109, 4.087, 3.270, 2.616, 2.093, 1.674, 1.339, 1.071, 0.857, 0.686, 0.549, 0.439, 0.351, 0.281, 0.225, 0.180, 0.144, 0.115, 0.092, 0.074, 0.059, 0.050\n",
      "Jump from coarse to fine between indices 14 (=6.386) and 15 (=5.109).\n",
      "Keep 16524/29225 = 56.5% of the coarse cost matrix.\n",
      "Keep 16173/30625 = 52.8% of the coarse cost matrix.\n",
      "Keep 14639/27889 = 52.5% of the coarse cost matrix.\n",
      "OMT matching distance: 1429.41650390625, time elapsed: 2.601929187774658\n",
      "308x325 clusters, computed at scale = 3.474\n",
      "Successive scales :  75.816, 75.816, 60.653, 48.522, 38.818, 31.054, 24.843, 19.875, 15.900, 12.720, 10.176, 8.141, 6.513, 5.210, 4.168, 3.334, 2.668, 2.134, 1.707, 1.366, 1.093, 0.874, 0.699, 0.559, 0.448, 0.358, 0.286, 0.229, 0.183, 0.147, 0.117, 0.094, 0.075, 0.060, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.168) and 15 (=3.334).\n",
      "Keep 38593/100100 = 38.6% of the coarse cost matrix.\n",
      "Keep 37004/94864 = 39.0% of the coarse cost matrix.\n",
      "Keep 40087/105625 = 38.0% of the coarse cost matrix.\n",
      "OMT matching distance: 0.6004239320755005, time elapsed: 3.3017263412475586\n",
      "150x156 clusters, computed at scale = 4.759\n",
      "Successive scales :  103.842, 103.842, 83.074, 66.459, 53.167, 42.534, 34.027, 27.222, 21.777, 17.422, 13.937, 11.150, 8.920, 7.136, 5.709, 4.567, 3.654, 2.923, 2.338, 1.871, 1.497, 1.197, 0.958, 0.766, 0.613, 0.490, 0.392, 0.314, 0.251, 0.201, 0.161, 0.129, 0.103, 0.082, 0.066, 0.053, 0.050\n",
      "Jump from coarse to fine between indices 14 (=5.709) and 15 (=4.567).\n",
      "Keep 13462/23400 = 57.5% of the coarse cost matrix.\n",
      "Keep 12324/22500 = 54.8% of the coarse cost matrix.\n",
      "Keep 13564/24336 = 55.7% of the coarse cost matrix.\n",
      "OMT matching distance: 1463.53662109375, time elapsed: 2.0690484046936035\n",
      "348x361 clusters, computed at scale = 3.383\n",
      "Successive scales :  73.819, 73.819, 59.055, 47.244, 37.795, 30.236, 24.189, 19.351, 15.481, 12.385, 9.908, 7.926, 6.341, 5.073, 4.058, 3.247, 2.597, 2.078, 1.662, 1.330, 1.064, 0.851, 0.681, 0.545, 0.436, 0.349, 0.279, 0.223, 0.178, 0.143, 0.114, 0.091, 0.073, 0.058, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.058) and 15 (=3.247).\n",
      "Keep 48127/125628 = 38.3% of the coarse cost matrix.\n",
      "Keep 46640/121104 = 38.5% of the coarse cost matrix.\n",
      "Keep 49625/130321 = 38.1% of the coarse cost matrix.\n",
      "OMT matching distance: 0.3512294292449951, time elapsed: 3.621522903442383\n",
      "342x344 clusters, computed at scale = 3.541\n",
      "Successive scales :  77.269, 77.269, 61.815, 49.452, 39.562, 31.649, 25.320, 20.256, 16.205, 12.964, 10.371, 8.297, 6.637, 5.310, 4.248, 3.398, 2.719, 2.175, 1.740, 1.392, 1.114, 0.891, 0.713, 0.570, 0.456, 0.365, 0.292, 0.234, 0.187, 0.149, 0.120, 0.096, 0.077, 0.061, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.248) and 15 (=3.398).\n",
      "Keep 45702/117648 = 38.8% of the coarse cost matrix.\n",
      "Keep 45444/116964 = 38.9% of the coarse cost matrix.\n",
      "Keep 45918/118336 = 38.8% of the coarse cost matrix.\n",
      "OMT matching distance: 0.018472453579306602, time elapsed: 3.659111738204956\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 9993 is out of bounds for axis 0 with size 9990",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_476292/3409716412.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Now we need to perform two interpolations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mv_fullres_to_lowres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vij,vi->vj'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_native\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv_int_fr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_int_fr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mv_temp_to_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vij,vi->vj'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_fullres_to_lowres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m#pd_i_fit, pd_i_omt = map_template_to_subject(md_temp, md_infl_fullres, p_temp[i],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 9993 is out of bounds for axis 0 with size 9990"
     ]
    }
   ],
   "source": [
    "# Match template to each subject and save the resulting meshes\n",
    "for i, (id, md_i) in enumerate(md_aff.items()):\n",
    "    # We want to map the template to the halfway surface of the MTL cortex in subject space\n",
    "    # But that mesh has different number of vertices than the meshes we fitted in the template\n",
    "    # building process. So we need to apply affine transform to the full-resolution inflated\n",
    "    # mesh, then do OMT matching between the warped template and this target, then use this to\n",
    "    # get coordinates of template vertices the space of the native halfway surface\n",
    "    pd_infl_fullres = load_vtk(data[id]['workspace'].affine_moving)\n",
    "    A = np.loadtxt(f'tmp/affine_to_template_{id}.mat')\n",
    "    v_infl_fullres = vtk_get_points(pd_infl_fullres)\n",
    "    v_infl_fullres_affine = (A[0:3,0:3] @ v_infl_fullres.T).T + A[0:3,3]\n",
    "\n",
    "    # Send this mesh to the device\n",
    "    vtk_set_points(pd_infl_fullres, v_infl_fullres_affine)\n",
    "    vtk_set_cell_array(pd_infl_fullres, 'plab', np.zeros((v_infl_fullres_affine.shape[0],1)))\n",
    "    md_infl_fullres = MeshData(pd_infl_fullres, device)\n",
    "\n",
    "    # Get template mesh and OMT fitted mesh\n",
    "    pd_i_fit, pd_i_omt = map_template_to_subject(md_temp, md_i, p_temp[i], \n",
    "                                                 sigma_lddmm = template['left'].get_lddmm_sigma())\n",
    "    \n",
    "    # These interpolation arrays map every template vertex to a face on the subject mesh. But this\n",
    "    # mesh has been downsampled from a full-resolution mesh. In order to map to the original mesh,\n",
    "    # we have to account for the downsampling\n",
    "    v_int = vtk_get_point_array(pd_i_fit, 'omt_v_int').astype(np.int32)\n",
    "    w_int = vtk_get_point_array(pd_i_fit, 'omt_w_int')\n",
    "\n",
    "    # Get the full-resolution mesh and corresponding downsampled mesh\n",
    "    pd_fullres, pd_lowres = data[id]['pd_input'], data[id]['pd_ds']\n",
    "\n",
    "    # Perform OMT matching between these two meshes\n",
    "    _, w_omt = match_omt(torch.tensor(vtk_get_points(pd_lowres), dtype=torch.float32, device=device), \n",
    "                         torch.tensor(vtk_get_triangles(pd_lowres), dtype=torch.long, device=device), \n",
    "                         torch.tensor(vtk_get_points(pd_fullres), dtype=torch.float32, device=device), \n",
    "                         torch.tensor(vtk_get_triangles(pd_fullres), dtype=torch.long, device=device))\n",
    "    \n",
    "    # The target locations stored in w_omt are at the triangle centers, need to remap them to\n",
    "    # vertices before we can get interpolation weights\n",
    "    pd_omt = vtk_clone_pd(pd_lowres)\n",
    "    pd_omt = vtk_set_cell_array(pd_omt, 'match', w_omt.detach().cpu().numpy())\n",
    "    vtk_cell_array_to_point_array(pd_omt, 'match')\n",
    "    v_omt = vtk_get_point_array(pd_omt, 'match')\n",
    "    v_int_fr, w_int_fr = vtk_get_interpolation_arrays_for_sample(pd_fullres, v_omt)\n",
    "\n",
    "    # We also want to go all the way back to the original space. Load the original space mesh\n",
    "    pd_hw_native = load_vtk(data[id]['workspace'].fn_cruise('mtl_avg_l2m-mesh-ras.vtk'))\n",
    "    v_native = vtk_get_points(pd_hw_native)\n",
    "    \n",
    "    # Now we need to perform two interpolations\n",
    "    v_fullres_to_lowres = np.einsum('vij,vi->vj', v_native[v_int_fr,:], w_int_fr)\n",
    "    v_temp_to_native = np.einsum('vij,vi->vj', v_fullres_to_lowres[v_int,:], w_int)\n",
    "\n",
    "    #pd_i_fit, pd_i_omt = map_template_to_subject(md_temp, md_infl_fullres, p_temp[i], \n",
    "    #                                             sigma_lddmm = template['left'].get_lddmm_sigma())\n",
    "    \n",
    "    # The original mesh has a different number of vertices compared to the \n",
    "    # v_int = vtk_get_point_array(pd_i_fit, 'omt_v_int').astype(np.int32)\n",
    "    # w_int = vtk_get_point_array(pd_i_fit, 'omt_w_int')\n",
    "    # v_temp_to_native = np.einsum('vij,vi->vj', v_native[v_int,:], w_int)\n",
    "    pd_temp_omt_to_native = vtk_make_pd(v_temp_to_native, vtk_get_triangles(pd_i_fit))\n",
    "    pd_temp_omt_to_native = vtk_set_cell_array(pd_temp_omt_to_native, 'plab', vtk_get_cell_array(pd_i_fit, 'plab'))\n",
    "\n",
    "    save_vtk(pd_i_fit, f'tmp/template_fit_to_{id}.vtk')\n",
    "    save_vtk(pd_i_omt, f'tmp/template_omt_to_{id}.vtk')\n",
    "    save_vtk(pd_temp_omt_to_native, f'tmp/template_omt_to_avg_ras_{id}.vtk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9990, (9994, 3))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['118374L']['pd_ds'].GetNumberOfPoints(), md_aff['118374L'].v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26828"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_vtk(data['104937L']['workspace'].affine_moving).GetNumberOfPoints()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute consensus labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_476292/3089950838.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Ok, so we have the template in native space, we can now sample the complete selection of labels. Load the scans.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mxvashs_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd_aff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd_aff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Read the global segmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import SimpleITK as sitk\n",
    "\n",
    "# Load the template again\n",
    "\n",
    "\n",
    "# Ok, so we have the template in native space, we can now sample the complete selection of labels. Load the scans.\n",
    "xvashs_label = np.zeros((md_temp.v.shape[0], len(md_aff)))\n",
    "for i, (id, md_i) in enumerate(md_aff.items()):\n",
    "    # Read the global segmentation\n",
    "    fn_global_seg = f'/data/pauly2/ashs_xv/input/{id}/{id}_label_global.nii.gz'\n",
    "    img = sitk.ReadImage(fn_global_seg, outputPixelType=sitk.sitkFloat32)\n",
    "\n",
    "    # Load the mesh\n",
    "    pd_temp_omt_to_native = load_vtk(f'tmp/template_omt_to_avg_ras_{id}.vtk')\n",
    "\n",
    "    # Sample all the vertices - nearest neighbor\n",
    "    v = vtk_get_points(pd_temp_omt_to_native)\n",
    "    v_label = np.zeros(v.shape[0])\n",
    "    for j in range(v.shape[0]):\n",
    "        x = [ -v[j,0], -v[j,1], v[j,2] ]\n",
    "        try:\n",
    "            l = img.EvaluateAtPhysicalPoint(x, sitk.sitkNearestNeighbor)\n",
    "        except:\n",
    "            l = 0\n",
    "        xvashs_label[j,i] = l\n",
    "\n",
    "    # Assign to the mesh\n",
    "    # vtk_set_point_array(pd_temp_omt_to_native, 'label_xv', v_label);\n",
    "    # save_vtk(pd_temp_omt_to_native, f'tmp/template_omt_to_avg_ras_withlabel_{id}.vtk')\n",
    "    # break\n",
    "        \n",
    "# Consensus labeling\n",
    "lab_consensus = np.argmax([np.sum(xvashs_label == v, 1) for v in range(69)], 0)\n",
    "pd_consensus = vtk_clone_pd(md_temp.pd)\n",
    "vtk_set_point_array(pd_consensus, 'xvashs', lab_consensus)\n",
    "save_vtk(pd_consensus, 'tmp/template_global_label.vtk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 68, 21, ..., 51, 12,  9])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1780083/3253760961.py:14: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  0 : loss 68562.21\n",
      "loss 68269.29\n",
      "loss 65726.28\n",
      "loss 49957.67\n",
      "loss 41948.418\n",
      "loss 35315.43\n",
      "loss 31865.328\n",
      "loss 27524.482\n",
      "loss 24512.904\n",
      "loss 21901.518\n",
      "loss 21002.684\n",
      "loss 18434.291\n",
      "loss 17767.508\n",
      "loss 16425.61\n",
      "loss 14754.634\n",
      "loss 14320.603\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  1 : loss 14320.603\n",
      "loss 12964.27\n",
      "loss 12482.753\n",
      "loss 11793.728\n",
      "loss 11102.531\n",
      "loss 10320.76\n",
      "loss 9811.943\n",
      "loss 9344.442\n",
      "loss 8759.904\n",
      "loss 8178.0654\n",
      "loss 7786.9263\n",
      "loss 7374.3496\n",
      "loss 6948.0205\n",
      "loss 6523.957\n",
      "loss 6197.33\n",
      "loss 5943.7188\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  2 : loss 5943.7188\n",
      "loss 5600.515\n",
      "loss 5372.085\n",
      "loss 5126.4575\n",
      "loss 4972.19\n",
      "loss 4778.7173\n",
      "loss 4606.7837\n",
      "loss 4421.307\n",
      "loss 4305.4272\n",
      "loss 4178.4614\n",
      "loss 3998.2537\n",
      "loss 3849.0493\n",
      "loss 3742.4143\n",
      "loss 3622.4014\n",
      "loss 3509.8123\n",
      "loss 3404.9758\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  3 : loss 3404.9758\n",
      "loss 3299.0818\n",
      "loss 3222.9644\n",
      "loss 3114.252\n",
      "loss 3034.4563\n",
      "loss 2950.6282\n",
      "loss 2892.7083\n",
      "loss 2827.1504\n",
      "loss 2750.397\n",
      "loss 2677.9817\n",
      "loss 2625.562\n",
      "loss 2567.638\n",
      "loss 2512.5273\n",
      "loss 2458.9014\n",
      "loss 2411.1138\n",
      "loss 2371.1125\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  4 : loss 2371.1125\n",
      "loss 2313.8555\n",
      "loss 2261.6301\n",
      "loss 2226.0217\n",
      "loss 2176.4429\n",
      "loss 2140.101\n",
      "loss 2102.8242\n",
      "loss 2064.7874\n",
      "loss 2037.9052\n",
      "loss 1989.9065\n",
      "loss 1956.2418\n",
      "loss 1922.0464\n",
      "loss 1892.4835\n",
      "loss 1864.2295\n",
      "loss 1829.6132\n",
      "loss 1798.8358\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  5 : loss 1798.8358\n",
      "loss 1769.5004\n",
      "loss 1745.338\n",
      "loss 1723.0116\n",
      "loss 1693.8981\n",
      "loss 1672.4169\n",
      "loss 1649.7345\n",
      "loss 1626.452\n",
      "loss 1608.7042\n",
      "loss 1583.0155\n",
      "loss 1560.9872\n",
      "loss 1540.9055\n",
      "loss 1521.9729\n",
      "loss 1501.0194\n",
      "loss 1482.6514\n",
      "loss 1465.9894\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  6 : loss 1465.9894\n",
      "loss 1448.5547\n",
      "loss 1429.4149\n",
      "loss 1411.7788\n",
      "loss 1393.1698\n",
      "loss 1376.1635\n",
      "loss 1360.3704\n",
      "loss 1340.9213\n",
      "loss 1325.3958\n",
      "loss 1310.4829\n",
      "loss 1296.2108\n",
      "loss 1284.717\n",
      "loss 1273.6514\n",
      "loss 1257.484\n",
      "loss 1245.3928\n",
      "loss 1232.8462\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  7 : loss 1232.8462\n",
      "loss 1220.6838\n",
      "loss 1211.3188\n",
      "loss 1197.7463\n",
      "loss 1186.651\n",
      "loss 1177.2997\n",
      "loss 1167.5673\n",
      "loss 1156.4751\n",
      "loss 1145.65\n",
      "loss 1137.4504\n",
      "loss 1130.427\n",
      "loss 1120.5881\n",
      "loss 1110.887\n",
      "loss 1102.5553\n",
      "loss 1094.6604\n",
      "loss 1086.2375\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  8 : loss 1086.2375\n",
      "loss 1080.5775\n",
      "loss 1067.2375\n",
      "loss 1063.0433\n",
      "loss 1056.1686\n",
      "loss 1046.7678\n",
      "loss 1036.6285\n",
      "loss 1028.7305\n",
      "loss 1022.5717\n",
      "loss 1014.24744\n",
      "loss 1008.45325\n",
      "loss 999.76794\n",
      "loss 994.2351\n",
      "loss 988.34436\n",
      "loss 979.0838\n",
      "loss 970.0686\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  9 : loss 970.0686\n",
      "loss 963.6965\n",
      "loss 957.91986\n",
      "loss 951.16003\n",
      "loss 942.6204\n",
      "loss 936.5159\n",
      "loss 931.6847\n",
      "loss 926.6027\n",
      "loss 922.0633\n",
      "loss 917.41394\n",
      "loss 911.20734\n",
      "loss 906.0184\n",
      "loss 898.6193\n",
      "loss 893.4752\n",
      "loss 889.9464\n",
      "loss 884.1811\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  10 : loss 884.1811\n",
      "loss 877.8167\n",
      "loss 872.15936\n",
      "loss 867.414\n",
      "loss 863.02826\n",
      "loss 857.8078\n",
      "loss 852.879\n",
      "loss 848.7407\n",
      "loss 846.37256\n",
      "loss 842.4126\n",
      "loss 838.35425\n",
      "loss 833.5406\n",
      "loss 830.25446\n",
      "loss 827.0431\n",
      "loss 821.65826\n",
      "loss 817.4601\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  11 : loss 817.4601\n",
      "loss 814.6635\n",
      "loss 811.20355\n",
      "loss 807.8316\n",
      "loss 803.05066\n",
      "loss 799.82965\n",
      "loss 795.7789\n",
      "loss 793.2007\n",
      "loss 789.5412\n",
      "loss 786.08295\n",
      "loss 781.94446\n",
      "loss 778.5276\n",
      "loss 775.40875\n",
      "loss 771.12646\n",
      "loss 766.99396\n",
      "loss 764.2584\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  12 : loss 764.2584\n",
      "loss 760.87683\n",
      "loss 757.4537\n",
      "loss 754.17957\n",
      "loss 751.26447\n",
      "loss 748.5452\n",
      "loss 745.0859\n",
      "loss 742.5146\n",
      "loss 739.95233\n",
      "loss 736.34143\n",
      "loss 733.1316\n",
      "loss 729.95374\n",
      "loss 727.9409\n",
      "loss 725.38574\n",
      "loss 720.57275\n",
      "loss 718.4606\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  13 : loss 718.4606\n",
      "loss 714.57666\n",
      "loss 712.8553\n",
      "loss 710.2578\n",
      "loss 705.8908\n",
      "loss 702.0804\n",
      "loss 699.58936\n",
      "loss 697.16956\n",
      "loss 694.626\n",
      "loss 690.61066\n",
      "loss 687.1219\n",
      "loss 684.2172\n",
      "loss 681.7602\n",
      "loss 679.0212\n",
      "loss 675.85223\n",
      "loss 672.97614\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  14 : loss 672.97614\n",
      "loss 670.9973\n",
      "loss 668.772\n",
      "loss 666.4826\n",
      "loss 663.7718\n",
      "loss 661.82\n",
      "loss 660.1222\n",
      "loss 657.945\n",
      "loss 655.5917\n",
      "loss 652.20215\n",
      "loss 650.00793\n",
      "loss 648.31976\n",
      "loss 646.02313\n",
      "loss 644.2054\n",
      "loss 641.9201\n",
      "loss 640.54535\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  15 : loss 640.54535\n",
      "loss 639.1154\n",
      "loss 637.3312\n",
      "loss 635.3971\n",
      "loss 633.67926\n",
      "loss 631.9333\n",
      "loss 630.0064\n",
      "loss 627.9796\n",
      "loss 626.4993\n",
      "loss 624.771\n",
      "loss 622.48627\n",
      "loss 620.4091\n",
      "loss 618.7396\n",
      "loss 616.88324\n",
      "loss 615.26874\n",
      "loss 612.74524\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  16 : loss 612.74524\n",
      "loss 610.892\n",
      "loss 609.4677\n",
      "loss 607.54755\n",
      "loss 606.0708\n",
      "loss 603.7628\n",
      "loss 602.9687\n",
      "loss 601.3924\n",
      "loss 600.438\n",
      "loss 599.2989\n",
      "loss 597.3904\n",
      "loss 595.5946\n",
      "loss 593.93866\n",
      "loss 592.6403\n",
      "loss 591.1092\n",
      "loss 587.96906\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  17 : loss 587.96906\n",
      "loss 586.42523\n",
      "loss 584.71497\n",
      "loss 583.55676\n",
      "loss 582.205\n",
      "loss 582.1632\n",
      "loss 580.9918\n",
      "loss 578.9755\n",
      "loss 577.4018\n",
      "loss 575.6962\n",
      "loss 574.3581\n",
      "loss 572.41205\n",
      "loss 571.3007\n",
      "loss 569.9912\n",
      "loss 568.64404\n",
      "loss 567.0425\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  18 : loss 567.0425\n",
      "loss 565.6686\n",
      "loss 564.49194\n",
      "loss 562.4867\n",
      "loss 560.86383\n",
      "loss 559.50696\n",
      "loss 558.1948\n",
      "loss 557.0246\n",
      "loss 555.4521\n",
      "loss 553.98975\n",
      "loss 552.7298\n",
      "loss 551.57556\n",
      "loss 549.8721\n",
      "loss 548.7415\n",
      "loss 547.76135\n",
      "loss 546.5532\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  19 : loss 546.5532\n",
      "loss 545.4396\n",
      "loss 544.9242\n",
      "loss 543.2035\n",
      "loss 542.6463\n",
      "loss 541.4246\n",
      "loss 540.3677\n",
      "loss 539.0475\n",
      "loss 537.8784\n",
      "loss 536.818\n",
      "loss 535.02277\n",
      "loss 536.3525\n",
      "loss 534.1416\n",
      "loss 532.95245\n",
      "loss 531.9961\n",
      "loss 530.8108\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  20 : loss 530.8108\n",
      "loss 529.6688\n",
      "loss 528.7103\n",
      "loss 527.39325\n",
      "loss 526.5159\n",
      "loss 525.5715\n",
      "loss 524.67535\n",
      "loss 523.8618\n",
      "loss 522.5328\n",
      "loss 521.6212\n",
      "loss 520.65204\n",
      "loss 519.827\n",
      "loss 518.9502\n",
      "loss 518.1861\n",
      "loss 516.88306\n",
      "loss 516.2751\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  21 : loss 516.2751\n",
      "loss 515.5042\n",
      "loss 514.21924\n",
      "loss 513.3948\n",
      "loss 512.1615\n",
      "loss 511.53107\n",
      "loss 510.77448\n",
      "loss 510.35526\n",
      "loss 509.0951\n",
      "loss 508.52792\n",
      "loss 507.86017\n",
      "loss 506.73672\n",
      "loss 505.36267\n",
      "loss 503.94998\n",
      "loss 503.19778\n",
      "loss 502.49976\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  22 : loss 502.49976\n",
      "loss 501.86688\n",
      "loss 501.2704\n",
      "loss 499.8412\n",
      "loss 499.51932\n",
      "loss 498.58005\n",
      "loss 497.82303\n",
      "loss 497.08878\n",
      "loss 496.06033\n",
      "loss 497.14423\n",
      "loss 495.39554\n",
      "loss 494.2327\n",
      "loss 493.40985\n",
      "loss 492.30524\n",
      "loss 491.66937\n",
      "loss 490.97946\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  23 : loss 490.97946\n",
      "loss 490.36545\n",
      "loss 489.84216\n",
      "loss 488.541\n",
      "loss 488.30838\n",
      "loss 486.95923\n",
      "loss 486.4942\n",
      "loss 485.69308\n",
      "loss 484.8998\n",
      "loss 483.96555\n",
      "loss 483.4508\n",
      "loss 482.78387\n",
      "loss 481.88284\n",
      "loss 481.67508\n",
      "loss 480.33682\n",
      "loss 479.92517\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  24 : loss 479.92517\n",
      "loss 479.4198\n",
      "loss 478.72473\n",
      "loss 477.9593\n",
      "loss 477.16898\n",
      "loss 476.65646\n",
      "loss 475.59973\n",
      "loss 475.79306\n",
      "loss 475.0344\n",
      "loss 474.422\n",
      "loss 473.78882\n",
      "loss 473.2188\n",
      "loss 472.31165\n",
      "loss 471.31696\n",
      "loss 470.462\n",
      "loss 469.84308\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  25 : loss 469.84308\n",
      "loss 469.0331\n",
      "loss 468.4928\n",
      "loss 467.88892\n",
      "loss 467.3024\n",
      "loss 466.7643\n",
      "loss 466.0856\n",
      "loss 465.0082\n",
      "loss 464.52692\n",
      "loss 463.87424\n",
      "loss 463.69412\n",
      "loss 462.83206\n",
      "loss 462.32053\n",
      "loss 461.83493\n",
      "loss 461.08322\n",
      "loss 460.9189\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  26 : loss 460.9189\n",
      "loss 459.69577\n",
      "loss 459.4544\n",
      "loss 458.88354\n",
      "loss 458.4478\n",
      "loss 457.81717\n",
      "loss 457.455\n",
      "loss 456.95468\n",
      "loss 456.00085\n",
      "loss 457.73517\n",
      "loss 455.624\n",
      "loss 455.08163\n",
      "loss 454.47174\n",
      "loss 453.92667\n",
      "loss 453.39932\n",
      "loss 452.85168\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  27 : loss 452.85168\n",
      "loss 452.3044\n",
      "loss 451.62552\n",
      "loss 450.97485\n",
      "loss 450.56384\n",
      "loss 450.1794\n",
      "loss 449.75308\n",
      "loss 449.1466\n",
      "loss 448.52386\n",
      "loss 447.72552\n",
      "loss 446.97214\n",
      "loss 446.4429\n",
      "loss 445.97736\n",
      "loss 445.30786\n",
      "loss 445.16626\n",
      "loss 444.16068\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  28 : loss 444.16068\n",
      "loss 443.93942\n",
      "loss 443.3184\n",
      "loss 442.5131\n",
      "loss 441.96002\n",
      "loss 441.21902\n",
      "loss 440.75446\n",
      "loss 440.3361\n",
      "loss 440.12802\n",
      "loss 439.40323\n",
      "loss 439.0147\n",
      "loss 438.64023\n",
      "loss 437.98767\n",
      "loss 437.32416\n",
      "loss 436.57388\n",
      "loss 436.21448\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  29 : loss 436.21448\n",
      "loss 435.65866\n",
      "loss 435.0942\n",
      "loss 434.4384\n",
      "loss 433.9311\n",
      "loss 433.60416\n",
      "loss 433.1601\n",
      "loss 432.57483\n",
      "loss 432.066\n",
      "loss 431.43228\n",
      "loss 430.983\n",
      "loss 430.54126\n",
      "loss 429.87915\n",
      "loss 429.46753\n",
      "loss 428.27563\n",
      "loss 429.71042\n",
      "loss 427.8839\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  30 : loss 427.8839\n",
      "loss 427.39792\n",
      "loss 426.97513\n",
      "loss 426.49667\n",
      "loss 425.77917\n",
      "loss 425.28473\n",
      "loss 424.72757\n",
      "loss 424.29922\n",
      "loss 423.81998\n",
      "loss 423.4869\n",
      "loss 423.11243\n",
      "loss 422.7249\n",
      "loss 422.42502\n",
      "loss 421.5942\n",
      "loss 421.58325\n",
      "loss 421.14166\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  31 : loss 421.14166\n",
      "loss 420.48547\n",
      "loss 420.11075\n",
      "loss 419.66354\n",
      "loss 419.2629\n",
      "loss 418.85718\n",
      "loss 418.39905\n",
      "loss 417.96652\n",
      "loss 417.14066\n",
      "loss 417.50745\n",
      "loss 416.74866\n",
      "loss 416.35684\n",
      "loss 416.0448\n",
      "loss 415.63226\n",
      "loss 415.09567\n",
      "loss 414.6116\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  32 : loss 414.6116\n",
      "loss 414.2338\n",
      "loss 413.71228\n",
      "loss 413.3471\n",
      "loss 412.68008\n",
      "loss 412.40158\n",
      "loss 412.06372\n",
      "loss 411.55887\n",
      "loss 410.7945\n",
      "loss 410.06842\n",
      "loss 409.6258\n",
      "loss 409.29352\n",
      "loss 409.0032\n",
      "loss 408.56714\n",
      "loss 407.74243\n",
      "loss 407.3585\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  33 : loss 407.3585\n",
      "loss 406.96515\n",
      "loss 406.40942\n",
      "loss 406.15625\n",
      "loss 405.89157\n",
      "loss 405.6176\n",
      "loss 405.22266\n",
      "loss 404.7973\n",
      "loss 404.47192\n",
      "loss 403.91235\n",
      "loss 403.6631\n",
      "loss 403.2691\n",
      "loss 402.7517\n",
      "loss 402.50412\n",
      "loss 401.8623\n",
      "loss 401.6664\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  34 : loss 401.6664\n",
      "loss 401.24832\n",
      "loss 400.95084\n",
      "loss 400.40906\n",
      "loss 400.12674\n",
      "loss 399.80182\n",
      "loss 399.59595\n",
      "loss 399.05914\n",
      "loss 398.78104\n",
      "loss 398.43884\n",
      "loss 397.95886\n",
      "loss 398.0117\n",
      "loss 397.64523\n",
      "loss 397.1715\n",
      "loss 396.88815\n",
      "loss 396.48767\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  35 : loss 396.48767\n",
      "loss 396.0951\n",
      "loss 395.68094\n",
      "loss 395.27814\n",
      "loss 394.9897\n",
      "loss 394.6079\n",
      "loss 394.1174\n",
      "loss 393.71304\n",
      "loss 393.33765\n",
      "loss 393.02698\n",
      "loss 392.65704\n",
      "loss 392.4187\n",
      "loss 391.99316\n",
      "loss 391.64923\n",
      "loss 390.98773\n",
      "loss 391.8668\n",
      "loss 390.6873\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  36 : loss 390.6873\n",
      "loss 390.17017\n",
      "loss 389.82953\n",
      "loss 389.53625\n",
      "loss 389.25854\n",
      "loss 388.92163\n",
      "loss 388.54388\n",
      "loss 388.08365\n",
      "loss 387.69846\n",
      "loss 387.28824\n",
      "loss 386.9087\n",
      "loss 386.53223\n",
      "loss 386.19345\n",
      "loss 385.8589\n",
      "loss 385.44525\n",
      "loss 385.1765\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  37 : loss 385.1765\n",
      "loss 385.13858\n",
      "loss 384.86484\n",
      "loss 384.34903\n",
      "loss 384.1214\n",
      "loss 383.69336\n",
      "loss 383.39987\n",
      "loss 383.05496\n",
      "loss 382.64102\n",
      "loss 382.30444\n",
      "loss 382.0444\n",
      "loss 381.73096\n",
      "loss 381.3919\n",
      "loss 380.97504\n",
      "loss 380.79648\n",
      "loss 380.3453\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  38 : loss 380.3453\n",
      "loss 380.15646\n",
      "loss 379.82822\n",
      "loss 379.63132\n",
      "loss 379.29645\n",
      "loss 379.02194\n",
      "loss 378.79227\n",
      "loss 378.27188\n",
      "loss 379.26276\n",
      "loss 378.0374\n",
      "loss 377.62628\n",
      "loss 377.35083\n",
      "loss 377.10837\n",
      "loss 376.85822\n",
      "loss 376.56973\n",
      "loss 376.32022\n",
      "loop <pymeshlab.pmeshlab.Mesh object at 0x7f4ce1e39330> it  39 : loss 376.32022\n",
      "loss 375.76813\n",
      "loss 376.8443\n",
      "loss 375.60303\n",
      "loss 375.2381\n",
      "loss 374.9762\n",
      "loss 374.68924\n",
      "loss 374.39023\n",
      "loss 374.12134\n",
      "loss 373.89105\n",
      "loss 373.4675\n",
      "loss 372.94894\n",
      "loss 372.86566\n",
      "loss 372.32483\n",
      "loss 372.1692\n",
      "loss 371.88748\n",
      "Optimization (L-BFGS) time:  1775.24  seconds\n"
     ]
    }
   ],
   "source": [
    "# Once the template has been constructed, we need to warp it to the population\n",
    "# using shooting and then shooting plus OMT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327x356 clusters, computed at scale = 3.157\n",
      "Successive scales :  68.903, 68.903, 55.122, 44.098, 35.278, 28.222, 22.578, 18.062, 14.450, 11.560, 9.248, 7.398, 5.919, 4.735, 3.788, 3.030, 2.424, 1.939, 1.552, 1.241, 0.993, 0.794, 0.636, 0.508, 0.407, 0.325, 0.260, 0.208, 0.167, 0.133, 0.107, 0.085, 0.068, 0.055, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.788) and 15 (=3.030).\n",
      "Keep 42597/116412 = 36.6% of the coarse cost matrix.\n",
      "Keep 39065/106929 = 36.5% of the coarse cost matrix.\n",
      "Keep 46508/126736 = 36.7% of the coarse cost matrix.\n",
      "OMT matching distance: 2.1609036922454834, time elapsed: 2.9839351177215576\n",
      "349x377 clusters, computed at scale = 3.066\n",
      "Successive scales :  66.898, 66.898, 53.519, 42.815, 34.252, 27.402, 21.921, 17.537, 14.030, 11.224, 8.979, 7.183, 5.747, 4.597, 3.678, 2.942, 2.354, 1.883, 1.506, 1.205, 0.964, 0.771, 0.617, 0.494, 0.395, 0.316, 0.253, 0.202, 0.162, 0.129, 0.104, 0.083, 0.066, 0.053, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.678) and 15 (=2.942).\n",
      "Keep 48461/131573 = 36.8% of the coarse cost matrix.\n",
      "Keep 43151/121801 = 35.4% of the coarse cost matrix.\n",
      "Keep 51907/142129 = 36.5% of the coarse cost matrix.\n",
      "OMT matching distance: 5.140484809875488, time elapsed: 3.1443610191345215\n",
      "322x358 clusters, computed at scale = 3.246\n",
      "Successive scales :  70.835, 70.835, 56.668, 45.334, 36.268, 29.014, 23.211, 18.569, 14.855, 11.884, 9.507, 7.606, 6.085, 4.868, 3.894, 3.115, 2.492, 1.994, 1.595, 1.276, 1.021, 0.817, 0.653, 0.523, 0.418, 0.335, 0.268, 0.214, 0.171, 0.137, 0.110, 0.088, 0.070, 0.056, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.894) and 15 (=3.115).\n",
      "Keep 43429/115276 = 37.7% of the coarse cost matrix.\n",
      "Keep 39176/103684 = 37.8% of the coarse cost matrix.\n",
      "Keep 46810/128164 = 36.5% of the coarse cost matrix.\n",
      "OMT matching distance: 7.185439109802246, time elapsed: 3.0067975521087646\n",
      "326x315 clusters, computed at scale = 3.197\n",
      "Successive scales :  69.760, 69.760, 55.808, 44.646, 35.717, 28.574, 22.859, 18.287, 14.630, 11.704, 9.363, 7.490, 5.992, 4.794, 3.835, 3.068, 2.454, 1.964, 1.571, 1.257, 1.005, 0.804, 0.643, 0.515, 0.412, 0.329, 0.264, 0.211, 0.169, 0.135, 0.108, 0.086, 0.069, 0.055, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.835) and 15 (=3.068).\n",
      "Keep 38772/102690 = 37.8% of the coarse cost matrix.\n",
      "Keep 39266/106276 = 36.9% of the coarse cost matrix.\n",
      "Keep 37201/99225 = 37.5% of the coarse cost matrix.\n",
      "OMT matching distance: 6.750411510467529, time elapsed: 2.827338695526123\n",
      "326x345 clusters, computed at scale = 3.150\n",
      "Successive scales :  68.751, 68.751, 55.001, 44.000, 35.200, 28.160, 22.528, 18.023, 14.418, 11.534, 9.228, 7.382, 5.906, 4.725, 3.780, 3.024, 2.419, 1.935, 1.548, 1.239, 0.991, 0.793, 0.634, 0.507, 0.406, 0.325, 0.260, 0.208, 0.166, 0.133, 0.106, 0.085, 0.068, 0.054, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.780) and 15 (=3.024).\n",
      "Keep 42300/112470 = 37.6% of the coarse cost matrix.\n",
      "Keep 38576/106276 = 36.3% of the coarse cost matrix.\n",
      "Keep 45377/119025 = 38.1% of the coarse cost matrix.\n",
      "OMT matching distance: 17.089303970336914, time elapsed: 2.898796319961548\n",
      "284x315 clusters, computed at scale = 3.326\n",
      "Successive scales :  72.575, 72.575, 58.060, 46.448, 37.158, 29.727, 23.781, 19.025, 15.220, 12.176, 9.741, 7.793, 6.234, 4.987, 3.990, 3.192, 2.554, 2.043, 1.634, 1.307, 1.046, 0.837, 0.669, 0.536, 0.428, 0.343, 0.274, 0.219, 0.175, 0.140, 0.112, 0.090, 0.072, 0.057, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.990) and 15 (=3.192).\n",
      "Keep 35106/89460 = 39.2% of the coarse cost matrix.\n",
      "Keep 31904/80656 = 39.6% of the coarse cost matrix.\n",
      "Keep 37663/99225 = 38.0% of the coarse cost matrix.\n",
      "OMT matching distance: 5.225931167602539, time elapsed: 2.599527597427368\n",
      "270x300 clusters, computed at scale = 3.413\n",
      "Successive scales :  74.485, 74.485, 59.588, 47.670, 38.136, 30.509, 24.407, 19.526, 15.621, 12.496, 9.997, 7.998, 6.398, 5.119, 4.095, 3.276, 2.621, 2.097, 1.677, 1.342, 1.073, 0.859, 0.687, 0.550, 0.440, 0.352, 0.281, 0.225, 0.180, 0.144, 0.115, 0.092, 0.074, 0.059, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.095) and 15 (=3.276).\n",
      "Keep 32831/81000 = 40.5% of the coarse cost matrix.\n",
      "Keep 29642/72900 = 40.7% of the coarse cost matrix.\n",
      "Keep 35776/90000 = 39.8% of the coarse cost matrix.\n",
      "OMT matching distance: 4.707029342651367, time elapsed: 2.5048272609710693\n",
      "324x338 clusters, computed at scale = 3.227\n",
      "Successive scales :  70.431, 70.431, 56.345, 45.076, 36.061, 28.849, 23.079, 18.463, 14.770, 11.816, 9.453, 7.562, 6.050, 4.840, 3.872, 3.098, 2.478, 1.982, 1.586, 1.269, 1.015, 0.812, 0.650, 0.520, 0.416, 0.333, 0.266, 0.213, 0.170, 0.136, 0.109, 0.087, 0.070, 0.056, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.872) and 15 (=3.098).\n",
      "Keep 42209/109512 = 38.5% of the coarse cost matrix.\n",
      "Keep 39328/104976 = 37.5% of the coarse cost matrix.\n",
      "Keep 43994/114244 = 38.5% of the coarse cost matrix.\n",
      "OMT matching distance: 6.3784403800964355, time elapsed: 2.8656773567199707\n",
      "329x328 clusters, computed at scale = 3.154\n",
      "Successive scales :  68.826, 68.826, 55.061, 44.048, 35.239, 28.191, 22.553, 18.042, 14.434, 11.547, 9.238, 7.390, 5.912, 4.730, 3.784, 3.027, 2.422, 1.937, 1.550, 1.240, 0.992, 0.794, 0.635, 0.508, 0.406, 0.325, 0.260, 0.208, 0.166, 0.133, 0.107, 0.085, 0.068, 0.055, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.784) and 15 (=3.027).\n",
      "Keep 41303/107912 = 38.3% of the coarse cost matrix.\n",
      "Keep 39437/108241 = 36.4% of the coarse cost matrix.\n",
      "Keep 41754/107584 = 38.8% of the coarse cost matrix.\n",
      "OMT matching distance: 7.170167446136475, time elapsed: 2.8781332969665527\n",
      "328x311 clusters, computed at scale = 3.155\n",
      "Successive scales :  68.855, 68.855, 55.084, 44.067, 35.254, 28.203, 22.562, 18.050, 14.440, 11.552, 9.242, 7.393, 5.915, 4.732, 3.785, 3.028, 2.423, 1.938, 1.550, 1.240, 0.992, 0.794, 0.635, 0.508, 0.406, 0.325, 0.260, 0.208, 0.166, 0.133, 0.107, 0.085, 0.068, 0.055, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.785) and 15 (=3.028).\n",
      "Keep 38249/102008 = 37.5% of the coarse cost matrix.\n",
      "Keep 39270/107584 = 36.5% of the coarse cost matrix.\n",
      "Keep 36713/96721 = 38.0% of the coarse cost matrix.\n",
      "OMT matching distance: 8.426424026489258, time elapsed: 2.799736261367798\n",
      "327x345 clusters, computed at scale = 3.221\n",
      "Successive scales :  70.290, 70.290, 56.232, 44.985, 35.988, 28.791, 23.033, 18.426, 14.741, 11.793, 9.434, 7.547, 6.038, 4.830, 3.864, 3.091, 2.473, 1.978, 1.583, 1.266, 1.013, 0.810, 0.648, 0.519, 0.415, 0.332, 0.266, 0.212, 0.170, 0.136, 0.109, 0.087, 0.070, 0.056, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.864) and 15 (=3.091).\n",
      "Keep 42703/112815 = 37.9% of the coarse cost matrix.\n",
      "Keep 39905/106929 = 37.3% of the coarse cost matrix.\n",
      "Keep 45009/119025 = 37.8% of the coarse cost matrix.\n",
      "OMT matching distance: 13.555181503295898, time elapsed: 2.9297094345092773\n",
      "323x331 clusters, computed at scale = 3.232\n",
      "Successive scales :  70.534, 70.534, 56.427, 45.141, 36.113, 28.891, 23.112, 18.490, 14.792, 11.834, 9.467, 7.573, 6.059, 4.847, 3.878, 3.102, 2.482, 1.985, 1.588, 1.271, 1.016, 0.813, 0.651, 0.520, 0.416, 0.333, 0.266, 0.213, 0.171, 0.136, 0.109, 0.087, 0.070, 0.056, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.878) and 15 (=3.102).\n",
      "Keep 39829/106913 = 37.3% of the coarse cost matrix.\n",
      "Keep 39367/104329 = 37.7% of the coarse cost matrix.\n",
      "Keep 39537/109561 = 36.1% of the coarse cost matrix.\n",
      "OMT matching distance: 5.982914924621582, time elapsed: 2.8600034713745117\n",
      "344x356 clusters, computed at scale = 3.103\n",
      "Successive scales :  67.722, 67.722, 54.178, 43.342, 34.674, 27.739, 22.191, 17.753, 14.202, 11.362, 9.090, 7.272, 5.817, 4.654, 3.723, 2.978, 2.383, 1.906, 1.525, 1.220, 0.976, 0.781, 0.625, 0.500, 0.400, 0.320, 0.256, 0.205, 0.164, 0.131, 0.105, 0.084, 0.067, 0.054, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.723) and 15 (=2.978).\n",
      "Keep 43788/122464 = 35.8% of the coarse cost matrix.\n",
      "Keep 42998/118336 = 36.3% of the coarse cost matrix.\n",
      "Keep 44740/126736 = 35.3% of the coarse cost matrix.\n",
      "OMT matching distance: 0.07986817508935928, time elapsed: 3.069551706314087\n",
      "356x350 clusters, computed at scale = 2.803\n",
      "Successive scales :  61.166, 61.166, 48.933, 39.146, 31.317, 25.054, 20.043, 16.034, 12.827, 10.262, 8.210, 6.568, 5.254, 4.203, 3.363, 2.690, 2.152, 1.722, 1.377, 1.102, 0.881, 0.705, 0.564, 0.451, 0.361, 0.289, 0.231, 0.185, 0.148, 0.118, 0.095, 0.076, 0.061, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.363) and 15 (=2.690).\n",
      "Keep 43915/124600 = 35.2% of the coarse cost matrix.\n",
      "Keep 44984/126736 = 35.5% of the coarse cost matrix.\n",
      "Keep 42898/122500 = 35.0% of the coarse cost matrix.\n",
      "OMT matching distance: 0.02683163434267044, time elapsed: 2.8735175132751465\n"
     ]
    }
   ],
   "source": [
    "md_src3 = update_model_by_remeshing(md_src2, md_aff, p_root, p_temp_z)\n",
    "save_vtk(md_src3.pd, 'tmp/template_stage2.vtk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1780083/2990742960.py:39: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 000  Loss 60426.01171875\n",
      "Iteration 001  Loss 12709.44921875\n",
      "Iteration 002  Loss 6302.05908203125\n",
      "Iteration 003  Loss 3513.724609375\n",
      "Iteration 004  Loss 2372.8330078125\n",
      "Iteration 005  Loss 1814.6024169921875\n",
      "Iteration 006  Loss 1471.04736328125\n",
      "Iteration 007  Loss 1235.9661865234375\n",
      "Iteration 008  Loss 1092.425537109375\n",
      "Iteration 009  Loss 981.1105346679688\n",
      "Optimization (L-BFGS) time: 465.75 seconds\n"
     ]
    }
   ],
   "source": [
    "p_root_3, p_temp_z_3 = fit_model_to_population(md_src3, md_aff, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = GaussKernel(sigma=sigma_lddmm)\n",
    "_, q_temp_3 = Shooting(p_root_3, md_src3.vt.clone().requires_grad_(True).contiguous(), K)[-1]\n",
    "pd_result_3 = vtk_make_pd(q_temp_3.detach().cpu().numpy(), md_src3.f)\n",
    "pd_result_3 = vtk_set_cell_array(pd_result_3, 'plab', md_src3.lp)\n",
    "save_vtk(pd_result, 'tmp/template_stage2_def.vtk')\n",
    "\n",
    "for i, (id,v) in enumerate(md_aff.items()):\n",
    "    _, q_i = Shooting(p_temp_z_3[i,:], q_temp_3, K)[-1]\n",
    "    # loss_h = 0.1 * Hamiltonian(K)(p_temp_z[i,:], q_temp)\n",
    "    # loss_d = d_loss[id](q_i)\n",
    "    # print(f'{id}: loss_h: {loss_h}, loss_d: {loss_d}')\n",
    "    pd_result = vtk_make_pd(q_i.detach().cpu().numpy(), md_src3.f)\n",
    "    pd_result = vtk_set_cell_array(pd_result, 'plab', md_src3.lp)\n",
    "    save_vtk(pd_result, f'tmp/template_stage2_def_to_{id}.vtk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, q_temp = Shooting(p_root, q_root, K)[-1]\n",
    "pd_result = vtk_make_pd(q_temp.detach().cpu().numpy(), md_src2.f)\n",
    "pd_result = vtk_set_cell_array(pd_result, 'plab', md_src2.lp)\n",
    "save_vtk(pd_result, 'tmp/template_from_taubin.vtk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104937L: loss_h: 92.9029769897461, loss_d: 299.8125\n",
      "106049L: loss_h: 53.60837936401367, loss_d: 566.75\n",
      "106312R: loss_h: 61.9499626159668, loss_d: 592.5625\n",
      "113909R: loss_h: 42.26411819458008, loss_d: 158.8125\n",
      "116748R: loss_h: 65.7442626953125, loss_d: 283.09375\n",
      "117243R: loss_h: 47.26437759399414, loss_d: 273.9375\n",
      "117667R: loss_h: 74.99248504638672, loss_d: 444.53125\n",
      "118374L: loss_h: 45.83708572387695, loss_d: 170.875\n",
      "118430R: loss_h: 73.35762023925781, loss_d: 232.75\n",
      "120126L: loss_h: 43.98615646362305, loss_d: 253.875\n",
      "120267L: loss_h: 46.03990173339844, loss_d: 218.84375\n",
      "120937L: loss_h: 59.33658981323242, loss_d: 399.78125\n",
      "121250L: loss_h: 50.62836837768555, loss_d: 181.0\n"
     ]
    }
   ],
   "source": [
    "p_temp_z = p_temp - torch.mean(p_temp, 0, keepdim=True)\n",
    "for i, (id,v) in enumerate(md_aff.items()):\n",
    "    _, q_i = Shooting(p_temp_z[i,:], q_temp, K)[-1]\n",
    "    loss_h = 0.1 * Hamiltonian(K)(p_temp_z[i,:], q_temp)\n",
    "    loss_d = d_loss[id](q_i)\n",
    "    print(f'{id}: loss_h: {loss_h}, loss_d: {loss_d}')\n",
    "    pd_result = vtk_make_pd(q_i.detach().cpu().numpy(), md_src2.f)\n",
    "    pd_result = vtk_set_cell_array(pd_result, 'plab', md_src2.lp)\n",
    "    save_vtk(pd_result, f'tmp/template_to_{id}.vtk')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327x356 clusters, computed at scale = 3.157\n",
      "Successive scales :  68.903, 68.903, 55.122, 44.098, 35.278, 28.222, 22.578, 18.062, 14.450, 11.560, 9.248, 7.398, 5.919, 4.735, 3.788, 3.030, 2.424, 1.939, 1.552, 1.241, 0.993, 0.794, 0.636, 0.508, 0.407, 0.325, 0.260, 0.208, 0.167, 0.133, 0.107, 0.085, 0.068, 0.055, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.788) and 15 (=3.030).\n",
      "Keep 42596/116412 = 36.6% of the coarse cost matrix.\n",
      "Keep 39065/106929 = 36.5% of the coarse cost matrix.\n",
      "Keep 46508/126736 = 36.7% of the coarse cost matrix.\n",
      "OMT matching distance: 2.1609044075012207, time elapsed: 2.936350107192993\n",
      "349x377 clusters, computed at scale = 3.066\n",
      "Successive scales :  66.898, 66.898, 53.519, 42.815, 34.252, 27.402, 21.921, 17.537, 14.030, 11.224, 8.979, 7.183, 5.747, 4.597, 3.678, 2.942, 2.354, 1.883, 1.506, 1.205, 0.964, 0.771, 0.617, 0.494, 0.395, 0.316, 0.253, 0.202, 0.162, 0.129, 0.104, 0.083, 0.066, 0.053, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.678) and 15 (=2.942).\n",
      "Keep 48461/131573 = 36.8% of the coarse cost matrix.\n",
      "Keep 43151/121801 = 35.4% of the coarse cost matrix.\n",
      "Keep 51907/142129 = 36.5% of the coarse cost matrix.\n",
      "OMT matching distance: 5.14048433303833, time elapsed: 3.1086032390594482\n",
      "322x358 clusters, computed at scale = 3.246\n",
      "Successive scales :  70.835, 70.835, 56.668, 45.334, 36.268, 29.014, 23.211, 18.569, 14.855, 11.884, 9.507, 7.606, 6.085, 4.868, 3.894, 3.115, 2.492, 1.994, 1.595, 1.276, 1.021, 0.817, 0.653, 0.523, 0.418, 0.335, 0.268, 0.214, 0.171, 0.137, 0.110, 0.088, 0.070, 0.056, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.894) and 15 (=3.115).\n",
      "Keep 43429/115276 = 37.7% of the coarse cost matrix.\n",
      "Keep 39176/103684 = 37.8% of the coarse cost matrix.\n",
      "Keep 46810/128164 = 36.5% of the coarse cost matrix.\n",
      "OMT matching distance: 7.185438632965088, time elapsed: 2.925116539001465\n",
      "326x315 clusters, computed at scale = 3.197\n",
      "Successive scales :  69.760, 69.760, 55.808, 44.646, 35.717, 28.574, 22.859, 18.287, 14.630, 11.704, 9.363, 7.490, 5.992, 4.794, 3.835, 3.068, 2.454, 1.964, 1.571, 1.257, 1.005, 0.804, 0.643, 0.515, 0.412, 0.329, 0.264, 0.211, 0.169, 0.135, 0.108, 0.086, 0.069, 0.055, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.835) and 15 (=3.068).\n",
      "Keep 38772/102690 = 37.8% of the coarse cost matrix.\n",
      "Keep 39266/106276 = 36.9% of the coarse cost matrix.\n",
      "Keep 37201/99225 = 37.5% of the coarse cost matrix.\n",
      "OMT matching distance: 6.750411510467529, time elapsed: 2.7802343368530273\n",
      "326x345 clusters, computed at scale = 3.150\n",
      "Successive scales :  68.751, 68.751, 55.001, 44.000, 35.200, 28.160, 22.528, 18.023, 14.418, 11.534, 9.228, 7.382, 5.906, 4.725, 3.780, 3.024, 2.419, 1.935, 1.548, 1.239, 0.991, 0.793, 0.634, 0.507, 0.406, 0.325, 0.260, 0.208, 0.166, 0.133, 0.106, 0.085, 0.068, 0.054, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.780) and 15 (=3.024).\n",
      "Keep 42300/112470 = 37.6% of the coarse cost matrix.\n",
      "Keep 38576/106276 = 36.3% of the coarse cost matrix.\n",
      "Keep 45377/119025 = 38.1% of the coarse cost matrix.\n",
      "OMT matching distance: 17.089303970336914, time elapsed: 2.902498960494995\n",
      "284x315 clusters, computed at scale = 3.326\n",
      "Successive scales :  72.575, 72.575, 58.060, 46.448, 37.158, 29.727, 23.781, 19.025, 15.220, 12.176, 9.741, 7.793, 6.234, 4.987, 3.990, 3.192, 2.554, 2.043, 1.634, 1.307, 1.046, 0.837, 0.669, 0.536, 0.428, 0.343, 0.274, 0.219, 0.175, 0.140, 0.112, 0.090, 0.072, 0.057, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.990) and 15 (=3.192).\n",
      "Keep 35106/89460 = 39.2% of the coarse cost matrix.\n",
      "Keep 31904/80656 = 39.6% of the coarse cost matrix.\n",
      "Keep 37663/99225 = 38.0% of the coarse cost matrix.\n",
      "OMT matching distance: 5.225930690765381, time elapsed: 2.6031551361083984\n",
      "270x300 clusters, computed at scale = 3.413\n",
      "Successive scales :  74.485, 74.485, 59.588, 47.670, 38.136, 30.509, 24.407, 19.526, 15.621, 12.496, 9.997, 7.998, 6.398, 5.119, 4.095, 3.276, 2.621, 2.097, 1.677, 1.342, 1.073, 0.859, 0.687, 0.550, 0.440, 0.352, 0.281, 0.225, 0.180, 0.144, 0.115, 0.092, 0.074, 0.059, 0.050\n",
      "Jump from coarse to fine between indices 14 (=4.095) and 15 (=3.276).\n",
      "Keep 32831/81000 = 40.5% of the coarse cost matrix.\n",
      "Keep 29642/72900 = 40.7% of the coarse cost matrix.\n",
      "Keep 35776/90000 = 39.8% of the coarse cost matrix.\n",
      "OMT matching distance: 4.707029819488525, time elapsed: 2.4851150512695312\n",
      "324x338 clusters, computed at scale = 3.227\n",
      "Successive scales :  70.431, 70.431, 56.345, 45.076, 36.061, 28.849, 23.079, 18.463, 14.770, 11.816, 9.453, 7.562, 6.050, 4.840, 3.872, 3.098, 2.478, 1.982, 1.586, 1.269, 1.015, 0.812, 0.650, 0.520, 0.416, 0.333, 0.266, 0.213, 0.170, 0.136, 0.109, 0.087, 0.070, 0.056, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.872) and 15 (=3.098).\n",
      "Keep 42209/109512 = 38.5% of the coarse cost matrix.\n",
      "Keep 39328/104976 = 37.5% of the coarse cost matrix.\n",
      "Keep 43994/114244 = 38.5% of the coarse cost matrix.\n",
      "OMT matching distance: 6.3784403800964355, time elapsed: 2.8495774269104004\n",
      "329x328 clusters, computed at scale = 3.154\n",
      "Successive scales :  68.826, 68.826, 55.061, 44.048, 35.239, 28.191, 22.553, 18.042, 14.434, 11.547, 9.238, 7.390, 5.912, 4.730, 3.784, 3.027, 2.422, 1.937, 1.550, 1.240, 0.992, 0.794, 0.635, 0.508, 0.406, 0.325, 0.260, 0.208, 0.166, 0.133, 0.107, 0.085, 0.068, 0.055, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.784) and 15 (=3.027).\n",
      "Keep 41303/107912 = 38.3% of the coarse cost matrix.\n",
      "Keep 39437/108241 = 36.4% of the coarse cost matrix.\n",
      "Keep 41754/107584 = 38.8% of the coarse cost matrix.\n",
      "OMT matching distance: 7.170166969299316, time elapsed: 2.8295669555664062\n",
      "328x311 clusters, computed at scale = 3.155\n",
      "Successive scales :  68.855, 68.855, 55.084, 44.067, 35.254, 28.203, 22.562, 18.050, 14.440, 11.552, 9.242, 7.393, 5.915, 4.732, 3.785, 3.028, 2.423, 1.938, 1.550, 1.240, 0.992, 0.794, 0.635, 0.508, 0.406, 0.325, 0.260, 0.208, 0.166, 0.133, 0.107, 0.085, 0.068, 0.055, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.785) and 15 (=3.028).\n",
      "Keep 38249/102008 = 37.5% of the coarse cost matrix.\n",
      "Keep 39270/107584 = 36.5% of the coarse cost matrix.\n",
      "Keep 36713/96721 = 38.0% of the coarse cost matrix.\n",
      "OMT matching distance: 8.426424026489258, time elapsed: 2.7361233234405518\n",
      "327x345 clusters, computed at scale = 3.221\n",
      "Successive scales :  70.290, 70.290, 56.232, 44.985, 35.988, 28.791, 23.033, 18.426, 14.741, 11.793, 9.434, 7.547, 6.038, 4.830, 3.864, 3.091, 2.473, 1.978, 1.583, 1.266, 1.013, 0.810, 0.648, 0.519, 0.415, 0.332, 0.266, 0.212, 0.170, 0.136, 0.109, 0.087, 0.070, 0.056, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.864) and 15 (=3.091).\n",
      "Keep 42703/112815 = 37.9% of the coarse cost matrix.\n",
      "Keep 39905/106929 = 37.3% of the coarse cost matrix.\n",
      "Keep 45009/119025 = 37.8% of the coarse cost matrix.\n",
      "OMT matching distance: 13.555181503295898, time elapsed: 2.8913097381591797\n",
      "323x331 clusters, computed at scale = 3.232\n",
      "Successive scales :  70.534, 70.534, 56.427, 45.141, 36.113, 28.891, 23.112, 18.490, 14.792, 11.834, 9.467, 7.573, 6.059, 4.847, 3.878, 3.102, 2.482, 1.985, 1.588, 1.271, 1.016, 0.813, 0.651, 0.520, 0.416, 0.333, 0.266, 0.213, 0.171, 0.136, 0.109, 0.087, 0.070, 0.056, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.878) and 15 (=3.102).\n",
      "Keep 39829/106913 = 37.3% of the coarse cost matrix.\n",
      "Keep 39367/104329 = 37.7% of the coarse cost matrix.\n",
      "Keep 39537/109561 = 36.1% of the coarse cost matrix.\n",
      "OMT matching distance: 5.982913970947266, time elapsed: 2.8176634311676025\n",
      "344x356 clusters, computed at scale = 3.103\n",
      "Successive scales :  67.722, 67.722, 54.178, 43.342, 34.674, 27.739, 22.191, 17.753, 14.202, 11.362, 9.090, 7.272, 5.817, 4.654, 3.723, 2.978, 2.383, 1.906, 1.525, 1.220, 0.976, 0.781, 0.625, 0.500, 0.400, 0.320, 0.256, 0.205, 0.164, 0.131, 0.105, 0.084, 0.067, 0.054, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.723) and 15 (=2.978).\n",
      "Keep 43788/122464 = 35.8% of the coarse cost matrix.\n",
      "Keep 42998/118336 = 36.3% of the coarse cost matrix.\n",
      "Keep 44740/126736 = 35.3% of the coarse cost matrix.\n",
      "OMT matching distance: 0.07986818253993988, time elapsed: 2.994403600692749\n"
     ]
    }
   ],
   "source": [
    "# Use OMT after registration to remap labels to the template\n",
    "_, q_temp = Shooting(p_root, q_root, K)[-1]\n",
    "plab_sample = []\n",
    "p_temp_z = p_temp - torch.mean(p_temp, 0, keepdim=True)\n",
    "for (id, md_i) in md_aff.items():\n",
    "    _, q_i = Shooting(p_temp_z[i,:], q_temp, K)[-1]\n",
    "    f_omt, w_omt = match_omt(q_i, md_src2.ft, md_i.vt, md_i.ft)\n",
    "    lp_omt = vtk_sample_cell_array_at_vertices(md_i.pd, md_i.lp, w_omt.detach().cpu().numpy())\n",
    "    plab_sample.append(lp_omt)\n",
    "    \n",
    "plab_sample_avg = np.stack(plab_sample).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_template = vtk_make_pd(q_temp.detach().cpu().numpy(), md_src2.f)\n",
    "pd_template = vtk_set_cell_array(pd_template, 'plab_orig', md_src2.lp)\n",
    "pd_template = vtk_set_cell_array(pd_template, 'plab', softmax(plab_sample_avg * 10, 1))\n",
    "for i, (id, md_i) in enumerate(md_aff.items()):\n",
    "    pd_template = vtk_set_point_array(pd_template, f'momenta_{id}', p_temp_z[i,:,:].detach().cpu().numpy())\n",
    "\n",
    "save_vtk(pd_template, 'tmp/template_before_remesh.vtk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356x350 clusters, computed at scale = 2.803\n",
      "Successive scales :  61.166, 61.166, 48.933, 39.146, 31.317, 25.054, 20.043, 16.034, 12.827, 10.262, 8.210, 6.568, 5.254, 4.203, 3.363, 2.690, 2.152, 1.722, 1.377, 1.102, 0.881, 0.705, 0.564, 0.451, 0.361, 0.289, 0.231, 0.185, 0.148, 0.118, 0.095, 0.076, 0.061, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.363) and 15 (=2.690).\n",
      "Keep 43915/124600 = 35.2% of the coarse cost matrix.\n",
      "Keep 44984/126736 = 35.5% of the coarse cost matrix.\n",
      "Keep 42898/122500 = 35.0% of the coarse cost matrix.\n",
      "OMT matching distance: 0.02683163434267044, time elapsed: 2.844156503677368\n"
     ]
    }
   ],
   "source": [
    "# Let's try to remesh the template\n",
    "ms = pymeshlab.MeshSet()\n",
    "ms.add_mesh(pymeshlab.Mesh(vertex_matrix=q_temp.detach().cpu().numpy(), face_matrix=md_src2.f))\n",
    "ms.meshing_isotropic_explicit_remeshing()\n",
    "v_remesh, f_remesh = ms.mesh(0).vertex_matrix(), ms.mesh(0).face_matrix()\n",
    "pd_remesh = vtk_make_pd(v_remesh, f_remesh)\n",
    "\n",
    "# Apply remeshing to the momenta\n",
    "p_temp_remesh_src = []\n",
    "for i, (id, md_i) in enumerate(md_aff.items()):\n",
    "    p_i = vtk_sample_point_array_at_vertices(pd_template, p_temp_z[i,:,:].detach().cpu().numpy(), v_remesh)\n",
    "    p_temp_remesh_src.append(p_i)\n",
    "    pd_remesh = vtk_set_point_array(pd_remesh, f'momenta_{id}', p_i)\n",
    "\n",
    "# Apply the remeshing to the plab array\n",
    "f_omt, w_omt = match_omt(torch.tensor(v_remesh, dtype=torch.float32, device=device), \n",
    "                         torch.tensor(f_remesh, dtype=torch.long, device=device),\n",
    "                         q_temp, md_src2.ft)\n",
    "\n",
    "lp_remesh = vtk_sample_cell_array_at_vertices(pd_template, plab_sample_avg, w_omt.detach().cpu().numpy())\n",
    "pd_remesh = vtk_set_cell_array(pd_remesh, 'plab', softmax(lp_remesh * 10, 1))\n",
    "\n",
    "# Save the remeshed array\n",
    "save_vtk(pd_remesh, 'tmp/template_after_remesh.vtk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_remesh = MeshData(pd_remesh, device)\n",
    "_, q_test = Shooting(torch.tensor(p_temp_remesh_src[0], dtype=torch.float32, device=device, requires_grad=True).contiguous(),\n",
    "                     torch.tensor(v_remesh, dtype=torch.float32, device=device, requires_grad=True).contiguous(), K)[-1]\n",
    "\n",
    "pd_test = vtk_make_pd(q_test.detach().cpu().numpy(), f_remesh)\n",
    "save_vtk(pd_test,'tmp/remesh_to_subj_shooting_test.vtk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116x350 clusters, computed at scale = 2.803\n",
      "Successive scales :  61.166, 61.166, 48.933, 39.146, 31.317, 25.054, 20.043, 16.034, 12.827, 10.262, 8.210, 6.568, 5.254, 4.203, 3.363, 2.690, 2.152, 1.722, 1.377, 1.102, 0.881, 0.705, 0.564, 0.451, 0.361, 0.289, 0.231, 0.185, 0.148, 0.118, 0.095, 0.076, 0.061, 0.050\n",
      "Jump from coarse to fine between indices 14 (=3.363) and 15 (=2.690).\n",
      "Keep 19067/40600 = 47.0% of the coarse cost matrix.\n",
      "Keep 7906/13456 = 58.8% of the coarse cost matrix.\n",
      "Keep 42898/122500 = 35.0% of the coarse cost matrix.\n",
      "OMT matching distance: 50.010459899902344, time elapsed: 1.9429802894592285\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform OMT between remeshed mesh and the \n",
    "pd_sphere_opt_2 = vtk_set_cell_array(pd_sphere_opt, 'plab', softmax(plab_sample_avg * 10, axis=1))\n",
    "save_vtk(pd_sphere_opt_2, 'tmp/ellipsoid_best_fit_plab.vtk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12542, 3)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_remesh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5120, 3)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_sph.f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "be537",
   "language": "python",
   "name": "be537"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
